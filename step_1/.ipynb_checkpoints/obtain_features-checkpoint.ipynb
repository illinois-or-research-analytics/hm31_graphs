{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f303592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T01:54:36.851224569Z",
     "start_time": "2023-09-04T01:54:34.244136250Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98753it [00:00, 889393.00it/s]\n",
      "2004it [00:00, 918621.34it/s]\n"
     ]
    }
   ],
   "source": [
    "#Load edges and nodes\n",
    "\n",
    "import numpy as np\n",
    "from load_data import *\n",
    "\n",
    "nodes_array, edge_array = assert_edges_are_within_first_cluster()\n",
    "\n",
    "node_lookup_dict = {}\n",
    "\n",
    "min_index = np.amin(nodes_array)\n",
    "max_index = np.amax(nodes_array)\n",
    "\n",
    "\n",
    "i = 0\n",
    "for node in nodes_array:\n",
    "    node_lookup_dict[str(node)] = i\n",
    "    i+= 1\n",
    "    \n",
    "adj_matrix = np.load('adj_matrix.npy')    \n",
    "data_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdeaad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T01:55:08.611484619Z",
     "start_time": "2023-09-04T01:54:36.754851060Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get dois from the exosome csv\n",
    "#Read the DOIS from the node id\n",
    "\n",
    "from load_data import *\n",
    "\n",
    "import csv\n",
    "\n",
    "csv_file_path = data_dir + 'exosome.csv'\n",
    "doi_lookup_dict = {}\n",
    "\n",
    "# Open the CSV file for reading\n",
    "with open(csv_file_path, 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    dois = {}\n",
    "    for line_number, row in tqdm(enumerate(csv_reader), total = 14695476):  # 'total' is the total number of iterations\n",
    "        \n",
    "        if line_number <min_index or line_number > max_index:\n",
    "            continue\n",
    "            \n",
    "        id = str(row[0])\n",
    "        doi = row[2]\n",
    "        \n",
    "        if id in node_lookup_dict:\n",
    "            doi_lookup_dict[id] = doi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9c810cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T01:55:08.612905863Z",
     "start_time": "2023-09-04T01:55:08.610948941Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Save\n",
    "import json\n",
    "\n",
    "with open('first_cluster_dois.json', 'w') as json_file:\n",
    "    json.dump(doi_lookup_dict, json_file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f66d16",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-04T01:55:08.611984690Z"
    },
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2004 [00:00<04:24,  7.57it/s]"
     ]
    }
   ],
   "source": [
    "#Get PMID by doi\n",
    "\n",
    "import requests\n",
    "import xmltodict\n",
    "\n",
    "doi_dict = {}\n",
    "\n",
    "#Get dois\n",
    "def fetch_pmid_from_doi(doi='10.1073/pnas.0510928103'):\n",
    "\n",
    "    pmid_dict = {}\n",
    "    request_str = 'https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?tool=my_tool&email=my_email@example.com&ids='\n",
    "    request_str += str(doi)\n",
    "    \n",
    "    response = requests.get(request_str)\n",
    "    response_text = response.text\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        index = response_text.index('pmid=')\n",
    "\n",
    "\n",
    "        pmid_whole = response_text[index:].split(' ')[0]\n",
    "        pmid = int(pmid_whole[:-1].split('\\\"')[1])\n",
    "\n",
    "        return pmid\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "for key in tqdm(node_lookup_dict.keys()):\n",
    "    doi_dict[key] = fetch_pmid_from_doi(key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e21bf",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#It turns out that initial node ids is their PMID\n",
    "\n",
    "\n",
    "for key, value in doi_dict.items():\n",
    "    assert key == value\n",
    "    \n",
    "\n",
    "with open('first_cluster_pmid.json', 'w') as json_file:\n",
    "    json.dump(doi_dict, json_file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce168bb",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('first_cluster_pmid.json', 'r') as json_file:\n",
    "    doi_dict = json.load(json_file)\n",
    "    \n",
    "pmid_dict = doi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2af2d",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Save all xmls\n",
    "all_xmls = {}\n",
    "def save_all_xmls(pmid):\n",
    "    wait = 0.25\n",
    "    time.sleep(wait)\n",
    "    pmid_dict = {}\n",
    "    request_str  = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id='\n",
    "    request_str += str(pmid)\n",
    "    \n",
    "    response = requests.get(request_str)\n",
    "    response_text = response.text\n",
    "    \n",
    "    try:\n",
    "        xml_dict = xmltodict.parse(response_text)\n",
    "        \n",
    "    except:\n",
    "        time.sleep(2 * wait)\n",
    "        return fetch_metadata_from_pmid(pmid)\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "# for id in tqdm(pmid_dict):\n",
    "#     all_xmls[id] = save_all_xmls(id)\n",
    "\n",
    "with open('first_cluster_xmls.json', 'w') as json_file:\n",
    "    json.dump(all_xmls, json_file, indent=4)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9485977d",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load all XMLs\n",
    "import json\n",
    "\n",
    "with open('first_cluster_xmls.json', 'r') as json_file:\n",
    "    all_xmls = json.load(json_file)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29decb9",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2004/2004 [00:03<00:00, 553.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed parse 0\n",
      "Occured keyword dict: {'keyword': 19, 'grant': 139, 'mesh': 1990, 'chemicallist': 1085, 'datecompleted': 1991, 'journal': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Mispelled\n",
    "import time\n",
    "import requests\n",
    "import xmltodict\n",
    "\n",
    "parsed_error = []\n",
    "dict_of_interest = {'keyword': 0, \"grant\": 0, \"mesh\": 0, \"chemicallist\":0, 'datecompleted': 0, 'journal': 0}\n",
    "journal_title_lookup_dict = {}\n",
    "\n",
    "def fetch_metadata_from_pmid(response_text, idx, pmid): \n",
    "    global dict_of_interest\n",
    "    mesh_headings = []\n",
    "    grants = []\n",
    "    year = \"\"\n",
    "    journal_ISSN = \"\"\n",
    "    abstract = \"\"\n",
    "    chemical_list = []\n",
    "    meta_data = {}\n",
    "    pub_year = \"\"\n",
    "    \n",
    "    try:\n",
    "        xml_dict = xmltodict.parse(response_text)\n",
    "        \n",
    "        for key_of_interest in dict_of_interest.keys():\n",
    "            if key_of_interest in str(xml_dict).lower():\n",
    "\n",
    "                dict_of_interest[key_of_interest] += 1\n",
    "\n",
    "        #Date completed or revised?\n",
    "        #print(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation'].keys())\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            if 'DateCompleted' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']:\n",
    "                if 'Year' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['DateCompleted']:\n",
    "                    year = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['DateCompleted']['Year']\n",
    "\n",
    "            else:\n",
    "    #             print(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation'])\n",
    "                  pass\n",
    "    \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "        try:\n",
    "            if 'JournalIssue' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal'].keys():\n",
    "                if 'PubDate' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['JournalIssue']:\n",
    "                    if 'Year' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']:\n",
    "                        pub_year = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Year']\n",
    "                        \n",
    "            if 'ISSN' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal'].keys():\n",
    "                journal_ISSN = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['ISSN']['#text']\n",
    "                if 'Title' in  xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal'].keys():\n",
    "                    journal_title_lookup_dict[xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['Title']] = journal_ISSN\n",
    "            \n",
    "            elif 'Title' in  xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal'].keys():\n",
    "                if xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['Title'] in journal_title_lookup_dict:       \n",
    "                    journal_ISSN = journal_title_lookup_dict[xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['Title']]\n",
    "        except:\n",
    "            pass\n",
    "        #print(len(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['GrantList']['Grant']))\n",
    "        \n",
    "        \n",
    "        #Grant\n",
    "        #Very few grants don't have grant id's\n",
    "        #Grant institute could also be relevant\n",
    "        #TODO: collect missing grant id\n",
    "\n",
    "        try:\n",
    "            if 'GrantList' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']:\n",
    "                if type(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['GrantList']['Grant']) == list:\n",
    "                    for grant in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['GrantList']['Grant']:\n",
    "                        if 'GrantID' in grant:\n",
    "                            grants.append((grant['GrantID']))\n",
    "                            \n",
    "                else:\n",
    "                     grants.append(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['GrantList']['Grant']['GrantID'])\n",
    "                     pass   \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    " \n",
    "\n",
    "        #print(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['GrantList']['Grant'][0])\n",
    "        \n",
    "        #MeSH heading  \n",
    "        \n",
    "        try:\n",
    "        #print(len(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']))\n",
    "        \n",
    "            #DescriptorName? Is a term\n",
    "            if 'MeshHeadingList' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']:\n",
    "                if type(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']) == list:\n",
    "                    for mesh in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']:\n",
    "    #                 print(mesh['DescriptorName'])\n",
    "    #                 print(mesh['DescriptorName']['@UI'])\n",
    "    #                 print(mesh['DescriptorName']['#text'])\n",
    "    \n",
    "                        if '@Type' in mesh['DescriptorName'].keys() and mesh['DescriptorName']['@Type'] == 'Geographic':\n",
    "                            continue\n",
    "                \n",
    "                \n",
    "                        mesh_headings.append((mesh['DescriptorName']['@UI'], mesh['DescriptorName']['#text']))\n",
    "            \n",
    "            else:\n",
    "                mesh_headings.append(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']['DescriptorName']['@UI'],\n",
    "                                    xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']['DescriptorName']['#text'])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        try:\n",
    "        #print(len(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']))\n",
    "        \n",
    "            #DescriptorName? Is a term\n",
    "            if 'ChemicalList' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']:\n",
    "#                print(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']\n",
    "# #                      ['ChemicalList']['Chemical']['NameOfSubstance'])\n",
    "               #print(len(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['ChemicalList']['Chemical']))\n",
    "               if type(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['ChemicalList']['Chemical']) == list:\n",
    "                   for substance in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['ChemicalList']['Chemical']:\n",
    "                            chemical_list.append(substance['NameOfSubstance']['@UI'])\n",
    "                        \n",
    "               else:\n",
    "                   chemical_list.append(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['ChemicalList']['Chemical']['NameOfSubstance']['@UI'])\n",
    "                #print(chemical_list)\n",
    "                \n",
    "               \n",
    "              \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "        #References and history\n",
    "        #print(xml_dict['PubmedArticleSet']['PubmedArticle']['PubmedData'].keys())\n",
    "\n",
    "\n",
    "    except:\n",
    "        parsed_error.append(idx)\n",
    "        pass\n",
    "\n",
    "\n",
    "    if len(year) == 0:\n",
    "        year = pub_year\n",
    "        \n",
    "    meta_data = {'mesh': mesh_headings, 'grants': grants, 'year': year, 'journal': journal_ISSN, 'chemical' : chemical_list} \n",
    "        \n",
    "    return meta_data\n",
    "\n",
    "metadata_dict = {}\n",
    "\n",
    "# [166, 719, 1672, 1918] odd\n",
    "\n",
    "idx = 0\n",
    "for key, value in tqdm(all_xmls.items()):\n",
    "    metadata_dict[key] = fetch_metadata_from_pmid(value, idx, key)\n",
    "    idx += 1\n",
    "    \n",
    "\n",
    "\n",
    "print(f'failed parse {len(parsed_error)}')\n",
    "print(f'Occured keyword dict: {dict_of_interest}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c2472e",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocurred features  {'mesh': 1982, 'grants': 136, 'year': 1993, 'journal': 1960, 'chemical': 1085}\n",
      "avg mesh length  9.433400605449041\n",
      "avg chemical length  3.3788018433179725\n"
     ]
    }
   ],
   "source": [
    "#### Count incomplete data\n",
    "\n",
    "features = {'mesh': 0, 'grants': 0, 'year': 0, 'journal': 0, 'chemical' : 0, 'journal': 0}\n",
    "#Mesh terms are sometimes unrelated\n",
    "\n",
    "mesh_length = []\n",
    "chemical_length = []\n",
    "\n",
    "for feature in features.keys():\n",
    "    for _, meta in metadata_dict.items():\n",
    "        if len(meta[feature]) > 0:\n",
    "            features[feature] += 1\n",
    "            if feature == 'mesh':\n",
    "                mesh_length.append(len(meta[feature]))\n",
    "            \n",
    "            elif feature == 'chemical':\n",
    "                chemical_length.append(len(meta[feature]))\n",
    "                \n",
    "            \n",
    "print(\"Ocurred features \", features)\n",
    "print(\"avg mesh length \", np.mean(mesh_length))\n",
    "print(\"avg chemical length \", np.mean(chemical_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0c402",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('first_cluster_metadata.json', 'w') as json_file:\n",
    "    json.dump(metadata_dict, json_file, indent=4)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93b161bb",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the metadata file\n",
    "with open('first_cluster_metadata.json', 'r') as json_file:\n",
    "    metadata_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab9512e5",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_dict_similarity(dict_1, dict_2, mode ): \n",
    "    similarity = 0\n",
    "    modes = ['number_of_common_terms', 'jaccard']\n",
    "    \n",
    "    assert mode in modes\n",
    "    \n",
    "    for key in dict_1:\n",
    "            if key in dict_2:\n",
    "                similarity += 1\n",
    "                \n",
    "    \n",
    "    if mode == 'number_of_common_terms':\n",
    "        pass\n",
    "       \n",
    "    elif mode == 'jaccard':\n",
    "        similarity = similarity / (len(dict_1) + len(dict_2))\n",
    "        \n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a17bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metadata_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec54f8d",
   "metadata": {},
   "source": [
    "<h1>Checking for same grants</h1> <p> Let's simply record number of same grants</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f28cb52",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def grant_similarity(pmid_1, pmid_2):\n",
    "    grants_1 = metadata_dict[pmid_1]['grants']\n",
    "    grants_2 = metadata_dict[pmid_2]['grants']\n",
    "    \n",
    "\n",
    "                \n",
    "    return common_grants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08a7e782",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate similarity between two pmid's\n",
    "#Lets call it metric for now. This is unnormalized\n",
    "def calculate_similarity(pmid1, pmid2, feature):\n",
    "    \n",
    "    metric = 0\n",
    "    pmid1 = str(pmid1)\n",
    "    pmid2 = str(pmid2)\n",
    "    \n",
    "    assert feature in ['year', 'mesh', 'chemical', 'co-citation', 'bib-coupling', 'grants']\n",
    "    if feature == 'year':             \n",
    "                year1 = metadata_dict[pmid1][feature]\n",
    "                year2 = metadata_dict[pmid2][feature]\n",
    "                \n",
    "                if len(year1) > 0 and len(year2)>0:\n",
    "                    metric = np.abs(int(year1)-int(year2))\n",
    "                \n",
    "                else:\n",
    "                    metric = -1\n",
    "    \n",
    "    \n",
    "    #They are both treated the same way ...\n",
    "    elif feature == 'mesh' or feature == 'chemical':\n",
    "        common_terms = 0\n",
    "        terms_1 = {}\n",
    "        terms_2 = {}\n",
    "        \n",
    "        for term in metadata_dict[pmid1][feature]:\n",
    "            terms_1[term[0]] = 1\n",
    "    \n",
    "        for term in metadata_dict[pmid2][feature]:\n",
    "            terms_2[term[0]] = 1\n",
    "        \n",
    "        if len(terms_1) > 0 and len(terms_2)>0:\n",
    "            metric = calculate_dict_similarity(terms_1, terms_2, 'jaccard')\n",
    "                    \n",
    "        else:\n",
    "            metric = -1\n",
    "            \n",
    "    elif feature == 'bib-coupling':\n",
    "        node_1 = node_lookup_dict[pmid1]\n",
    "        node_2 = node_lookup_dict[pmid2]\n",
    "        \n",
    "        common = np.dot(adj_matrix[node_1,:], adj_matrix[node_2, :])\n",
    "        denom = np.sum(adj_matrix[node_1, :]) + np.sum(adj_matrix[node_2, :]) - common\n",
    "        \n",
    "        if denom > 0 :\n",
    "            metric = common / denom\n",
    "        \n",
    "    \n",
    "    elif feature == 'co-citation':\n",
    "        node_1 = node_lookup_dict[pmid1]\n",
    "        node_2 = node_lookup_dict[pmid2]\n",
    "        \n",
    "        common = np.dot(adj_matrix[: , node_1], adj_matrix[: , node_2])\n",
    "        denom = np.sum(adj_matrix[:, node_1]) + np.sum(adj_matrix[:, node_2]) - common\n",
    "        \n",
    "        if denom > 0 :\n",
    "            metric = common / denom\n",
    "            \n",
    "    \n",
    "    elif feature == 'grants':\n",
    "        grants_1 = metadata_dict[pmid1]['grants']\n",
    "        grants_2 = metadata_dict[pmid2]['grants']\n",
    "       \n",
    "        \n",
    "        for first in grants_1:\n",
    "            for second in grants_2:\n",
    "                if first[0] == second[0]:\n",
    "                    metric +=1\n",
    "                    \n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c8c7268",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_three_hop_similarity():\n",
    "    #Is currently inefficient as relies on matrix multiplication\n",
    "    # We use undirected edges\n",
    "    aggregated_three_hop_similarity = np.zeros_like(adj_matrix)\n",
    "    undirected_adj_matrix = adj_matrix + adj_matrix.transpose()\n",
    "    second_hop_distance = np.matmul(undirected_adj_matrix, undirected_adj_matrix)\n",
    "    \n",
    "    three_hop_distance = np.matmul(second_hop_distance, undirected_adj_matrix)\n",
    "    \n",
    "    for i in range(adj_matrix.shape[0]):\n",
    "        for j in range(i):\n",
    "            similarity = 0\n",
    "            if undirected_adj_matrix[i][j] == 1:\n",
    "                similarity = 1\n",
    "            \n",
    "            elif second_hop_distance[i][j] > 0:\n",
    "                similarity = 2/3\n",
    "            \n",
    "            elif three_hop_distance[i][j] > 0:\n",
    "                similarity = 1/3\n",
    "            \n",
    "            aggregated_three_hop_similarity[i][j] = similarity\n",
    "    \n",
    "    aggregated_three_hop_similarity = aggregated_three_hop_similarity + aggregated_three_hop_similarity.transpose()\n",
    "    return aggregated_three_hop_similarity\n",
    "\n",
    "aggregated_three_hop_similarity = calculate_three_hop_similarity()\n",
    "np.save('aggregated_three_hop_similarity.npy', aggregated_three_hop_similarity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3748c102",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh terms with one entires 0\n",
      "Mesh terms with two entires 18697\n",
      "Example of a mesh: ['D015046', 'Zoology']\n"
     ]
    }
   ],
   "source": [
    "#all mesh terms are tuples, so we use UI's as they are standard\n",
    "\n",
    "ones = 0\n",
    "twos = 0\n",
    "\n",
    "for key, value in metadata_dict.items():\n",
    "    if len(value['mesh']) >0:\n",
    "        for mesh in value['mesh']:\n",
    "            if len(mesh) == 1:\n",
    "                ones += 1\n",
    "            \n",
    "            elif len(mesh) == 2:\n",
    "                twos += 1\n",
    "            \n",
    "            else:\n",
    "                raise 'error'\n",
    "            \n",
    "print(f'Mesh terms with one entires {ones}')\n",
    "print(f'Mesh terms with two entires {twos}')\n",
    "print(f'Example of a mesh: {mesh}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bae28d79",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2004/2004 [00:34<00:00, 57.82it/s] \n",
      "100%|██████████| 2004/2004 [01:27<00:00, 22.97it/s]\n",
      "100%|██████████| 2004/2004 [00:03<00:00, 549.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def report_stats(vals, title):\n",
    "    filtered_val = []\n",
    "    for val in vals:\n",
    "        if val != -1:\n",
    "            filtered_val.append(val)\n",
    "            \n",
    "    median = np.median(filtered_val)\n",
    "    mean = np.mean(filtered_val)\n",
    "    min = np.amin(filtered_val)\n",
    "    max = np.amax(filtered_val)\n",
    "    total = np.sum(filtered_val)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "#     fig.suptitle('bold figure suptitle', fontsize=14, fontweight='bold')\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.boxplot(vals)\n",
    "    \n",
    "    labels = [title]\n",
    "\n",
    "    ax.set_xticklabels(labels)\n",
    "\n",
    "    ax.set_title(f'{title}  boxplot diagram')\n",
    "#     ax.set_xlabel(f'{title}')\n",
    "    ax.set_ylabel('Values')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print(f'median {median} mean {mean} min {min} max {max}')\n",
    "\n",
    "    \n",
    "\n",
    "def calculate_similarity_matrix(feature):\n",
    "    similarity_matrix = np.zeros((len(nodes_array), len(nodes_array))) \n",
    "    \n",
    "    for i in tqdm(range(similarity_matrix.shape[0])):\n",
    "        for j in range(i):\n",
    "            pmid1 = str(nodes_array[i])\n",
    "            pmid2 = str(nodes_array[j])            \n",
    "            similarity_matrix[i][j] = calculate_similarity(pmid1, pmid2, feature)\n",
    "        \n",
    "    similarity_matrix = similarity_matrix + similarity_matrix.transpose()\n",
    "    \n",
    "    #Year is the only feature that is initially distance and needs to be similarity\n",
    "    if feature == 'year':\n",
    "        similarity_matrix = np.ones_like(similarity_matrix) - similarity_matrix/np.amax(similarity_matrix)\n",
    "        similarity_matrix = np.where(similarity_matrix > 1, -1, similarity_matrix)\n",
    "        \n",
    "    return similarity_matrix\n",
    "\n",
    "# year_similarity_matrix = calculate_similarity_matrix('year')\n",
    "# np.save('year_similarity_matrix.npy', year_similarity_matrix)\n",
    "\n",
    "# mesh_similarity_matrix = calculate_similarity_matrix('mesh')\n",
    "# np.save('mesh_similarity_matrix.npy', mesh_similarity_matrix)\n",
    "\n",
    "\n",
    "bib_coupling_similarity_matrix = calculate_similarity_matrix('bib-coupling')\n",
    "np.save('bib_coupling_similarity_matrix.npy', bib_coupling_similarity_matrix)\n",
    "\n",
    "\n",
    "\n",
    "cocitation_similarity_matrix = calculate_similarity_matrix('co-citation')\n",
    "np.save('cocitation_similarity_matrix.npy', cocitation_similarity_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# chemical_similarity_matrix = calculate_similarity_matrix('chemical')\n",
    "# np.save('chemical_similarity_matrix.npy', chemical_similarity_matrix)\n",
    "\n",
    "\n",
    "grants_similarity_matrix = calculate_similarity_matrix('grants')\n",
    "np.save('grants_similarity_matrix.npy', grants_similarity_matrix)\n",
    "\n",
    "print(np.mean(grants_similarity_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad8626da",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cocitation_matrix = np.load('cocitation_matrix.npy')\n",
    "bib_coupling_matrix = np.load('bib_coupling_matrix.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cad3cec",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAGrCAYAAACWp3C3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeEElEQVR4nO3deZRlZ13v4e/vJgwikAAJIQPQKEFvFBksmbwgyswVwzwphMnAvbJAASXKQiKDgsoFmeSGMQJCGCUyhcmAIIZ0wiABQkK4rCQEaJIwhDCF/O4fZ7eeVKq6qpOuPv2mn2etXnXO3u/e+z1V1as/vfcZqrsDAMAY/tuiJwAAwPqJNwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDdgp6qq91bVYZdx25dX1dOn23esqrMuxzx+t6ref1m3X2Pfj6iqj23EvrdxzE1V1VW15wbt/7VV9ezp9u2r6tSNOA6wtg35Sw6Mr6o2JflKkit190U7ar/dfY/Lse3jduA83pDkDVvvV1UnObi7T99Rx9hVVdWRSW7c3b93Wbbv7n9N8gs7dFLAujnzBldQG3UG5orA92bXVDP+XYI1+EsCA6mqW1bVp6rqe1X1lqo6Zu5S1h2r6qyqempVfT3Ja6rqWlX1rqraUlXnT7cPmtvf8VX1rKr6+LTP91fVPtPqj05fv11VF1TVbavqxlX1kar6TlV9q6qOWWWeV62q11fVuVX17ao6sar2mzvmY6bbj5iO/YJp3BlVdbtp+ZlV9c35S6zzl+5WOOYRVfXl6XF8vqruM7du/jjnJjly/tJmVW19rJ+ZHuuDqupzVXWvuX1caXrMt1j/j6teMn2vvlhVd5pbcUBVHVtV51XV6VX1+9Pyn5+W3XJu3JaquuPc9+6vquqTVfXdqnpnVV17lYOvdoy7J/mzJA+aHutnVtn+FlV18vT9PCbJVefWXeKS9Rrf+z2q6vnT9+4rVfX4mru8Oz2m51TVx5NcmOTnquqRVfWFaX9nVNVjlx+7qv5k+v04p6ruXVX3rKovTY/3z9b5M4IhiTcYRFVdOck7krw2ybWTvDHJfZYNu9607oZJDs/s7/hrpvs3SPKDJC9Zts1DkzwyyXWTXDnJU6bld5i+7t3dV+/uTyR5VpL3J7lWkoOSvHiV6R6WZK8k109ynSSPm469klsn+ew07h+TvCnJryW5cZLfS/KSqrr6KtvO+3KS20/H/Yskr6+q/Zcd54wk+yV5zvyG3b31sd5seqzHJPmH6fhb3TPJOd39qXXMZevxvpxknyTPSPL2udB6U5KzkhyQ5P5J/rKqfqu7v5zkqdPcr5bZz+7o7j5+br8PT/KoJPsnuSjJi1Y5/mrHeF+Sv0xyzPRYb7Z8w+l37Z+SvC6z36e3JLnfNh7rtr73v5/kHklunuSWSe69wvYPy+z39RpJvprkm0l+O8k1M/vdfMHWoJ1cL7OYPDDJnyd5RWY/q1+d5vH0qrrRNuYLQxNvMI7bZPY81Rd190+6++1JPrlszMVJntHdP+ruH3T3ud39tu6+sLu/l1m0/MaybV7T3V/q7h8keXNm/8iu5ieZheAB3f3D7l7tSfk/ySzGbtzdP+3uk7r7u6uM/Up3v6a7f5rkmMyC75nTY3h/kh9nFnLb1N1v6e6vdffFU3ydluRWc0O+1t0v7u6Lpse6ltcnuWdVXXO6/7DMYma9vpnkhdPP6pgkpyb5n1V1/SS/nuSp0/fw00lemVmUpbtfkeT0JCdkFmhPW7bf13X357r7+0menuSBVbXH/IC1jrEOt0lypbn5vzXJiasNXuN7/8Akf9fdZ3X3+Umeu8IuXtvdp0w/m59097u7+8s985HM/sNw+7nxP0nynO7+SWaRus90jO919ylJPp/kUlEKVxTiDcZxQJKzu7vnlp25bMyW7v7h1jtVdbWq+r9V9dWq+m5ml0L3XvaP/dfnbl+YZFtnuf4kSSX5ZFWdUlWPWmXc65Icl+RNVfW1qvrrqrrSKmO/MXf7B0nS3cuXrXnmraoeXlWfni6/fjvJL2f2j/pWy79X29TdX0vy8ST3q6q9Mzt79IZtbnRJy39WX83sZ3hAkvOmmJ5fd+Dc/VdkNv8Xd/ePlu13/nF8NbPI2mfZmPUcY1tW+l376mqD1/jeH7Bsziv9HC6xrKruUVX/Pl0C/XZmZz3nH+O5U+wn/3VGd7t/Z2BU4g3GcU6SA6uq5pZdf9mYXnb/yZm9KvDW3X3N/Nel0Mralu8r3f317v797j4gyWOTvKyqLnVWbDp78hfdfUiS22V2CWy9Z322W1XdMLPgeXyS63T33kk+l0s+zks9nnU4OrPLcQ9I8onuPns7tl3+s7pBkq9Nf65dVddYtu7sJJkuEb8wyasye27e8ue0XX/Zdj9J8q1lY7Z5jKz9vVjpd+0GKw1cx/f+nMwusa80/63+cz5VdZUkb0vyt0n2m/b3nqzvdxZ2C+INxvGJJD9N8viq2rOqDs0lLwuu5BqZnYX49hQBz9iO423J7DLsz21dUFUPqP96wcP5mf2je/HyDavqN6vqptMZvu9mFhiXGrcD/ew0ly3T8R+Z2dmf7fGNzD3WyT9l9jytJ2b2HLjtcd0kT6jZCx0ekOS/J3lPd5+Z5N+S/FXNXtjxK0kendll2iT5uySbu/sxSd6d5OXL9vt7VXXI9Jy4ZyZ569xZqCTJOo7xjSSbavVXdn4is+fTbZ3/fbP679pa3/s3J3liVR04ncF86ir72erKSa4y7e+iqrpHkruusQ3sVsQbDKK7f5zkvpn9I/ztzM4IvSvJ8stq816Y5GcyOzPz70netx3HuzCz58h9fLocdpvMXkhwQlVdkOTYJE/s7jNW2Px6Sd6aWbh9IclHsn3PF9su3f35JM/PLDq+keSmmV3y3B5HJjl6eqwPnPb7g8zOAt0oydu3c38nJDk4s+/9c5Lcv7vPndY9JMmmzM6QvSOz5yl+cAryuyf5X9O4JyW5ZVX97tx+X5fZi1a+ntmT9p+wyvFXPMa07i3T13Or6uTlG879rj0iyXlJHpRVHv86vvevyOw5a59N8qnMzqJdlNl/RFba3/emx/TmzP6D8NDMfteASV3yKQ3ASKrqhCQv7+7XLHouV1RV9edJbnJZ39B2B8/l+CSv7+5XLnoul9V0Ju3l3X3DRc8FRuXMGwykqn6jqq43XTY9LMmvZDvOprF9pkvNj05y1KLnMqqq+pnpPdj2rKoDM7t0/45FzwtGJt5gLL+Q5DOZXTZ9cmaX4s5Z6IyuoGr2prZnJnlvd390rfGsqjJ777fzM7ts+oXM3psNuIxcNgUAGIgzbwAAA9mtPpx5n3326U2bNi16GgAAazrppJO+1d37Ll++W8Xbpk2bsnnz5kVPAwBgTVW14iebuGwKADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMBDxBgAwEPEGADAQ8QYAMJCFxltV3b2qTq2q06vqiBXWX6WqjpnWn1BVm5atv0FVXVBVT9lpkwYAWKCFxVtV7ZHkpUnukeSQJA+pqkOWDXt0kvO7+8ZJXpDkecvW/58k793ouQIA7CoWeebtVklO7+4zuvvHSd6U5NBlYw5NcvR0+61J7lRVlSRVde8kX0lyys6ZLgDA4i0y3g5Mcubc/bOmZSuO6e6LknwnyXWq6upJnprkL9Y6SFUdXlWbq2rzli1bdsjEAQAWZdQXLByZ5AXdfcFaA7v7qO5e6u6lfffdd+NnBgCwgfZc4LHPTnL9ufsHTctWGnNWVe2ZZK8k5ya5dZL7V9VfJ9k7ycVV9cPufsmGzxoAYIEWGW8nJjm4qm6UWaQ9OMlDl405NslhST6R5P5JPtzdneT2WwdU1ZFJLhBuAMDuYGHx1t0XVdXjkxyXZI8kr+7uU6rqmUk2d/exSV6V5HVVdXqS8zILPACA3VbNTmTtHpaWlnrz5s2LngYAwJqq6qTuXlq+fNQXLAAA7JbEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAFhpvVXX3qjq1qk6vqiNWWH+VqjpmWn9CVW2alt+lqk6qqv+Yvv7WTp88AMACLCzeqmqPJC9Nco8khyR5SFUdsmzYo5Oc3903TvKCJM+bln8ryb26+6ZJDkvyup0zawCAxVrkmbdbJTm9u8/o7h8neVOSQ5eNOTTJ0dPttya5U1VVd3+qu782LT8lyc9U1VV2yqwBABZokfF2YJIz5+6fNS1bcUx3X5TkO0mus2zM/ZKc3N0/WukgVXV4VW2uqs1btmzZIRMHAFiUoV+wUFW/lNml1MeuNqa7j+rupe5e2nfffXfe5AAANsAi4+3sJNefu3/QtGzFMVW1Z5K9kpw73T8oyTuSPLy7v7zhswUA2AUsMt5OTHJwVd2oqq6c5MFJjl025tjMXpCQJPdP8uHu7qraO8m7kxzR3R/fWRMGAFi0hcXb9By2xyc5LskXkry5u0+pqmdW1e9Mw16V5DpVdXqSJyXZ+nYij09y4yR/XlWfnv5cdyc/BACAna66e9Fz2GmWlpZ68+bNi54GAMCaquqk7l5avnzoFywAAOxuxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBAxBsAwEDWjLeq+tmq+m/T7ZtU1e9U1ZU2fmoAACy3njNvH01y1ao6MMn7kzwsyWs3clIAAKxsPfFW3X1hkvsmeVl3PyDJL23stAAAWMm64q2qbpvkd5O8e1q2x8ZNCQCA1awn3v4wyZ8meUd3n1JVP5fkXzZ0VgAArGjPtQZ090eSfKSqrjbdPyPJEzZ6YgAAXNp6Xm1626r6fJIvTvdvVlUv2/CZAQBwKeu5bPrCJHdLcm6SdPdnktxhA+cEAMAq1vUmvd195rJFP92AuQAAsIY1n/OW5Myqul2Snt6c94lJvrCx0wIAYCXrOfP2uCR/kOTAJGcnufl0/3KrqrtX1alVdXpVHbHC+qtU1THT+hOqatPcuj+dlp9aVXfbEfMBANjVrefVpt/K7D3edqiq2iPJS5PcJclZSU6sqmO7+/Nzwx6d5PzuvnFVPTjJ85I8qKoOSfLgzN4s+IAkH6yqm3S3y7kAwBXamvFWVa9J0suXd/ejLuexb5Xk9OmtR1JVb0pyaJL5eDs0yZHT7bcmeUlV1bT8Td39oyRfqarTp/194nLOCQBgl7ae57y9a+72VZPcJ8nXdsCxD0wy/0KIs5LcerUx3X1RVX0nyXWm5f++bNsDd8CcAAB2aeu5bPq2+ftV9cYkH9uwGe1gVXV4ksOT5AY3uMGCZwNslyP3WvQMrniO/M6iZwBcTus587bcwUmuuwOOfXaS68/dP2hattKYs6pqzyR7ZfZ+c+vZNknS3UclOSpJlpaWLnX5F9iFCQ2AS1nPJyx8r6q+u/Vrkn9O8tQdcOwTkxxcVTeqqitn9gKEY5eNOTbJYdPt+yf5cHf3tPzB06tRb5RZUH5yB8wJAGCXtp7LptfYiANPz2F7fJLjkuyR5NXTB98/M8nm7j42yauSvG56QcJ5mQVepnFvzuzFDRcl+QOvNAUAdgc1O5G1woqqW25rw+4+eUNmtIGWlpZ68+bNi54GAMCaquqk7l5avnxbZ96ev411neS3LvesAADYLqvGW3f/5s6cCAAAa1vXq02r6peTHJLZ+7wlSbr7HzZqUgAArGw9n7DwjCR3zCze3pPkHpm9z5t4AwDYydbzwfT3T3KnJF/v7kcmuVlm77cGAMBOtp54+2F3X5zkoqq6ZpJv5pJvkAsAwE6y6mXTqnppkjcm+WRV7Z3kFUlOSnJBfAA8AMBCbOs5b19K8jdJDkjy/cxC7i5Jrtndn90JcwMAYJlVL5t29991922T3CGzzxN9dZL3JblPVR28k+YHAMCcNZ/z1t1f7e7ndfctkjwkyb2TfHGjJwYAwKWt54Pp96yqe1XVG5K8N8mpSe674TMDAOBStvWChbtkdqbtnkk+meRNSQ7v7u/vpLkBALDMtl6w8KdJ/jHJk7v7/J00HwAAtmFbn23qg+cBAHYx63mTXgAAdhHiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIAuJt6q6dlV9oKpOm75ea5Vxh01jTquqw6ZlV6uqd1fVF6vqlKp67s6dPQDA4izqzNsRST7U3Qcn+dB0/xKq6tpJnpHk1kluleQZc5H3t939i0lukeTXq+oeO2faAACLtah4OzTJ0dPto5Pce4Uxd0vyge4+r7vPT/KBJHfv7gu7+1+SpLt/nOTkJAdt/JQBABZvUfG2X3efM93+epL9VhhzYJIz5+6fNS37T1W1d5J7ZXb2bkVVdXhVba6qzVu2bLlckwYAWLQ9N2rHVfXBJNdbYdXT5u90d1dVX4b975nkjUle1N1nrDauu49KclSSLC0tbfdxAAB2JRsWb91959XWVdU3qmr/7j6nqvZP8s0Vhp2d5I5z9w9Kcvzc/aOSnNbdL7z8swUAGMOiLpsem+Sw6fZhSd65wpjjkty1qq41vVDhrtOyVNWzk+yV5A83fqoAALuORcXbc5PcpapOS3Ln6X6qaqmqXpkk3X1ekmclOXH688zuPq+qDsrs0ushSU6uqk9X1WMW8SAAAHa26t59nga2tLTUmzdvXvQ0AADWVFUndffS8uU+YQEAYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAg4g0AYCDiDQBgIOINAGAgC4m3qrp2VX2gqk6bvl5rlXGHTWNOq6rDVlh/bFV9buNnDACwa1jUmbcjknyouw9O8qHp/iVU1bWTPCPJrZPcKskz5iOvqu6b5IKdM10AgF3DouLt0CRHT7ePTnLvFcbcLckHuvu87j4/yQeS3D1JqurqSZ6U5NkbP1UAgF3HouJtv+4+Z7r99ST7rTDmwCRnzt0/a1qWJM9K8vwkF651oKo6vKo2V9XmLVu2XI4pAwAs3p4bteOq+mCS662w6mnzd7q7q6q3Y783T/Lz3f1HVbVprfHdfVSSo5JkaWlp3ccBANgVbVi8dfedV1tXVd+oqv27+5yq2j/JN1cYdnaSO87dPyjJ8Ulum2Spqv5fZvO/blUd3913DADAFdyiLpsem2Trq0cPS/LOFcYcl+SuVXWt6YUKd01yXHf/fXcf0N2bkvyPJF8SbgDA7mJR8fbcJHepqtOS3Hm6n6paqqpXJkl3n5fZc9tOnP48c1oGALDbqu7d52lgS0tLvXnz5kVPAwBgTVV1UncvLV/uExYAAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAYi3gAABiLeAAAGIt4AAAZS3b3oOew0VbUlyVcXPQ/gCmefJN9a9CSAK5wbdve+yxfuVvEGsBGqanN3Ly16HsDuwWVTAICBiDcAgIGIN4DL76hFTwDYfXjOGwDAQJx5AwAYiHgDABiIeAN2W1W1d1X97x2wn8dV1cO3c5t/m75uqqrPXYZjzm//0O3dHhiXeAOuEKpqz8uw2d5JLne8dffLu/sftnOb212WY219nHPbb0oi3mA3It6AXV5VPb2qTq2qj1XVG6vqKdPy46vqhVW1OckTq+peVXVCVX2qqj5YVftN446sqldP48+oqidMu35ukp+vqk9X1d9U1f5V9dHp/ueq6vYrzOW5VfX5qvpsVf3t3P7n5/SCqtpcVV+oql+rqrdX1WlV9ey5/Vywwr43VdW/VtXJ05/bTcvvOC0/Nsnnl23/3CS3n+b8R9P8bz63z49V1c0u548A2IVclv+pAuw0VfVrSe6X5GZJrpTk5CQnzQ258tZPN6iqayW5TXd3VT0myZ8kefI07heT/GaSayQ5tar+PskRSX65u28+bf/kJMd193Oqao8kV1s2l+skuU+SX5yOsfcq0/5xdy9V1ROTvDPJryY5L8mXq+oF3X3uKtt9M8lduvuHVXVwkjcm2frJDbec5vqVZdsckeQp3f3b0xzPS/KIJH9YVTdJctXu/swqxwMGJN6AXd2vJ3lnd/8wyQ+r6p+XrT9m7vZBSY6pqv2TXDnJfOi8u7t/lORHVfXNJPutcKwTk7y6qq6U5J+6+9PL1n8nyQ+TvKqq3pXkXavM+djp638kOaW7z0mSqjojyfWTrBZvV0rykunM2U+T3GRu3SdXCLeVvCXJ06vqj5M8Kslr17ENMBCXTYHRfX/u9ouTvKS7b5rksUmuOrfuR3O3f5oV/vPa3R9NcockZyd57fIXIXT3RUluleStSX47yftWmdPWY1287LgXr3TcOX+U5BuZnWVcyixAt/r+iltc+jFcmOQDSQ5N8sAkb1jPdsA4xBuwq/t4kntV1VWr6uqZRdNq9sosvJLksHXs+3uZXUZNklTVDZN8o7tfkeSVmV2qzNz6qyfZq7vfk1lo7ejnku2V5JzuvjjJw5LssY5tLvEYJq9M8qIkJ3b3+Tt2isCiuWwK7NK6+8Tpifqfzeys1H9kdvlyJUcmeUtVnZ/kw0lutMa+z62qj09v1fHeJJ9L8sdV9ZMkFyRZ/vYf10jyzqq6apJK8qTL9qhW9bIkb5vO+L0v6zvb9tkkP62qzyR5bXe/oLtPqqrvJnnNDp4fsAvw8VjALq+qrt7dF1TV1ZJ8NMnh3X3youe1q6qqA5Icn9kLKy5e8HSAHcxlU2AER1XVpzN7penbhNvqprN2JyR5mnCDKyZn3gAABuLMGwDAQMQbAMBAxBsAwEDEGwDAQMQbAMBA/j+dtk3BAdQguQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median 0.0 mean 0.0 min 0.0 max 0.0\n"
     ]
    }
   ],
   "source": [
    "#Assuming a square matrix, report statistics\n",
    "def report_matrix_stats(matrix, title):\n",
    "    n = matrix.shape[0]\n",
    "    all_values = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            #Remove negatives as they are flags\n",
    "            if matrix[i][j] > -1:\n",
    "                all_values.append(matrix[i][j])\n",
    "    \n",
    "    report_stats(all_values, title)\n",
    "    \n",
    "    \n",
    "# report_matrix_stats(year_similarity_matrix, 'year')\n",
    "# report_matrix_stats(mesh_similarity_matrix, 'jaccard mesh similarity')\n",
    "# report_matrix_stats(chemical_similarity_matrix, 'jaccard chemical similarity')\n",
    "# report_matrix_stats(cocitation_similarity_matrix, 'jaccard co-citation similarity')\n",
    "# report_matrix_stats(bib_coupling_similarity_matrix, 'jaccard bib-coupling similarity')\n",
    "# report_matrix_stats(aggregated_three_hop_similarity, 'aggregated three hop similarity')\n",
    "report_matrix_stats(grants_similarity_matrix, 'grants similarity')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9db9a7ed",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[['AI-23939', 'NIAID NIH HHS'], ['AI-28412', 'NIAID NIH HHS'], ['HL-44275', 'NHLBI NIH HHS']]\n",
      "[['AI 27054', 'NIAID NIH HHS'], ['CA 11198', 'NCI NIH HHS']]\n",
      "[['HL 35389', 'NHLBI NIH HHS'], ['R01 HL 42075', 'NHLBI NIH HHS']]\n",
      "[['AI27713', 'NIAID NIH HHS'], ['GM08296', 'NIGMS NIH HHS']]\n",
      "[['AR 34313', 'NIAMS NIH HHS'], ['BRSG S07', 'DRS NIH HHS'], ['RR 05410', 'NCRR NIH HHS']]\n",
      "[['5-T32-HL-07284', 'NHLBI NIH HHS'], ['R01-HL-37942', 'NHLBI NIH HHS']]\n",
      "[['AM32634', 'NIADDK NIH HHS'], ['NS14627', 'NINDS NIH HHS'], ['NS21647', 'NINDS NIH HHS']]\n",
      "[['HL-01205', 'NHLBI NIH HHS'], ['HL-19187', 'NHLBI NIH HHS'], ['MCH-000955', 'PHS HHS']]\n",
      "[['CA37645', 'NCI NIH HHS'], ['T32 AI-07272', 'NIAID NIH HHS']]\n",
      "[['HD-13938', 'NICHD NIH HHS'], ['HD-19302', 'NICHD NIH HHS']]\n",
      "[['DK-51610', 'NIDDK NIH HHS'], ['NS-30591', 'NINDS NIH HHS']]\n",
      "[['DE07158', 'NIDCR NIH HHS'], ['NS-18773', 'NINDS NIH HHS']]\n",
      "[['HL-21584', 'NHLBI NIH HHS'], ['HL-30937', 'NHLBI NIH HHS']]\n",
      "[['AM 17989', 'NIADDK NIH HHS'], ['GM 29198', 'NIGMS NIH HHS']]\n",
      "[['CA 37082', 'NCI NIH HHS'], ['CA 37209', 'NCI NIH HHS']]\n",
      "[['2PO-1AG02478', 'NIA NIH HHS'], ['P50AG05131', 'NIA NIH HHS']]\n",
      "[['HL-17669', 'NHLBI NIH HHS'], ['HL-30570', 'NHLBI NIH HHS']]\n",
      "[['AI-21504', 'NIAID NIH HHS'], ['AM-35108', 'NIADDK NIH HHS'], ['GM-17702', 'NIGMS NIH HHS']]\n",
      "[['1R01MH41766-01', 'NIMH NIH HHS'], ['R01 AG06584-01', 'NIA NIH HHS']]\n",
      "[['AM-12829', 'NIADDK NIH HHS'], ['AM-17047', 'NIADDK NIH HHS']]\n",
      "[['CA 16853', 'NCI NIH HHS'], ['HD 05515', 'NICHD NIH HHS'], ['NS 10437', 'NINDS NIH HHS']]\n",
      "[['AM-16667', 'NIADDK NIH HHS'], ['HL-14197', 'NHLBI NIH HHS'], ['HL-29252', 'NHLBI NIH HHS']]\n",
      "[['55M01RR0095', 'NCRR NIH HHS'], ['AM 2665705', 'NIADDK NIH HHS']]\n",
      "[['GM-20784', 'NIGMS NIH HHS'], ['K6-GM-442', 'NIGMS NIH HHS']]\n",
      "[['DA 00458', 'NIDA NIH HHS'], ['DA 07254', 'NIDA NIH HHS'], ['DA 08863', 'NIDA NIH HHS']]\n",
      "[['AM07178-01', 'NIADDK NIH HHS'], ['AM25998-05', 'NIADDK NIH HHS']]\n",
      "[['AI 14148', 'NIAID NIH HHS'], ['HD 11844', 'NICHD NIH HHS']]\n",
      "[['CA 09351', 'NCI NIH HHS'], ['CA 13539', 'NCI NIH HHS'], ['CA 18029', 'NCI NIH HHS']]\n",
      "[['ES-01599', 'NIEHS NIH HHS'], ['HL-19129', 'NHLBI NIH HHS']]\n",
      "[['PHS 14212', 'PHPPO CDC HHS'], ['R01 HL 39469', 'NHLBI NIH HHS']]\n",
      "[['DK 36836', 'NIDDK NIH HHS'], ['DK33201', 'NIDDK NIH HHS'], ['DK43808', 'NIDDK NIH HHS']]\n",
      "[['AI13544', 'NIAID NIH HHS'], ['GM33928', 'NIGMS NIH HHS'], ['R01 GM033928-22', 'NIGMS NIH HHS'], ['R01 GM062723-30', 'NIGMS NIH HHS']]\n",
      "[['F32 DC000480', 'NIDCD NIH HHS'], ['R01 HD033402', 'NICHD NIH HHS'], ['DC00480', 'NIDCD NIH HHS']]\n",
      "[['DC-01140', 'NIDCD NIH HHS'], ['NS-24778', 'NINDS NIH HHS'], ['NS-26656', 'NINDS NIH HHS']]\n",
      "[['AI-24838', 'NIAID NIH HHS'], ['HD-18661', 'NICHD NIH HHS'], ['K08HL-02253-01', 'NHLBI NIH HHS']]\n",
      "[['AG0096', 'NIA NIH HHS'], ['MH00371', 'NIMH NIH HHS'], ['NS22698', 'NINDS NIH HHS']]\n",
      "[['AI 16432', 'NIAID NIH HHS'], ['AI 24847', 'NIAID NIH HHS'], ['AI28525', 'NIAID NIH HHS']]\n",
      "[['CA 40053', 'NCI NIH HHS'], ['N01-AI-62530', 'NIAID NIH HHS']]\n",
      "[['DA-00250', 'NIDA NIH HHS'], ['GM-22220', 'NIGMS NIH HHS']]\n",
      "[['CA 34233', 'NCI NIH HHS'], ['CA 38621', 'NCI NIH HHS']]\n",
      "[['AM09070-21', 'NIADDK NIH HHS'], ['GM10972', 'NIGMS NIH HHS'], ['GM21919-11', 'NIGMS NIH HHS']]\n",
      "[['CA 18138', 'NCI NIH HHS'], ['HD-13541', 'NICHD NIH HHS'], ['HL-07223', 'NHLBI NIH HHS']]\n",
      "[['ES 03598', 'NIEHS NIH HHS'], ['ES 03785', 'NIEHS NIH HHS']]\n",
      "[['AM19269', 'NIADDK NIH HHS'], ['DK13083', 'NIDDK NIH HHS'], ['RR400', 'NCRR NIH HHS']]\n",
      "[['AI20564', 'NIAID NIH HHS'], ['GM18305', 'NIGMS NIH HHS']]\n",
      "[['AI 12320', 'NIAID NIH HHS'], ['CA 16038', 'NCI NIH HHS']]\n",
      "[['1D28', 'PHS HHS'], ['PE 10057-01', 'BHP HRSA HHS']]\n",
      "[['AM 25141', 'NIADDK NIH HHS'], ['AM 26687', 'NIADDK NIH HHS'], ['HD 12637', 'NICHD NIH HHS']]\n",
      "[['R01 CA022556', 'NCI NIH HHS'], ['R37 CA022556', 'NCI NIH HHS'], ['CA22556', 'NCI NIH HHS']]\n",
      "[['5-T32-GM07594', 'NIGMS NIH HHS'], ['DA 00541', 'NIDA NIH HHS'], ['K02-DA00008', 'NIDA NIH HHS']]\n",
      "[['HD-07504', 'NICHD NIH HHS'], ['T32-HD-07068', 'NICHD NIH HHS']]\n",
      "[['IT32ES07087', 'NIEHS NIH HHS'], ['N0 1-ES-1-5001', 'NIEHS NIH HHS']]\n",
      "[['HD-11149', 'NICHD NIH HHS'], ['HD-13234', 'NICHD NIH HHS']]\n",
      "[['NS-06262', 'NINDS NIH HHS'], ['NS-10237', 'NINDS NIH HHS'], ['NS-15322', 'NINDS NIH HHS']]\n",
      "[['1 F32 CA 06227', 'NCI NIH HHS'], ['CA 18450', 'NCI NIH HHS'], ['N01 CP 53516', 'NCI NIH HHS']]\n",
      "[['HD-15472', 'NICHD NIH HHS'], ['HD-19938', 'NICHD NIH HHS']]\n",
      "[['CA-09200', 'NCI NIH HHS'], ['CA-27130', 'NCI NIH HHS'], ['CA-28302', 'NCI NIH HHS']]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(grants_similarity_matrix))\n",
    "\n",
    "for key, value in metadata_dict.items():\n",
    "    if len(value['grants']) > 0:\n",
    "        print(value['grants'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dea75bd3",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for first 10 papers:\n",
      "\n",
      "DOIs without grant: ['10.1016/s0092-8674(04)00045-5', '10.1158/0008-5472.can-05-1783', '10.1073/pnas.0307323101', '10.1093/nar/gkm641', '10.1093/nar/gkn714', '10.1038/nrc2867', '10.1038/ni.f.209', '10.1016/j.cell.2009.01.002', '10.1515/enr-2016-0012', '10.1038/leu.2011.356']\n",
      "PMIDs without grant: ['3734909', '324738', '590327', '211930', '515484', '96765', '626435', '3645914', '51441', '33725']\n",
      "\n",
      "PMID of papers with grants ['6896447']\n"
     ]
    }
   ],
   "source": [
    "#Verify that those entries without grant actually do not have grants\n",
    "sample_list_of_pmid_without_grant = []\n",
    "without_grants_doi = []\n",
    "i = 0\n",
    "with_grants = []\n",
    "\n",
    "for key, value in all_xmls.items():\n",
    "    if 'grant' in str(value).lower():\n",
    "        with_grants.append(key)\n",
    "    \n",
    "    else:\n",
    "        sample_list_of_pmid_without_grant.append(key)\n",
    "        without_grants_doi.append(doi_lookup_dict[key])\n",
    "        \n",
    "    i+= 1\n",
    "    \n",
    "    if i == 100:\n",
    "        break\n",
    "\n",
    "print('Statistics for first 10 papers:\\n')\n",
    "print(f'DOIs without grant: {without_grants_doi[0:10]}')\n",
    "print(f'PMIDs without grant: {sample_list_of_pmid_without_grant[0:10]}\\n')\n",
    "\n",
    "print(f'PMID of papers with grants {with_grants}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd746ba",
   "metadata": {},
   "source": [
    "<h1>Example</h1>\n",
    "An example of bib-couple and co-citation calculation for two nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7784fe88",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recorded bib-coupling: 6.0\n",
      "crossed checked bib-coupling: 6\n",
      "\n",
      "recorded co-citation: 99.0\n",
      "crossed checked co-citation: 99\n"
     ]
    }
   ],
   "source": [
    "first_node_id = 0\n",
    "first_node_pmid = nodes_array[first_node_id]\n",
    "\n",
    "second_node_id = 50\n",
    "second_node_pmid = nodes_array[second_node_id]\n",
    "\n",
    "first_reference = {}\n",
    "first_cited = {}\n",
    "\n",
    "second_reference = {}\n",
    "second_cited = {}\n",
    "\n",
    "for edge in edge_array:\n",
    "    start_node = edge[0]\n",
    "    end_node = edge[1]\n",
    "\n",
    "    if start_node == first_node_pmid:\n",
    "        first_reference[end_node] = 1\n",
    "    if end_node == first_node_pmid:\n",
    "        first_cited[start_node] = 1     \n",
    "        \n",
    "    \n",
    "    if start_node == second_node_pmid:\n",
    "        second_reference[end_node] = 1\n",
    "    if end_node == second_node_pmid:\n",
    "        second_cited[start_node] = 1       \n",
    "\n",
    "print(f'recorded bib-coupling: {bib_coupling_matrix[first_node_id][second_node_id]}')\n",
    "print(f'crossed checked bib-coupling: {calculate_dict_similarity(first_reference, second_reference, mode = \"number_of_common_terms\")}')\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'recorded co-citation: {cocitation_matrix[first_node_id][second_node_id]}')\n",
    "print(f'crossed checked co-citation: {calculate_dict_similarity(first_cited, second_cited, mode = \"number_of_common_terms\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d49b37",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "<h1>Missing ISSN</h1>\n",
    "Finding xml's without ISSN. Any journal info?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74ea48bb",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing ISSN pmids ['3645914', '14066214', '1211972', '10474434', '3429506', '11460150', '4347574', '4713388', '4308132', '4383515', '5119427', '12335001', '5631946', '5293199', '5162804', '6377493', '6513295', '290137', '332795', '234110', '151982', '544612', '62782', '1282098', '1691743', '9877917', '3043083', '3710688', '4233264', '4447963', '4871582', '4506117', '11441495', '12163935', '4789929', '4286257', '5084293', '5302502', '5624558', '5377235', '6568438', '410866', '1797831']\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "missing_issn = []\n",
    "for key, value in all_xmls.items():\n",
    "    if not 'issn' in str(value).lower():\n",
    "        missing_issn.append(key)\n",
    "        \n",
    "print(f'missing ISSN pmids {missing_issn}')\n",
    "print(len(missing_issn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab282043",
   "metadata": {},
   "source": [
    "<h1>Examples of co-citation similarity of 1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4b7d8",
   "metadata": {},
   "source": [
    "Interestingly, for all those of paris with jaccard_cocitation = 1, they have been only cited once! As we see below, citation counts of all of those pairs is 1. This could falsly inflate co_citation similarity. This will likely be the case with new publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aff64255",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 0.9210526315789473\n",
      "1.0 1.0 0.868421052631579\n",
      "1.0 1.0 0.8157894736842105\n",
      "1.0 1.0 0.4736842105263158\n",
      "1.0 1.0 0.8421052631578947\n",
      "1.0 1.0 0.9210526315789473\n",
      "1.0 1.0 0.8421052631578947\n",
      "1.0 1.0 0.6052631578947368\n",
      "1.0 1.0 0.9210526315789473\n",
      "1.0 1.0 0.39473684210526316\n",
      "1.0 1.0 0.868421052631579\n",
      "1.0 1.0 0.868421052631579\n",
      "1.0 1.0 0.9473684210526316\n",
      "1.0 1.0 0.5263157894736843\n",
      "1.0 1.0 0.8421052631578947\n",
      "1.0 1.0 0.9210526315789473\n",
      "1.0 1.0 0.7105263157894737\n",
      "1.0 1.0 0.7631578947368421\n",
      "1.0 1.0 0.9210526315789473\n",
      "1.0 1.0 0.736842105263158\n",
      "1.0 1.0 0.6052631578947368\n",
      "1.0 1.0 0.6842105263157895\n",
      "1.0 1.0 0.4736842105263158\n",
      "1.0 1.0 0.736842105263158\n",
      "1.0 1.0 0.8421052631578947\n",
      "1.0 1.0 0.7894736842105263\n",
      "1.0 1.0 0.7631578947368421\n",
      "1.0 1.0 0.9210526315789473\n",
      "1.0 1.0 0.7894736842105263\n",
      "1.0 1.0 0.5263157894736843\n",
      "1.0 1.0 0.8947368421052632\n",
      "1.0 1.0 0.6052631578947368\n",
      "1.0 1.0 0.8421052631578947\n",
      "1.0 1.0 0.8947368421052632\n",
      "1.0 1.0 0.8421052631578947\n",
      "1.0 1.0 0.9210526315789473\n",
      "1.0 1.0 0.9210526315789473\n",
      "1.0 1.0 0.7631578947368421\n",
      "1.0 1.0 0.8157894736842105\n",
      "1.0 1.0 0.9473684210526316\n",
      "1.0 1.0 0.7631578947368421\n",
      "1.0 1.0 0.8421052631578947\n",
      "1.0 1.0 0.5\n",
      "1.0 1.0 0.9210526315789473\n",
      "1.0 1.0 0.6842105263157895\n",
      "1.0 1.0 0.8947368421052632\n",
      "1.0 1.0 0.7105263157894737\n",
      "1.0 1.0 0.6052631578947368\n",
      "1.0 1.0 0.9210526315789473\n",
      "1.0 1.0 0.8421052631578947\n",
      "1.0 1.0 0.6578947368421053\n",
      "1.0 1.0 0.736842105263158\n",
      "1.0 1.0 0.5\n",
      "1.0 1.0 0.6578947368421053\n",
      "1.0 1.0 0.39473684210526316\n",
      "1.0 1.0 0.736842105263158\n",
      "1.0 1.0 0.8947368421052632\n",
      "1.0 1.0 0.868421052631579\n",
      "Average year similarity 0.765880217785844\n"
     ]
    }
   ],
   "source": [
    "year_similarity_matrix = np.load('year_similarity_matrix.npy')\n",
    "year_similarity_array = []\n",
    "\n",
    "row_indices, col_indices = np.where(cocitation_similarity_matrix == 1)\n",
    "for idx in range(row_indices.shape[0]):\n",
    "    row = row_indices[idx]\n",
    "    col = col_indices[idx]\n",
    "    year_similarity_array.append(year_similarity_matrix[row][col])\n",
    "    print(np.sum(adj_matrix[:,row]), np.sum(adj_matrix[:, col]), year_similarity_matrix[row][col])\n",
    "    \n",
    "print(f'Average year similarity {np.average(year_similarity_array)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0b73db1",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first paper pmid: 678632 second paper pmid: 1167910. Citing list:\n",
      "\n",
      "[4462343]\n"
     ]
    }
   ],
   "source": [
    "bib_coupling_similarity_matrix = np.load('bib_coupling_similarity_matrix.npy')\n",
    "cocitation_similarity_matrix = np.load('cocitation_similarity_matrix.npy')\n",
    "\n",
    "#For co_citation of 1\n",
    "first_paper_id = np.unravel_index(cocitation_similarity_matrix.argmax(), cocitation_similarity_matrix.shape)[0]\n",
    "second_paper_id = np.unravel_index(cocitation_similarity_matrix.argmax(), cocitation_similarity_matrix.shape)[1]\n",
    "\n",
    "first_node_pmid =  nodes_array[first_paper_id]\n",
    "second_node_pmid =  nodes_array[second_paper_id]\n",
    "\n",
    "first_cited = []\n",
    "second_cited = []\n",
    "\n",
    "\n",
    "\n",
    "for edge in edge_array:\n",
    "    start_node = edge[0]\n",
    "    end_node = edge[1]\n",
    "\n",
    "    if end_node == first_node_pmid:\n",
    "        first_cited.append(start_node)   \n",
    "        \n",
    "    if end_node == second_node_pmid:\n",
    "        second_cited.append(start_node)\n",
    "        \n",
    "\n",
    "print(f'first paper pmid: {first_node_pmid} second paper pmid: {second_node_pmid}. Citing list:\\n')\n",
    "print(first_cited)\n",
    "\n",
    "#Assert two arrays are equal\n",
    "assert np.sum(np.sort(first_cited) - np.sort(second_cited)) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3f863b",
   "metadata": {},
   "source": [
    "<h1>Examples of bib-coupling similarity of 1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631c1dcd",
   "metadata": {},
   "source": [
    "Here the situation is differen. As we expect, reference list is typically larger than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11bc92ca",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 0.5526315789473684\n",
      "1.0 1.0 0.6578947368421053\n",
      "68.0 68.0 0.9736842105263158\n",
      "63.0 63.0 1.0\n",
      "100.0 100.0 0.9210526315789473\n",
      "63.0 63.0 1.0\n",
      "100.0 100.0 0.9210526315789473\n",
      "110.0 110.0 0.5789473684210527\n",
      "54.0 54.0 0.868421052631579\n",
      "53.0 53.0 0.8157894736842105\n",
      "75.0 75.0 0.868421052631579\n",
      "68.0 68.0 0.9736842105263158\n",
      "75.0 75.0 0.868421052631579\n",
      "91.0 91.0 0.8157894736842105\n",
      "1.0 1.0 0.5526315789473684\n",
      "1.0 1.0 0.8947368421052632\n",
      "110.0 110.0 0.5789473684210527\n",
      "53.0 53.0 0.8157894736842105\n",
      "54.0 54.0 0.868421052631579\n",
      "91.0 91.0 0.8157894736842105\n",
      "4.0 4.0 0.5263157894736843\n",
      "1.0 1.0 0.6578947368421053\n",
      "1.0 1.0 0.8947368421052632\n",
      "4.0 4.0 0.5263157894736843\n",
      "Average year similarity 0.7894736842105264\n"
     ]
    }
   ],
   "source": [
    "row_indices, col_indices = np.where(bib_coupling_similarity_matrix == 1)\n",
    "year_similarity_array = []\n",
    "\n",
    "for idx in range(row_indices.shape[0]):\n",
    "    row = row_indices[idx]\n",
    "    col = col_indices[idx]\n",
    "    year_similarity_array.append(year_similarity_matrix[row][col])\n",
    "    print(np.sum(adj_matrix[row, :]), np.sum(adj_matrix[col, :]), year_similarity_matrix[row][col])\n",
    "    \n",
    "print(f'Average year similarity {np.average(year_similarity_array)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0239f8b0",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first paper pmid: 3144507 second paper pmid: 2730206. Reference list:\n",
      "\n",
      "[239226, 398042, 3734909, 282506, 1331250, 1987518, 1791140, 2099708, 2263454, 1941775, 2203573, 2125982, 1962532, 2360006, 3201489, 2796739, 2892044, 2817498, 2772090, 2715427, 3582271, 3407741, 3405656, 3641907, 3442376, 3691393, 3953965, 4484758, 4542211, 5241540, 5259617, 5985223, 6314802, 6194500, 5965506, 6568545, 350741, 584627, 956242, 857688, 1265223, 891249, 2360005, 2272728, 2277164, 1707498, 2243141, 2360009, 1911157, 2524190, 3041644, 2890069, 3988276, 3908563, 3854063, 4646950, 4804995, 5545417, 5141533, 5395091, 5584139, 6135458, 5955175]\n"
     ]
    }
   ],
   "source": [
    "bib_coupling_similarity_matrix = np.load('bib_coupling_similarity_matrix.npy')\n",
    "cocitation_similarity_matrix = np.load('cocitation_similarity_matrix.npy')\n",
    "\n",
    "#For co_citation of 1\n",
    "first_paper_id = row_indices[3]\n",
    "second_paper_id = col_indices[3]\n",
    "\n",
    "\n",
    "first_node_pmid =  nodes_array[first_paper_id]\n",
    "second_node_pmid =  nodes_array[second_paper_id]\n",
    "\n",
    "first_reference = []\n",
    "second_reference = []\n",
    "\n",
    "\n",
    "\n",
    "for edge in edge_array:\n",
    "    start_node = edge[0]\n",
    "    end_node = edge[1]\n",
    "\n",
    "    if start_node == first_node_pmid:\n",
    "        first_reference.append(end_node)   \n",
    "        \n",
    "    if start_node == second_node_pmid:\n",
    "        second_reference.append(end_node)\n",
    "        \n",
    "\n",
    "print(f'first paper pmid: {first_node_pmid} second paper pmid: {second_node_pmid}. Reference list:\\n')\n",
    "print(first_reference)\n",
    "\n",
    "#Assert two arrays are equal\n",
    "assert np.sum(np.sort(first_reference) - np.sort(second_reference)) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd51e3",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "<h1> Missing grants </h1>\n",
    "<p>Let's see how those samples with 'grant' string but no grant data look like </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3483c43a",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6896447', '1387753', '1531667', '1993690', '1971008', '8970530', '2289961', '2144770', '1701215', '2116419', '9009628', '2133544', '1884349', '2233799', '1893982', '1742025', '1791140', '1782805', '2912175', '2539430', '3228218', '2871725', '2986026', '3458240', '3427092', '3404558', '4040992', '3653217', '3773213', '3623654', '3508061', '3578811', '3501312', '3953965', '11739552', '6378152', '6724914', '6410074', '6191525', '6227521', '6090639', '6237171', '6495156', '8225876', '1371645', '1619667', '1311638', '1374245', '1402885', '1518362', '1731936', '2168227', '2449254', '1835656', '1768062', '1691743', '2016049', '1855136', '2173543', '2005588', '1737770', '2863135', '2621537', '2751691', '3025354', '3106032', '2554112', '2615640', '3004709', '2701284', '2710174', '3505259', '3708070', '3698999', '4067086', '6173335', '6396732', '6393874', '6203688', '4043005', '3731243', '6185176']\n"
     ]
    }
   ],
   "source": [
    "target_pmids = []\n",
    "\n",
    "for key, value in all_xmls.items():\n",
    "    if 'grant' in str(value).lower() and len(metadata_dict[key]['grants']) == 0:\n",
    "        target_pmids.append(key)\n",
    "        \n",
    "print(target_pmids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e1c17",
   "metadata": {},
   "source": [
    "Through better parsing, this number is now very low and negligible!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e105ed59",
   "metadata": {},
   "source": [
    "<h1>Missing ISSN</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97099845",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3645914', '14066214', '1211972', '10474434', '3429506', '4904464', '4347574', '4713388', '4308132', '4383515', '5119427', '5631946', '5293199', '6377493', '6513295', '290137', '234110', '151982', '544612', '1282098', '1691743', '3043083', '3710688', '4233264', '4871582', '4506117', '4789929', '4286257', '5084293', '5302502', '5624558', '6568438', '1797831']\n"
     ]
    }
   ],
   "source": [
    "target_pmids = []\n",
    "\n",
    "for key, value in all_xmls.items():\n",
    "    if 'journal' in str(value).lower() and len(metadata_dict[key]['journal']) == 0:\n",
    "        target_pmids.append(key)\n",
    "        \n",
    "print(target_pmids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a11f1f",
   "metadata": {},
   "source": [
    "As we see, even with having a lookup dict and mapping journal_title -> ISSN for pairs that we have both data, doesn't help much to resolve ISSN for cases that we only have journal_title. Only 3 over 2004 samples were resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04de5dbb",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print('Canadian journal of biochemistry and physiology' in journal_title_lookup_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
