{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f303592",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-31T01:22:05.953663551Z"
    },
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98753it [00:00, 1423377.83it/s]\n",
      "2004it [00:00, 1156651.33it/s]\n"
     ]
    }
   ],
   "source": [
    "#Load edges and nodes\n",
    "\n",
    "import numpy as np\n",
    "from load_data import *\n",
    "\n",
    "nodes_array, edge_array = assert_edges_are_within_first_cluster()\n",
    "\n",
    "node_lookup_dict = {}\n",
    "\n",
    "min_index = np.amin(nodes_array)\n",
    "max_index = np.amax(nodes_array)\n",
    "\n",
    "\n",
    "i = 0\n",
    "for node in nodes_array:\n",
    "    node_lookup_dict[str(node)] = i\n",
    "    i+= 1\n",
    "    \n",
    "adj_matrix = np.load('adj_matrix.npy')    \n",
    "data_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdeaad6",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get dois from the exosome csv\n",
    "#Read the DOIS from the node id\n",
    "\n",
    "from load_data import *\n",
    "\n",
    "import csv\n",
    "\n",
    "csv_file_path = data_dir + 'exosome.csv'\n",
    "\n",
    "# Open the CSV file for reading\n",
    "with open(csv_file_path, 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    dois = {}\n",
    "    for line_number, row in tqdm(enumerate(csv_reader), total = 14695476):  # 'total' is the total number of iterations\n",
    "        \n",
    "        if line_number <min_index or line_number > max_index:\n",
    "            continue\n",
    "            \n",
    "        id = int(row[0])\n",
    "        doi = row[2]\n",
    "        \n",
    "        if id in node_lookup_dict:\n",
    "            node_lookup_dict[id] = doi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c810cf",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Save\n",
    "import json\n",
    "\n",
    "with open('first_cluster_dois.json', 'w') as json_file:\n",
    "    json.dump(node_lookup_dict, json_file, indent=4)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f66d16",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get PMID by doi\n",
    "\n",
    "import requests\n",
    "import xmltodict\n",
    "\n",
    "doi_dict = {}\n",
    "\n",
    "#Get dois\n",
    "def fetch_pmid_from_doi(doi='10.1073/pnas.0510928103'):\n",
    "\n",
    "    pmid_dict = {}\n",
    "    request_str = 'https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?tool=my_tool&email=my_email@example.com&ids='\n",
    "    request_str += str(doi)\n",
    "    \n",
    "    response = requests.get(request_str)\n",
    "    response_text = response.text\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        index = response_text.index('pmid=')\n",
    "\n",
    "\n",
    "        pmid_whole = response_text[index:].split(' ')[0]\n",
    "        pmid = int(pmid_whole[:-1].split('\\\"')[1])\n",
    "\n",
    "        return pmid\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "for key in tqdm(node_lookup_dict.keys()):\n",
    "    doi_dict[key] = fetch_pmid_from_doi(key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e21bf",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#It turns out that initial node ids is their PMID\n",
    "\n",
    "\n",
    "for key, value in doi_dict.items():\n",
    "    assert key == value\n",
    "    \n",
    "\n",
    "with open('first_cluster_pmid.json', 'w') as json_file:\n",
    "    json.dump(doi_dict, json_file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce168bb",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('first_cluster_pmid.json', 'r') as json_file:\n",
    "    doi_dict = json.load(json_file)\n",
    "    \n",
    "pmid_dict = doi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2af2d",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Save all xmls\n",
    "all_xmls = {}\n",
    "def save_all_xmls(pmid):\n",
    "    wait = 0.25\n",
    "    time.sleep(wait)\n",
    "    pmid_dict = {}\n",
    "    request_str  = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id='\n",
    "    request_str += str(pmid)\n",
    "    \n",
    "    response = requests.get(request_str)\n",
    "    response_text = response.text\n",
    "    \n",
    "    try:\n",
    "        xml_dict = xmltodict.parse(response_text)\n",
    "        \n",
    "    except:\n",
    "        time.sleep(2 * wait)\n",
    "        return fetch_metadata_from_pmid(pmid)\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "for id in tqdm(pmid_dict):\n",
    "    all_xmls[id] = save_all_xmls(id)\n",
    "\n",
    "with open('first_cluster_xmls.json', 'w') as json_file:\n",
    "    json.dump(all_xmls, json_file, indent=4)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9485977d",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load all XMLs\n",
    "import json\n",
    "\n",
    "with open('first_cluster_xmls.json', 'r') as json_file:\n",
    "    all_xmls = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d29decb9",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2004/2004 [00:03<00:00, 539.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed parse 0\n",
      "Occured keyword dict: {'keyword': 19, 'grant': 139, 'abstract': 962, 'mesh': 1990, 'chemicallist': 1085, 'datecompleted': 1991}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Mispelled\n",
    "import time\n",
    "import requests\n",
    "import xmltodict\n",
    "\n",
    "parsed_error = []\n",
    "dict_of_interest = {'keyword': 0, \"grant\": 0, \"abstract\": 0, \"mesh\": 0, \"chemicallist\":0, 'datecompleted': 0}\n",
    "\n",
    "\n",
    "def fetch_metadata_from_pmid(response_text, idx, pmid): \n",
    "    global dict_of_interest\n",
    "    mesh_headings = []\n",
    "    grants = []\n",
    "    year = \"\"\n",
    "    journal_ISSN = \"\"\n",
    "    abstract = \"\"\n",
    "    chemical_list = []\n",
    "    meta_data = {}\n",
    "    \n",
    "    try:\n",
    "        xml_dict = xmltodict.parse(response_text)\n",
    "        \n",
    "        for key_of_interest in dict_of_interest.keys():\n",
    "            if key_of_interest in str(xml_dict).lower():\n",
    "\n",
    "                dict_of_interest[key_of_interest] += 1\n",
    "\n",
    "        #Date completed or revised?\n",
    "        #print(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation'].keys())\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            if 'DateCompleted' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']:\n",
    "                if 'Year' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['DateCompleted']:\n",
    "                    year = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['DateCompleted']['Year']\n",
    "\n",
    "            else:\n",
    "    #             print(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation'])\n",
    "                  pass\n",
    "    \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            if 'ISSN' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal'].keys():\n",
    "                journal_ISSN = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['ISSN']['#text']\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        #print(len(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['GrantList']['Grant']))\n",
    "        \n",
    "        \n",
    "        #Grant\n",
    "        #Very few grants don't have grant id's\n",
    "        #Grant institute could also be relevant\n",
    "        #TODO: collect missing grant id\n",
    "\n",
    "        try:\n",
    "            if 'GrantList' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']:\n",
    "                for grant in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['GrantList']['Grant']:\n",
    "                    if 'GrantID' in grant and 'Agency' in grant:\n",
    "                        grants.append((grant['GrantID'],grant['Agency']))\n",
    "                        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            if 'Abstract' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article'].keys():\n",
    "                if 'AbstractText'  in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Abstract'].keys():\n",
    "                    abstract = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Abstract']['AbstractText']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    " \n",
    "\n",
    "        #print(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['GrantList']['Grant'][0])\n",
    "        \n",
    "        #MeSH heading  \n",
    "        \n",
    "        try:\n",
    "        #print(len(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']))\n",
    "        \n",
    "            #DescriptorName? Is a term\n",
    "            if 'MeshHeadingList' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']:\n",
    "                for mesh in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']:\n",
    "    #                 print(mesh['DescriptorName'])\n",
    "    #                 print(mesh['DescriptorName']['@UI'])\n",
    "    #                 print(mesh['DescriptorName']['#text'])\n",
    "                    if (not '@Type' in mesh['DescriptorName'].keys()) or (mesh['DescriptorName']['@Type'] != 'Geographic'):\n",
    "                        if 'california' in str(mesh).lower():\n",
    "                            print(mesh)\n",
    "                        mesh_headings.append((mesh['DescriptorName']['@UI'], mesh['DescriptorName']['#text']))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        try:\n",
    "        #print(len(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']))\n",
    "        \n",
    "            #DescriptorName? Is a term\n",
    "            if 'ChemicalList' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']:\n",
    "#                print(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']\n",
    "# #                      ['ChemicalList']['Chemical']['NameOfSubstance'])\n",
    "               #print(len(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['ChemicalList']['Chemical']))\n",
    "               for substance in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['ChemicalList']['Chemical']:\n",
    "                        chemical_list.append(substance['NameOfSubstance']['@UI'])\n",
    "                #print(chemical_list)\n",
    "                \n",
    "               \n",
    "              \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "        #References and history\n",
    "        #print(xml_dict['PubmedArticleSet']['PubmedArticle']['PubmedData'].keys())\n",
    "\n",
    "\n",
    "    except:\n",
    "        parsed_error.append(idx)\n",
    "        pass\n",
    "\n",
    "\n",
    " \n",
    "        \n",
    "    meta_data = {'mesh': mesh_headings, 'grants': grants, 'year': year, 'journal': journal_ISSN,\n",
    "                 'abstract': abstract, 'chemical' : chemical_list} \n",
    "        \n",
    "    return meta_data\n",
    "\n",
    "metadata_dict = {}\n",
    "\n",
    "# [166, 719, 1672, 1918] odd\n",
    "\n",
    "idx = 0\n",
    "for key, value in tqdm(all_xmls.items()):\n",
    "    metadata_dict[key] = fetch_metadata_from_pmid(value, idx, key)\n",
    "    idx += 1\n",
    "    \n",
    "\n",
    "\n",
    "print(f'failed parse {len(parsed_error)}')\n",
    "print(f'Occured keyword dict: {dict_of_interest}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "07c2472e",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocurred features  {'mesh': 1982, 'grants': 57, 'year': 1991, 'journal': 1960, 'abstract': 853, 'chemical': 786}\n",
      "avg mesh length  9.433400605449041\n",
      "avg chemical length  4.283715012722646\n"
     ]
    }
   ],
   "source": [
    "#### Count incomplete data\n",
    "\n",
    "features = {'mesh': 0, 'grants': 0, 'year': 0, 'journal': 0, 'abstract': 0, 'chemical' : 0}\n",
    "#Mesh terms are sometimes unrelated\n",
    "\n",
    "mesh_length = []\n",
    "chemical_length = []\n",
    "\n",
    "for feature in features.keys():\n",
    "    for _, meta in metadata_dict.items():\n",
    "        if len(meta[feature]) > 0:\n",
    "            features[feature] += 1\n",
    "            if feature == 'mesh':\n",
    "                mesh_length.append(len(meta[feature]))\n",
    "            \n",
    "            elif feature == 'chemical':\n",
    "                chemical_length.append(len(meta[feature]))\n",
    "                \n",
    "            \n",
    "print(\"Ocurred features \", features)\n",
    "print(\"avg mesh length \", np.mean(mesh_length))\n",
    "print(\"avg chemical length \", np.mean(chemical_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30f0c402",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('first_cluster_metadata.json', 'w') as json_file:\n",
    "    json.dump(metadata_dict, json_file, indent=4)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eb36d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in metadata_dict.items():\n",
    "    if len(value['grants']) > 0:\n",
    "        for grant in value['grants']:\n",
    "            assert len(grant) == 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93b161bb",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the metadata file\n",
    "with open('first_cluster_metadata.json', 'r') as json_file:\n",
    "    metadata_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab9512e5",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_dict_similarity(dict_1, dict_2, mode ):\n",
    "    similarity = 0\n",
    "    modes = ['number_of_common_terms', 'jaccard']\n",
    "    \n",
    "    assert mode in modes\n",
    "    \n",
    "    for key in dict_1:\n",
    "            if key in dict_2:\n",
    "                similarity += 1\n",
    "                \n",
    "    \n",
    "    if mode == 'number_of_common_terms':\n",
    "        pass\n",
    "       \n",
    "    elif mode == 'jaccard':\n",
    "        similarity = similarity / (len(dict_1) + len(dict_2))\n",
    "        \n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08a7e782",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate distance/similarity between two pmid's\n",
    "#Lets call it metric for now. This is unnormalized\n",
    "def calculate_distance(pmid1, pmid2, feature):\n",
    "    \n",
    "    metric = 0\n",
    "    pmid1 = str(pmid1)\n",
    "    pmid2 = str(pmid2)\n",
    "    \n",
    "    assert feature in ['year', 'mesh', 'chemical', 'co-citation', 'bib-coupling']\n",
    "    if feature == 'year':             \n",
    "                year1 = metadata_dict[pmid1][feature]\n",
    "                year2 = metadata_dict[pmid2][feature]\n",
    "                \n",
    "                if len(year1) > 0 and len(year2)>0:\n",
    "                    metric = np.abs(int(year1)-int(year2))\n",
    "                \n",
    "                else:\n",
    "                    metric = -1\n",
    "    \n",
    "    \n",
    "    #They are both treated the same way ...\n",
    "    elif feature == 'mesh' or feature == 'chemical':\n",
    "        common_terms = 0\n",
    "        terms_1 = {}\n",
    "        terms_2 = {}\n",
    "        \n",
    "        for term in metadata_dict[pmid1][feature]:\n",
    "            terms_1[term[0]] = 1\n",
    "    \n",
    "        for term in metadata_dict[pmid2][feature]:\n",
    "            terms_2[term[0]] = 1\n",
    "        \n",
    "        if len(terms_1) > 0 and len(terms_2)>0:\n",
    "            metric = calculate_dict_similarity(terms_1, terms_2, 'jaccard')\n",
    "                    \n",
    "        else:\n",
    "            metric = -1\n",
    "            \n",
    "    elif feature == 'bib-coupling':\n",
    "        node_1 = node_lookup_dict[pmid1]\n",
    "        node_2 = node_lookup_dict[pmid2]\n",
    "        \n",
    "        common = np.dot(adj_matrix[node_1,:], adj_matrix[node_2, :])\n",
    "        denom = np.sum(adj_matrix[node_1, :]) + np.sum(adj_matrix[node_2, :]) - common\n",
    "        \n",
    "        if denom > 0 :\n",
    "            metric = common / denom\n",
    "        \n",
    "    \n",
    "    elif feature == 'co-citation':\n",
    "        node_1 = node_lookup_dict[pmid1]\n",
    "        node_2 = node_lookup_dict[pmid2]\n",
    "        \n",
    "        common = np.dot(adj_matrix[: , node_1], adj_matrix[: , node_2])\n",
    "        denom = np.sum(adj_matrix[:, node_1]) + np.sum(adj_matrix[:, node_2]) - common\n",
    "        \n",
    "        if denom > 0 :\n",
    "            metric = common / denom\n",
    "    return metric\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9004d1c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2004/2004 [00:04<00:00, 425.46it/s]\n"
     ]
    }
   ],
   "source": [
    "def calculate_three_hop_distance():\n",
    "    #Is currently inefficient as relies on matrix multiplication\n",
    "    # We use undirected edges\n",
    "    undirected_adj_matrix = adj_matrix + adj_matrix.transpose()\n",
    "    assert np.argmax(undirected_adj_matrix) == 1\n",
    "    \n",
    "    #Adj_matrix ^ k (i,j) = number of walks of length k from i to j \n",
    "    second_hop_distance = np.matmul(adj_matrix, adj_matrix)\n",
    "    third_hop_distance = np.matmul(second_hop_distance, adj_matrix)\n",
    "    \n",
    "    aggregated_three_hop_distance = np.zeros_like(adj_matrix)\n",
    "    \n",
    "    for i in tqdm(range(adj_matrix.shape[0])):\n",
    "        for j in range(i):\n",
    "            if adj_matrix[i][j] == 1:\n",
    "                aggregated_three_hop_distance[i][j] = 1 - 1/3\n",
    "            elif second_hop_distance[i][j] > 1:\n",
    "                aggregated_three_hop_distance[i][j] = 1 - 2/3\n",
    "\n",
    "            elif second_hop_distance[i][j] > 1:\n",
    "                aggregated_three_hop_distance[i][j] = 1 - 3/3\n",
    "            \n",
    "            else:\n",
    "                aggregated_three_hop_distance[i][j] = -1\n",
    "    \n",
    "    aggregated_three_hop_distance = aggregated_three_hop_distance + aggregated_three_hop_distance.transpose()\n",
    "    return aggregated_three_hop_distance\n",
    "\n",
    "aggregated_three_hop_similarity = calculate_three_hop_distance()\n",
    "np.save('aggregated_three_hop_distance.npy', aggregated_three_hop_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3748c102",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh terms with one entires 0\n",
      "Mesh terms with two entires 18933\n",
      "Example of a mesh: ['D015046', 'Zoology']\n"
     ]
    }
   ],
   "source": [
    "#all mesh terms are tuples, so we use UI's as they are standard\n",
    "\n",
    "ones = 0\n",
    "twos = 0\n",
    "\n",
    "for key, value in metadata_dict.items():\n",
    "    if len(value['mesh']) >0:\n",
    "        for mesh in value['mesh']:\n",
    "            if len(mesh) == 1:\n",
    "                ones += 1\n",
    "            \n",
    "            elif len(mesh) == 2:\n",
    "                twos += 1\n",
    "            \n",
    "            else:\n",
    "                raise 'error'\n",
    "            \n",
    "print(f'Mesh terms with one entires {ones}')\n",
    "print(f'Mesh terms with two entires {twos}')\n",
    "print(f'Example of a mesh: {mesh}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bae28d79",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2004/2004 [00:08<00:00, 232.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def report_stats(vals, title):\n",
    "    filtered_val = []\n",
    "    for val in vals:\n",
    "        if val != -1:\n",
    "            filtered_val.append(val)\n",
    "            \n",
    "    median = np.median(filtered_val)\n",
    "    mean = np.mean(filtered_val)\n",
    "    min = np.amin(filtered_val)\n",
    "    max = np.amax(filtered_val)\n",
    "    total = np.sum(filtered_val)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "#     fig.suptitle('bold figure suptitle', fontsize=14, fontweight='bold')\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.boxplot(vals)\n",
    "    \n",
    "    labels = [title]\n",
    "\n",
    "    ax.set_xticklabels(labels)\n",
    "\n",
    "    ax.set_title(f'{title}  boxplot diagram')\n",
    "#     ax.set_xlabel(f'{title}')\n",
    "    ax.set_ylabel('Values')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print(f'median {median} mean {mean} min {min} max {max}, total {total}')\n",
    "\n",
    "    \n",
    "\n",
    "def calculate_distance_matrix(feature):\n",
    "    distance_matrix = np.zeros((len(nodes_array), len(nodes_array))) \n",
    "    \n",
    "    for i in tqdm(range(distance_matrix.shape[0])):\n",
    "        for j in range(i):\n",
    "            pmid1 = str(nodes_array[i])\n",
    "            pmid2 = str(nodes_array[j])            \n",
    "            distance_matrix[i][j] = calculate_distance(pmid1, pmid2, feature)\n",
    "        \n",
    "    distance_matrix = distance_matrix + distance_matrix.transpose()\n",
    "    return distance_matrix\n",
    "\n",
    "# year_distance_matrix = calculate_distance_matrix('year')\n",
    "# np.save('year_distance_matrix.npy', year_distance_matrix)\n",
    "\n",
    "mesh_similarity_matrix = calculate_distance_matrix('mesh')\n",
    "np.save('mesh_similarity_matrix.npy', mesh_similarity_matrix)\n",
    "\n",
    "\n",
    "# bib_coupling_similarity_matrix = calculate_distance_matrix('bib-coupling')\n",
    "# np.save('bib_coupling_similarity_matrix.npy', bib_coupling_similarity_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# cocitation_similarity_matrix = calculate_distance_matrix('co-citation')\n",
    "# np.save('cocitation_similarity_matrix.npy', cocitation_similarity_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# chemical_similarity_matrix = calculate_distance_matrix('chemical')\n",
    "# np.save('chemical_similarity_matrix.npy', chemical_similarity_matrix)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8626da",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cocitation_matrix = np.load('cocitation_matrix.npy')\n",
    "# bib_coupling_matrix = np.load('bib_coupling_matrix.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1cad3cec",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median 0.33333333333333337 mean 0.4042799341548592 min 0.33333333333333337 max 0.6666666666666667, total 87595.33333333334\n"
     ]
    }
   ],
   "source": [
    "#Assuming a square matrix, report statistics\n",
    "def report_matrix_stats(matrix, title):\n",
    "    n = matrix.shape[0]\n",
    "    all_values = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            #Remove negatives as they are flags\n",
    "            if matrix[i][j] > -1:\n",
    "                all_values.append(matrix[i][j])\n",
    "    \n",
    "    report_stats(all_values, title)\n",
    "    \n",
    "    \n",
    "# report_matrix_stats(year_distance_matrix, 'year')\n",
    "# report_matrix_stats(cocitation_matrix, 'cocitation')\n",
    "# report_matrix_stats(bib_coupling_matrix, 'bib-couple')\n",
    "# report_matrix_stats(mesh_similarity_matrix, 'jaccard mesh similarity')\n",
    "# report_matrix_stats(chemical_similarity_matrix, 'jaccard chemical similarity')\n",
    "# report_matrix_stats(cocitation_similarity_matrix, 'jaccard co-citation similarity')\n",
    "# report_matrix_stats(bib_coupling_similarity_matrix, 'jaccard bib-coupling similarity')\n",
    "report_matrix_stats(aggregated_three_hop_similarity, 'three hop similarity ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea75bd3",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Verify that those entries without grant actually do not have grants\n",
    "sample_list_of_pmid_without_grant = []\n",
    "i = 0\n",
    "with_grants = []\n",
    "\n",
    "for key, value in all_xmls.items():\n",
    "    if 'grant' in str(value).lower():\n",
    "        with_grants.append(key)\n",
    "    \n",
    "    else:\n",
    "        sample_list_of_pmid_without_grant.append(key)\n",
    "        \n",
    "    i+= 1\n",
    "    \n",
    "    if i == 100:\n",
    "        break\n",
    "\n",
    "print('Statistics for first 10 papers:\\n')\n",
    "print(f'PMIDs without grant: {sample_list_of_pmid_without_grant[0:10]}\\n')\n",
    "print(f'PMID of papers with grants {with_grants}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09939584",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
