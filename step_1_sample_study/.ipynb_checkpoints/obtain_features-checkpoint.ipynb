{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55e291e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T19:57:34.934737029Z",
     "start_time": "2023-10-19T19:57:34.549789724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Postgres successfully\n",
      "(11233, 11233)\n",
      "(26264, 26264)\n",
      "(24416, 24416)\n",
      "(4790, 4790)\n",
      "(26745, 26745)\n",
      "(18803, 18803)\n",
      "(12502, 12502)\n",
      "(5468, 5468)\n",
      "(29089, 29089)\n",
      "(4326, 4326)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the PGDATABASE environment variable\n",
    "os.environ[\"PGDATABASE\"] = \"ernieplus\"\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\"\")\n",
    "print(\"Connected to Postgres successfully\")\n",
    "# conn.close()\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Define your SQL query\n",
    "sql_query = \"select * from hm31.aligned_musicians am limit 10\"\n",
    "\n",
    "# Execute the SQL query\n",
    "cur.execute(sql_query)\n",
    "\n",
    "# Fetch and print the result (you can modify this part based on your query)\n",
    "result = cur.fetchall()\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f303592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-19T19:57:36.900375665Z",
     "start_time": "2023-10-19T19:57:34.615548189Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98753it [00:00, 785342.99it/s]\n",
      "2004it [00:00, 1113443.53it/s]\n"
     ]
    }
   ],
   "source": [
    "#Load edges and nodes\n",
    "\n",
    "import numpy as np\n",
    "from load_data import *\n",
    "from multiprocessing import Process, Manager, Pool  # Import the Pool class\n",
    "\n",
    "nodes_array, edge_array = assert_edges_are_within_first_cluster()\n",
    "\n",
    "node_lookup_dict = {}\n",
    "\n",
    "min_index = np.amin(nodes_array)\n",
    "max_index = np.amax(nodes_array)\n",
    "\n",
    "\n",
    "i = 0\n",
    "for node in nodes_array:\n",
    "    node_lookup_dict[str(node)] = i\n",
    "    i+= 1\n",
    "    \n",
    "adj_matrix = np.load('adj_matrix.npy')    \n",
    "data_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdeaad6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-19T19:57:36.904824384Z"
    },
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 90249/14695476 [00:00<00:32, 451513.00it/s]"
     ]
    }
   ],
   "source": [
    "#Get dois from the exosome csv\n",
    "#Read the DOIS from the node id\n",
    "\n",
    "from load_data import *\n",
    "\n",
    "import csv\n",
    "\n",
    "csv_file_path = data_dir + 'exosome.csv'\n",
    "doi_lookup_dict = {}\n",
    "\n",
    "# Open the CSV file for reading\n",
    "with open(csv_file_path, 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    dois = {}\n",
    "    for line_number, row in tqdm(enumerate(csv_reader), total = 14695476):  # 'total' is the total number of iterations\n",
    "        \n",
    "        if line_number <min_index or line_number > max_index:\n",
    "            continue\n",
    "            \n",
    "        id = str(row[0])\n",
    "        doi = row[2]\n",
    "        \n",
    "        if id in node_lookup_dict:\n",
    "            doi_lookup_dict[id] = doi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c810cf",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Save\n",
    "import json\n",
    "\n",
    "with open('first_cluster_dois.json', 'w') as json_file:\n",
    "    json.dump(doi_lookup_dict, json_file, indent=4)\n",
    "    \n",
    "# with open('first_cluster_dois.json', 'w') as json_file:\n",
    "#     doi_lookup_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f66d16",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Get PMID by doi\n",
    "\n",
    "import requests\n",
    "import xmltodict\n",
    "\n",
    "doi_dict = {}\n",
    "\n",
    "#Get dois\n",
    "def fetch_pmid_from_doi(doi='10.1073/pnas.0510928103'):\n",
    "\n",
    "    pmid_dict = {}\n",
    "    request_str = 'https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?tool=my_tool&email=my_email@example.com&ids='\n",
    "    request_str += str(doi)\n",
    "    \n",
    "    response = requests.get(request_str)\n",
    "    response_text = response.text\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        index = response_text.index('pmid=')\n",
    "\n",
    "\n",
    "        pmid_whole = response_text[index:].split(' ')[0]\n",
    "        pmid = int(pmid_whole[:-1].split('\\\"')[1])\n",
    "\n",
    "        return pmid\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "for key in tqdm(node_lookup_dict.keys()):\n",
    "    doi_dict[key] = fetch_pmid_from_doi(key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66bf3ba",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(doi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe91773",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "node_id_to_PMID_mapping = {}\n",
    "\n",
    "with open('first_cluster_pmids.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for line_number, row in tqdm(enumerate(csv_reader)):  # 'total' is the total number of iterations\n",
    "        \n",
    "        if line_number == 0:\n",
    "            continue\n",
    "            \n",
    "        node_id,cluster_id, doi, pmid = row\n",
    "        node_id_to_PMID_mapping[node_id] = pmid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9fb23",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(node_id_to_PMID_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e21bf",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#It turns out that initial node ids is their PMID\n",
    "\n",
    "\n",
    "# for key, value in doi_dict.items():\n",
    "#     assert int(key) == int(value)    \n",
    "\n",
    "# with open('first_cluster_pmid.json', 'w') as json_file:\n",
    "#     json.dump(doi_dict, json_file, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce168bb",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('first_cluster_pmid.json', 'r') as json_file:\n",
    "#     doi_dict = json.load(json_file)\n",
    "    \n",
    "# pmid_dict = doi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2af2d",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Save all xmls\n",
    "all_xmls = {}\n",
    "import time\n",
    "\n",
    "def save_all_xmls(pmid):\n",
    "    wait = 0.25\n",
    "    time.sleep(wait)\n",
    "    pmid_dict = {}\n",
    "    request_str  = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id='\n",
    "    request_str += str(pmid)\n",
    "    \n",
    "    response = requests.get(request_str)\n",
    "    response_text = response.text\n",
    "    \n",
    "    try:\n",
    "        xml_dict = xmltodict.parse(response_text)\n",
    "        \n",
    "    except:\n",
    "        time.sleep(2 * wait)\n",
    "        return fetch_metadata_from_pmid(pmid)\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "for node_id, pmid in tqdm(node_id_to_PMID_mapping.items()):\n",
    "    all_xmls[node_id] = save_all_xmls(pmid)\n",
    "\n",
    "with open('first_cluster_xmls.json', 'w') as json_file:\n",
    "    json.dump(all_xmls, json_file, indent=4)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9485977d",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Load all XMLs\n",
    "import json\n",
    "\n",
    "with open('first_cluster_xmls.json', 'r') as json_file:\n",
    "    all_xmls = json.load(json_file)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a5bda0",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662\n"
     ]
    }
   ],
   "source": [
    "print(len(all_xmls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db269bba",
   "metadata": {},
   "source": [
    "<h1>Code to extract metadata from saved XMLs by parsing them </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d29decb9",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1662/1662 [00:13<00:00, 127.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed parse 0 which are: []\n",
      "Occured keyword dict: {'title': 1662, 'abstract': 1639, 'keyword': 105, 'grantlist': 702, 'meshheadinglist': 1592, 'chemicallist': 1586, 'datecompleted': 1643, 'journal': 1662}\n"
     ]
    }
   ],
   "source": [
    "#Mispelled\n",
    "import time\n",
    "import requests\n",
    "import xmltodict\n",
    "import tqdm\n",
    "\n",
    "parsed_error = []\n",
    "dict_of_interest = {'title':0, 'abstract': 0, 'keyword': 0, \"grantlist\": 0, \"meshheadinglist\": 0, \"chemicallist\":0, 'datecompleted': 0, 'journal': 0}\n",
    "journal_title_lookup_dict = {}\n",
    "journal_ISSN_lookup_dict = {}\n",
    "\n",
    "def fetch_metadata_from_pmid(response_text, idx, pmid): \n",
    "    global dict_of_interest\n",
    "    mesh_headings = []\n",
    "    grants = []\n",
    "    year = \"\"\n",
    "    journal_ISSN = \"\"\n",
    "    abstract = \"\"\n",
    "    chemical_list = []\n",
    "    meta_data = {}\n",
    "    journal_title = \"\"\n",
    "    pub_year = \"\"\n",
    "    keyword_list = []\n",
    "    article_title = \"\"\n",
    "\n",
    "    try:\n",
    "        xml_dict = xmltodict.parse(response_text)\n",
    "        if len(str(xml_dict))< 300:\n",
    "            parsed_error.append(pmid)\n",
    "            raise 'no data'\n",
    "        \n",
    "        for key_of_interest in dict_of_interest.keys():\n",
    "            if key_of_interest in str(xml_dict).lower():\n",
    "\n",
    "                dict_of_interest[key_of_interest] += 1\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            if 'DateCompleted' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']:\n",
    "                if 'Year' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['DateCompleted']:\n",
    "                    year = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['DateCompleted']['Year']\n",
    "\n",
    "            else:\n",
    "                  pass\n",
    "    \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "               if 'Abstract' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article'].keys():\n",
    "                    if 'AbstractText' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Abstract']:\n",
    "                        abstract = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Abstract']['AbstractText']\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "               if 'ArticleTitle' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article'].keys():\n",
    "                    article_title = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['ArticleTitle']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            if 'JournalIssue' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal'].keys():\n",
    "                if 'PubDate' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['JournalIssue']:\n",
    "                    if 'Year' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']:\n",
    "                        pub_year = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Year']\n",
    "                        \n",
    "            if 'ISSN' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal'].keys():\n",
    "                journal_ISSN = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['ISSN']['#text'] \n",
    "            \n",
    "            if 'Title' in  xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal'].keys():\n",
    "                journal_title = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['Title']\n",
    "                \n",
    "            if len(journal_ISSN) > 0 and len(journal_title)>0:\n",
    "                journal_ISSN_lookup_dict[journal_ISSN] = journal_title\n",
    "                journal_title_lookup_dict[journal_title] = journal_ISSN\n",
    "                \n",
    "            elif len(journal_ISSN) == 0:\n",
    "                if journal_title in journal_title_lookup_dict:\n",
    "                    journal_ISSN = journal_title_lookup_dict[journal_title]\n",
    "                    \n",
    "            elif len(journal_title) == 0:\n",
    "                if journal_ISSN in journal_ISSN_lookup_dict:\n",
    "                    journal_title = journal_ISSN_lookup_dict[journal_ISSN]                \n",
    "                \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e, pmid)\n",
    "        \n",
    "        \n",
    "        #Grant\n",
    "        #Very few grants don't have grant id's\n",
    "        #Grant institute could also be relevant\n",
    "        #TODO: collect missing grant id\n",
    "\n",
    "        try:\n",
    "            if 'GrantList' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']:\n",
    "                if type(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['GrantList']['Grant']) == list:\n",
    "                    for grant in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['GrantList']['Grant']:\n",
    "                        if 'GrantID' in grant:\n",
    "                            grants.append((grant['GrantID']))\n",
    "                            \n",
    "                else:\n",
    "                     grants.append(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['GrantList']['Grant']['GrantID'])\n",
    "                     pass   \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    " \n",
    "\n",
    "        #print(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['GrantList']['Grant'][0])\n",
    "        \n",
    "        #MeSH heading  \n",
    "        \n",
    "        try:\n",
    "              if 'KeywordList' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']:\n",
    "#                     print(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['KeywordList'].keys())\n",
    "#                     print(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['KeywordList']['Keyword'])\n",
    "#                     print(type(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['KeywordList']['Keyword']))\n",
    "#                     print(type(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['KeywordList']['Keyword']))\n",
    "                    if type(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['KeywordList']['Keyword']) == list:\n",
    "                        for key_word in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['KeywordList']['Keyword']:\n",
    "                            keyword_list.append(key_word['#text'])\n",
    "                    \n",
    "                    else:\n",
    "                        keyword_list.append(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['KeywordList']['Keyword']['#text'])\n",
    "                    \n",
    "\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        try:\n",
    "        #print(len(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']))\n",
    "        \n",
    "            #DescriptorName? Is a term\n",
    "            if 'MeshHeadingList' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']:\n",
    "                if type(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']) == list:\n",
    "                    for mesh in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']:\n",
    "    #                 print(mesh['DescriptorName'])\n",
    "    #                 print(mesh['DescriptorName']['@UI'])\n",
    "    #                 print(mesh['DescriptorName']['#text'])\n",
    "    \n",
    "                        if '@Type' in mesh['DescriptorName'].keys() and mesh['DescriptorName']['@Type'] == 'Geographic':\n",
    "                            continue\n",
    "                \n",
    "                \n",
    "                        mesh_headings.append((mesh['DescriptorName']['@UI']))\n",
    "            \n",
    "                else:\n",
    "                    mesh = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']['DescriptorName']\n",
    "                    if  (not '@Type' in mesh.keys() or mesh['@Type'] != 'Geographic'):\n",
    "                        mesh_headings.append(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']['DescriptorName']['@UI'])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        try:\n",
    "        #print(len(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['MeshHeadingList']['MeshHeading']))\n",
    "        \n",
    "            #DescriptorName? Is a term\n",
    "            if 'ChemicalList' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']:\n",
    "#                print(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']\n",
    "# #                      ['ChemicalList']['Chemical']['NameOfSubstance'])\n",
    "               #print(len(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['ChemicalList']['Chemical']))\n",
    "               if type(xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['ChemicalList']['Chemical']) == list:\n",
    "                   for substance in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['ChemicalList']['Chemical']:\n",
    "                        if substance['NameOfSubstance']['@UI'][0].lower() == 'c':\n",
    "                            chemical_list.append(substance['NameOfSubstance']['@UI'])\n",
    "                        \n",
    "               else:\n",
    "                       if substance['NameOfSubstance']['@UI'][0].lower() == 'c':\n",
    "                           xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['ChemicalList']['Chemical']['NameOfSubstance']['@UI'][0]\n",
    "                            \n",
    "                #print(chemical_list)\n",
    "                \n",
    "               \n",
    "              \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "        #References and history\n",
    "        #print(xml_dict['PubmedArticleSet']['PubmedArticle']['PubmedData'].keys())\n",
    "\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    if len(year) == 0:\n",
    "        year = pub_year\n",
    "        \n",
    "    meta_data = {'mesh': mesh_headings, 'grants': grants, 'year': year, \n",
    "                 'journal_ISSN': journal_ISSN,'journal_title': journal_title,\n",
    "                 'chemical' : chemical_list, 'pub_year': pub_year, 'keyword': keyword_list,\n",
    "                 'author': {}, 'title': article_title, 'abstract': abstract} \n",
    "    \n",
    "#     meta_data = {'title': article_title, 'abstract' : abstract}\n",
    "        \n",
    "    return meta_data\n",
    "\n",
    "metadata_dict = {}\n",
    "\n",
    "# [166, 719, 1672, 1918] odd\n",
    "\n",
    "idx = 0\n",
    "for key, value in tqdm.tqdm(all_xmls.items()):\n",
    "    metadata_dict[key] = fetch_metadata_from_pmid(value, idx, key)\n",
    "    idx += 1\n",
    "    \n",
    "\n",
    "\n",
    "print(f'failed parse {len(parsed_error)} which are: {parsed_error}')\n",
    "print(f'Occured keyword dict: {dict_of_interest}')\n",
    "\n",
    "with open('first_cluster_metadata.json', 'w') as json_file:\n",
    "    json.dump(metadata_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a21b37e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'BACKGROUND'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'MicroRNAs (miRNAs) are a class of recently discovered noncoding RNA genes that post-transcriptionally regulate gene expression. It is becoming clear that miRNAs play an important role in the regulation of gene expression during development. However, in mammals, expression data are principally based on whole tissue analysis and are still very incomplete.')]), OrderedDict([('@Label', 'RESULTS'), ('@NlmCategory', 'RESULTS'), ('#text', 'We used oligonucleotide arrays to analyze miRNA expression in the murine hematopoietic system. Complementary oligonucleotides capable of hybridizing to 181 miRNAs were immobilized on a membrane and probed with radiolabeled RNA derived from low molecular weight fractions of total RNA from several different hematopoietic and neuronal cells. This method allowed us to analyze cell type-specific patterns of miRNA expression and to identify miRNAs that might be important for cell lineage specification and/or cell effector functions.')]), OrderedDict([('@Label', 'CONCLUSION'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', 'This is the first report of systematic miRNA gene profiling in cells of the hematopoietic system. As expected, miRNA expression patterns were very different between hematopoietic and non-hematopoietic cells, with further subtle differences observed within the hematopoietic group. Interestingly, the most pronounced similarities were observed among fully differentiated effector cells (Th1 and Th2 lymphocytes and mast cells) and precursors at comparable stages of differentiation (double negative thymocytes and pro-B cells), suggesting that in addition to regulating the process of commitment to particular cellular lineages, miRNAs might have an important general role in the mechanism of cell differentiation and maintenance of cell identity.')])]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'BACKGROUND'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'The microRNAs (miRNAs) are an extensive class of small noncoding RNAs (18 to 25 nucleotides) with probable roles in the regulation of gene expression. In Caenorhabditis elegans, lin-4 and let-7 miRNAs control the timing of fate specification of neuronal and hypodermal cells during larval development. lin-4, let-7 and other miRNA genes are conserved in mammals, and their potential functions in mammalian development are under active study.')]), OrderedDict([('@Label', 'RESULTS'), ('@NlmCategory', 'RESULTS'), ('#text', \"In order to identify mammalian miRNAs that might function in development, we characterized the expression of 119 previously reported miRNAs in adult organs from mouse and human using northern blot analysis. Of these, 30 miRNAs were specifically expressed or greatly enriched in a particular organ (brain, lung, liver or skeletal muscle). This suggests organ- or tissue-specific functions for miRNAs. To test if any of the 66 brain-expressed miRNAs were present in neurons, embryonal carcinoma cells were treated with all-trans-retinoic acid to promote neuronal differentiation. A total of 19 brain-expressed miRNAs (including lin-4 and let-7 orthologs) were coordinately upregulated in both human and mouse embryonal carcinoma cells during neuronal differentiation. The mammalian ortholog of C. elegans lin-28, which is downregulated by lin-4 in worms via 3' untranslated region binding, was also repressed during neuronal differentiation of mammalian embryonal carcinoma cells. Mammalian lin-28 messenger RNAs contain conserved predicted binding sites in their 3' untranslated regions for neuron-expressed miR-125b (a lin-4 ortholog), let-7a, and miR-218.\")]), OrderedDict([('@Label', 'CONCLUSIONS'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', 'The identification of a subset of brain-expressed miRNAs whose expression behavior is conserved in both mouse and human differentiating neurons implicates these miRNAs in mammalian neuronal development or function.')])]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'BACKGROUND'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'MicroRNAs (miRNAs) are regulatory RNA molecules that are specified by their mode of action, the structure of primary transcripts, and their typical size of 20-24 nucleotides. Frequently, not only single miRNAs but whole families of closely related miRNAs have been found in animals and plants. Some families are widely conserved among different plant taxa. Hence, it is evident that these conserved miRNAs are of ancient origin and indicate essential functions that have been preserved over long evolutionary time scales. In contrast, other miRNAs seem to be species-specific and consequently must possess very distinct functions. Thus, the analysis of an early-branching species provides a window into the early evolution of fundamental regulatory processes in plants.')]), OrderedDict([('@Label', 'RESULTS'), ('@NlmCategory', 'RESULTS'), ('#text', 'Based on a combined experimental-computational approach, we report on the identification of 48 novel miRNAs and their putative targets in the moss Physcomitrella patens. From these, 18 miRNAs and two targets were verified in independent experiments. As a result of our study, the number of known miRNAs in Physcomitrella has been raised to 78. Functional assignments to mRNAs targeted by these miRNAs revealed a bias towards genes that are involved in regulation, cell wall biosynthesis and defense. Eight miRNAs were detected with different expression in protonema and gametophore tissue. The miRNAs 1-50 and 2-51 are located on a shared precursor that are separated by only one nucleotide and become processed in a tissue-specific way.')]), OrderedDict([('@Label', 'CONCLUSION'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', 'Our data provide evidence for a surprisingly diverse and complex miRNA population in Physcomitrella. Thus, the number and function of miRNAs must have significantly expanded during the evolution of early land plants. As we have described here within, the coupled maturation of two miRNAs from a shared precursor has not been previously identified in plants.')])]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'BACKGROUND'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'MicroRNAs (miRNAs) are small noncoding RNAs that bind mRNA target transcripts and repress gene expression. They have been implicated in multiple diseases, such as cancer, but the mechanisms of this involvement are not well understood. Given the complexity and degree of interactions between miRNAs and target genes, understanding how miRNAs achieve their specificity is important to understanding miRNA function and identifying their role in disease.')]), OrderedDict([('@Label', 'RESULTS'), ('@NlmCategory', 'RESULTS'), ('#text', \"Here we report factors that influence miRNA regulation by considering the effects of both single and multiple miRNAs targeting human genes. In the case of single miRNA targeting, we developed a metric that integrates miRNA and mRNA expression data to calculate how changes in miRNA expression affect target mRNA expression. Using the metric, our global analysis shows that the repression of a given miRNA on a target mRNA is modulated by 3' untranslated region length, the number of target sites, and the distance between a pair of binding sites. Additionally, we show that some miRNAs preferentially repress transcripts with longer CTG repeats, suggesting a possible role for miRNAs in repeat expansion disorders such as myotonic dystrophy. We also examine the large class of genes targeted by multiple miRNAs and show that specific types of genes are progressively more enriched as the number of targeting miRNAs increases. Expression microarray data further show that these highly targeted genes are downregulated relative to genes targeted by few miRNAs, which suggests that highly targeted genes are tightly regulated and that their dysregulation may lead to disease. In support of this idea, cancer genes are strongly enriched among highly targeted genes.\")]), OrderedDict([('@Label', 'CONCLUSION'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', \"Our data show that the rules governing miRNA targeting are complex, but that understanding the mechanisms that drive such control can uncover miRNAs' role in disease. Our study suggests that the number and arrangement of miRNA recognition sites can influence the degree and specificity of miRNA-mediated gene repression.\")])]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'BACKGROUND'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'MicroRNA (miRNA) encoding genes are abundant in vertebrate genomes but very few have been studied in any detail. Bioinformatic tools allow prediction of miRNA targets and this information coupled with knowledge of miRNA expression profiles facilitates formulation of hypotheses of miRNA function. Although the central nervous system (CNS) is a prominent site of miRNA expression, virtually nothing is known about the spatial and temporal expression profiles of miRNAs in the brain. To provide an overview of the breadth of miRNA expression in the CNS, we performed a comprehensive analysis of the neuroanatomical expression profiles of 38 abundant conserved miRNAs in developing and adult zebrafish brain.')]), OrderedDict([('@Label', 'RESULTS'), ('@NlmCategory', 'RESULTS'), ('#text', 'Our results show miRNAs have a wide variety of different expression profiles in neural cells, including: expression in neuronal precursors and stem cells (for example, miR-92b); expression associated with transition from proliferation to differentiation (for example, miR-124); constitutive expression in mature neurons (miR-124 again); expression in both proliferative cells and their differentiated progeny (for example, miR-9); regionally restricted expression (for example, miR-222 in telencephalon); and cell-type specific expression (for example, miR-218a in motor neurons).')]), OrderedDict([('@Label', 'CONCLUSION'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', 'The data we present facilitate prediction of likely modes of miRNA function in the CNS and many miRNA expression profiles are consistent with the mutual exclusion mode of function in which there is spatial or temporal exclusion of miRNAs and their targets. However, some miRNAs, such as those with cell-type specific expression, are more likely to be co-expressed with their targets. Our data provide an important resource for future functional studies of miRNAs in the CNS.')])]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'BACKGROUND'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'MicroRNAs (miRNAs) are a class of non-coding, endogenous, small RNAs that negatively regulate gene expression by inducing degradation or translational inhibition of target mRNAs. Aberrant expression of miRNAs appears to be a common characteristic of hematological malignancies including leukemias.')]), OrderedDict([('@Label', 'AIM'), ('@NlmCategory', 'OBJECTIVE'), ('#text', 'Here we review the available data supporting a role of aberrant expression of miRNAs in the pathogenesis of leukemias including acute myeloid leukemia (AML), acute lymphoblastic leukemia (ALL), chronic myeloid leukemia (CML), and chronic lymphocytic leukemia (CLL).')]), OrderedDict([('@Label', 'CONCLUSIONS'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', 'The expression signatures of miRNAs provide exciting opportunities in the diagnosis, prognosis, and therapy of leukemia. Since miRNAs can function as either oncogenes or tumor suppressor genes in leukemogenesis, the potential of using these small RNAs as therapeutic targets opens up new opportunities for leukemia therapy by either inhibiting or augmenting their activity.')])]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'collections.OrderedDict'>\n",
      "OrderedDict([('i', ['cis', 'trans']), ('#text', 'MicroRNAs (miRNAs) are important regulators of gene expression that bind complementary target mRNAs and repress their expression. Precursor miRNA molecules undergo nuclear and cytoplasmic processing events, carried out by the endoribonucleases DROSHA and DICER, respectively, to produce mature miRNAs that are loaded onto the RISC (RNA-induced silencing complex) to exert their biological function. Regulation of mature miRNA levels is critical in development, differentiation, and disease, as demonstrated by multiple levels of control during their biogenesis cascade. Here, we will focus on post-transcriptional mechanisms and will discuss the impact of -acting sequences in precursor miRNAs, as well as -acting factors that bind to these precursors and influence their processing. In particular, we will highlight the role of general RNA-binding proteins (RBPs) as factors that control the processing of specific miRNAs, revealing a complex layer of regulation in miRNA production and function.')])\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'BACKGROUND'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'MicroRNAs (miRNAs) are a recently discovered class of non-coding RNAs (ncRNAs) which play important roles in eukaryotic gene regulation. miRNA biogenesis and activation is a complex process involving multiple protein catalysts and involves the large macromolecular RNAi Silencing Complex or RISC. While phylogenetic analyses of miRNA genes have been previously published, the evolution of miRNA biogenesis itself has been little studied. In order to better understand the origin of miRNA processing in animals and plants, we determined the phyletic occurrences and evolutionary relationships of four major miRNA pathway protein components; Dicer, Argonaute, RISC RNA-binding proteins, and Exportin-5.')]), OrderedDict([('@Label', 'RESULTS'), ('@NlmCategory', 'RESULTS'), ('#text', 'Phylogenetic analyses show that all four miRNA pathway proteins were derived from large multiple protein families. As an example, vertebrate and invertebrate Argonaute (Ago) proteins diverged from a larger family of PIWI/Argonaute proteins found throughout eukaryotes. Further gene duplications among vertebrates after the evolution of chordates from urochordates but prior to the emergence of fishes lead to the evolution of four Ago paralogues. Invertebrate RISC RNA-binding proteins R2D2 and Loquacious are related to other RNA-binding protein families such as Staufens as well as vertebrate-specific TAR (HIV trans-activator RNA) RNA-binding protein (TRBP) and protein kinase R-activating protein (PACT). Export of small RNAs from the nucleus, including miRNA, is facilitated by three closely related karyopherin-related nuclear transporters, Exportin-5, Exportin-1 and Exportin-T. While all three exportins have direct orthologues in deutrostomes, missing exportins in arthropods (Exportin-T) and nematodes (Exportin-5) are likely compensated by dual specificities of one of the other exportin paralogues.')]), OrderedDict([('@Label', 'CONCLUSION'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', 'Co-opting particular isoforms from large, diverse protein families seems to be a common theme in the evolution of miRNA biogenesis. Human miRNA biogenesis proteins have direct, orthologues in cold-blooded fishes and, in some cases, urochordates and deutrostomes. However, lineage specific expansions of Dicer in plants and invertebrates as well as Argonaute and RNA-binding proteins in vertebrates suggests that novel ncRNA regulatory mechanisms can evolve in relatively short evolutionary timeframes. The occurrence of multiple homologues to RNA-binding and Argonaute/PIWI proteins also suggests the possible existence of further pathways for additional types of ncRNAs.')])]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'collections.OrderedDict'>\n",
      "OrderedDict([('i', 'via'), ('#text', 'MicroRNAs (miRNAs), a class of single-stranded non-coding RNA of about 22 nucleotides, are potent regulators of gene expression existing in both plants and animals. Recent studies showed that plant miRNAs could enter mammalian bloodstream  gastrointestinal tract, through which access a variety of tissues and cells of recipients to exert therapeutic effects. This intriguing phenomenon indicates that miRNAs of diet/plant origin may act as a new class of bioactive ingredients communicating with mammalian systems. In this review, in order to pinpoint the reason underlying discrepancies of miRNAs transmission from diet/plant to animals, the pathways that generate miRNAs and machineries involved in the functions of miRNAs in both kingdoms were outlined and compared. Then, the current controversies concerning cross-kingdom regulations and the potential mechanisms responsible for absorption and transfer of diet/plant-derived miRNAs were interpreted. Furthermore, the hormone-like action of miRNAs and the intricate interplay between miRNAs and hormones were implicated. Finally, how these findings may impact nutrition and medicine were briefly discussed.')])\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'BACKGROUND'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'During microRNA (miRNA) maturation in humans and flies, Drosha and Dicer cut the precursor transcript, thereby producing a short RNA duplex. One strand of this duplex becomes a functional component of the RNA-Induced Silencing Complex (RISC), while the other is eliminated. While thermodynamic asymmetry of the duplex ends appears to play a decisive role in the strand selection process, the details of the selection mechanism are not yet understood.')]), OrderedDict([('@Label', 'RESULTS'), ('@NlmCategory', 'RESULTS'), ('#text', 'Here, we assess miRNA strand selection bias in humans and fruit flies by analyzing the sequence composition and relative expression levels of the two strands of the precursor duplex in these species. We find that the sequence elements associated with preferential miRNA strand selection and/or rejection differ between the two species. Further, we identify another feature that distinguishes human and fly miRNA processing machinery: the relative accuracy of the Drosha and Dicer enzymes.')]), OrderedDict([('@Label', 'CONCLUSION'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', 'Our result provides clues to the mechanistic aspects of miRNA strand selection in humans and other mammals. Further, it indicates that human and fly miRNA processing pathways are more distinct than currently recognized. Finally, the observed strand selection determinants are instrumental in the rational design of efficient miRNA-based expression regulators.')])]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'BACKGROUND'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'A class of eukaryotic non-coding RNAs termed microRNAs (miRNAs) interact with target mRNAs by sequence complementarity to regulate their expression. The low abundance of some miRNAs and their time- and tissue-specific expression patterns make experimental miRNA identification difficult. We present here a computational method for genome-wide prediction of Arabidopsis thaliana microRNAs and their target mRNAs. This method uses characteristic features of known plant miRNAs as criteria to search for miRNAs conserved between Arabidopsis and Oryza sativa. Extensive sequence complementarity between miRNAs and their target mRNAs is used to predict miRNA-regulated Arabidopsis transcripts.')]), OrderedDict([('@Label', 'RESULTS'), ('@NlmCategory', 'RESULTS'), ('#text', \"Our prediction covered 63% of known Arabidopsis miRNAs and identified 83 new miRNAs. Evidence for the expression of 25 predicted miRNAs came from northern blots, their presence in the Arabidopsis Small RNA Project database, and massively parallel signature sequencing (MPSS) data. Putative targets functionally conserved between Arabidopsis and O. sativa were identified for most newly identified miRNAs. Independent microarray data showed that the expression levels of some mRNA targets anti-correlated with the accumulation pattern of their corresponding regulatory miRNAs. The cleavage of three target mRNAs by miRNA binding was validated in 5' RACE experiments.\")]), OrderedDict([('@Label', 'CONCLUSIONS'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', 'We identified new plant miRNAs conserved between Arabidopsis and O. sativa and report a wide range of transcripts as potential miRNA targets. Because MPSS data are generated from polyadenylated RNA molecules, our results suggest that at least some miRNA precursors are polyadenylated at certain stages. The broad range of putative miRNA targets indicates that miRNAs participate in the regulation of a variety of biological processes.')])]\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'BACKGROUND'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'MicroRNAs are a large new class of tiny regulatory RNAs found in nematodes, plants, insects and mammals. MicroRNAs are thought to act as post-transcriptional modulators of gene expression. In invertebrates microRNAs have been implicated as regulators of developmental timing, neuronal differentiation, cell proliferation, programmed cell death and fat metabolism. Little is known about the roles of microRNAs in mammals.')]), OrderedDict([('@Label', 'RESULTS'), ('@NlmCategory', 'RESULTS'), ('#text', 'We isolated 18-26 nucleotide RNAs from developing rat and monkey brains. From the sequences of these RNAs and the sequences of the rat and human genomes we determined which of these small RNAs are likely to have derived from stem-loop precursors typical of microRNAs. Next, we developed a microarray technology suitable for detecting microRNAs and printed a microRNA microarray representing 138 mammalian microRNAs corresponding to the sequences of the microRNAs we cloned as well as to other known microRNAs. We used this microarray to determine the profile of microRNAs expressed in the developing mouse brain. We observed a temporal wave of expression of microRNAs, suggesting that microRNAs play important roles in the development of the mammalian brain.')]), OrderedDict([('@Label', 'CONCLUSION'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', 'We describe a microarray technology that can be used to analyze the expression of microRNAs and of other small RNAs. MicroRNA microarrays offer a new tool that should facilitate studies of the biological roles of microRNAs. We used this method to determine the microRNA expression profile during mouse brain development and observed a temporal wave of gene expression of sequential classes of microRNAs.')])]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'BACKGROUND'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'The injection of double-stranded RNA (dsRNA) has been shown to induce a potent sequence-specific inhibition of gene function in diverse invertebrate and vertebrate species. The homology-dependent posttranscriptional gene silencing (PTGS) caused by the introduction of transgenes in plants may be mediated by dsRNA. The analysis of Caenorhabditis elegans mutants impaired with dsRNA-mediated silencing and studies in plants implicate a biological role of dsRNA-mediated silencing as a transposon-repression and antiviral mechanism.')]), OrderedDict([('@Label', 'RESULTS'), ('@NlmCategory', 'RESULTS'), ('#text', 'We investigated the silencing of testis-expressed Stellate genes by paralogous Su(Ste) tandem repeats, which are known to be involved in the maintenance of male fertility in Drosophila melanogaster. We found that both strands of repressor Su(Ste) repeats are transcribed, producing sense and antisense RNA. The Stellate silencing is associated with the presence of short Su(Ste) RNAs. Cotransfection experiments revealed that Su(Ste) dsRNA can target and eliminate Stellate transcripts in Drosophila cell culture. The short fragment of Stellate gene that is homologous to Su(Ste) was shown to be sufficient to confer Su(Ste)-dependent silencing of a reporter construct in testes. We demonstrated that Su(Ste) dsRNA-mediated silencing affects not only Stellate expression but also the level of sense Su(Ste) RNA providing a negative autogenous regulation of Su(Ste) expression. Mutation in the spindle-E gene relieving Stellate silencing also leads to a derepression of the other genomic tandem repeats and retrotransposons in the germline.')]), OrderedDict([('@Label', 'CONCLUSIONS'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', 'Homology-dependent gene silencing was shown to be used to inhibit Stellate gene expression in the D. melanogaster germline, ensuring male fertility. dsRNA-mediated silencing may provide a basis for negative autogenous control of gene expression. The related surveillance system is implicated to control expression of retrotransposons in the germline.')])]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'CONTEXT'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'MicroRNAs have potential as diagnostic biomarkers and therapeutic targets in cancer. No study has evaluated the association between microRNA expression patterns and colon cancer prognosis or therapeutic outcome.')]), OrderedDict([('@Label', 'OBJECTIVE'), ('@NlmCategory', 'OBJECTIVE'), ('#text', 'To identify microRNA expression patterns associated with colon adenocarcinomas, prognosis, or therapeutic outcome.')]), OrderedDict([('@Label', 'DESIGN, SETTING, AND PATIENTS'), ('@NlmCategory', 'METHODS'), ('#text', 'MicroRNA microarray expression profiling of tumors and paired nontumorous tissues was performed on a US test cohort of 84 patients with incident colon adenocarcinoma, recruited between 1993 and 2002. We evaluated associations with tumor status, TNM staging, survival prognosis, and response to adjuvant chemotherapy. Associations were validated in a second, independent Chinese cohort of 113 patients recruited between 1991 and 2000, using quantitative reverse transcription polymerase chain reaction assays. The final date of follow-up was December 31, 2005, for the Maryland cohort and August 16, 2004, for the Hong Kong cohort.')]), OrderedDict([('@Label', 'MAIN OUTCOME MEASURES'), ('@NlmCategory', 'METHODS'), ('#text', 'MicroRNAs that were differentially expressed in tumors and microRNA expression patterns associated with survival using cancer-specific death as the end point. RESULTS Thirty-seven microRNAs were differentially expressed in tumors from the test cohort. Selected for validation were miR-20a, miR-21, miR-106a, miR-181b, and miR-203, and all 5 were enriched in tumors from the validation cohort (P < .001). Higher miR-21 expression was present in adenomas (P = .006) and in tumors with more advanced TNM staging (P < .001). In situ hybridization demonstrated miR-21 to be expressed at high levels in colonic carcinoma cells. The 5-year cancer-specific survival rate was 57.5% for the Maryland cohort and was 49.5% for the Hong Kong cohort. High miR-21 expression was associated with poor survival in both the training (hazard ratio, 2.5; 95% confidence interval, 1.2-5.2) and validation cohorts (hazard ratio, 2.4; 95% confidence interval, 1.4-3.9), independent of clinical covariates, including TNM staging, and was associated with a poor therapeutic outcome.')]), OrderedDict([('@Label', 'CONCLUSIONS'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', 'Expression patterns of microRNAs are systematically altered in colon adenocarcinomas. High miR-21 expression is associated with poor survival and poor therapeutic outcome.')])]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[OrderedDict([('@Label', 'BACKGROUND'), ('@NlmCategory', 'BACKGROUND'), ('#text', 'MicroRNAs (miRNAs) mediate a form of translational regulation in animals. Hundreds of animal miRNAs have been identified, but only a few of their targets are known. Prediction of miRNA targets for translational regulation is challenging, since the interaction with the target mRNA usually occurs via incomplete and interrupted base pairing. Moreover, the rules that govern such interactions are incompletely defined.')]), OrderedDict([('@Label', 'RESULTS'), ('@NlmCategory', 'RESULTS'), ('#text', 'MovingTargets is a software program that allows a researcher to predict a set of miRNA targets that satisfy an adjustable set of biological constraints. We used MovingTargets to identify a high-likelihood set of 83 miRNA targets in Drosophila, all of which adhere to strict biological constraints. We tested and verified 3 of these predictions in cultured cells, including a target for the Drosophila let-7 homolog. In addition, we utilized the flexibility of MovingTargets by relaxing the biological constraints to identify and validate miRNAs targeting tramtrack, a gene also known to be subject to translational control dependent on the RNA binding protein Musashi.')]), OrderedDict([('@Label', 'CONCLUSION'), ('@NlmCategory', 'CONCLUSIONS'), ('#text', 'MovingTargets is a flexible tool for the accurate prediction of miRNA targets in Drosophila. MovingTargets can be used to conduct a genome-wide search of miRNA targets using all Drosophila miRNAs and potential targets, or it can be used to conduct a focused search for miRNAs targeting a specific gene. In addition, the values for a set of biological constraints used to define a miRNA target are adjustable, allowing the software to incorporate the rules used to characterize a miRNA target as these rules are experimentally determined and interpreted.')])]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-eb438f6c45b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetadata_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m'microrna'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmicrorna_title\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abstract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# microrna_title = 0\n",
    "# microrna_abstract = 0\n",
    "\n",
    "# for key, value in metadata_dict.items():\n",
    "#     if 'microrna' in value['title'].lower():\n",
    "#         microrna_title += 1\n",
    "#     print(type(value['abstract']))\n",
    "    \n",
    "#     if type(value['abstract']) == str:    \n",
    "    \n",
    "#         microrna_abstract += 1\n",
    "      \n",
    "# print(microrna_title)\n",
    "# print(microrna_abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018691bc",
   "metadata": {},
   "source": [
    "<h1>Adding author information </h1>\n",
    "<p> Now through Scopus API (to which we have subscription) we retrieve authors for each dois. Turns out 2003/2004 papers have doi, and some authors are not available</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23ef219",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Wait 1 minute for this cell to run ...\n",
    "from pybliometrics.scopus import AbstractRetrieval\n",
    "import tqdm\n",
    "pmid_authors_dict = {}\n",
    "i = 0\n",
    "failed_authors = []\n",
    "for node_id, pmid in node_id_to_PMID_mapping.items():\n",
    "\n",
    "    author_id_array = []\n",
    "\n",
    "    try:\n",
    "        ab = AbstractRetrieval(value)\n",
    "        for author in ab.authors:\n",
    "            author_id_array.append(author.auid)      \n",
    "    except:\n",
    "        failed_authors.append(value)\n",
    "        \n",
    "    pmid_authors_dict[pmid] = author_id_array\n",
    "\n",
    "for pmid, auth_arr in pmid_authors_dict.items():\n",
    "    metadata_dict[pmid]['author'] = auth_arr\n",
    "\n",
    " \n",
    "print(f'failed: {len(failed_authors)} success: {len(pmid_authors_dict)-len(failed_authors)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d78220",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Now save the complete metadata\n",
    "\n",
    "with open('meta_data_dict.json', 'w') as json_file:\n",
    "    json.dump(metadata_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb6921",
   "metadata": {},
   "source": [
    "Turns out that out of 2004 papers of CEN cluster1, 11 of those don't have any metadata. That leaves us with 1993 samples. The above dictionary tells us the frequence of keyword occurence. The bellow one tells us the frequency of actual recorded value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2472e",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Count incomplete data\n",
    "\n",
    "features = {'keyword':0, 'mesh': 0, 'grants': 0, 'year': 0,\n",
    "             \"journal_ISSN\":0, 'chemical' : 0, 'pub_year': 0}\n",
    "#Mesh terms are sometimes unrelated\n",
    "\n",
    "mesh_length = []\n",
    "chemical_length = []\n",
    "\n",
    "for feature in features.keys():\n",
    "    for _, meta in metadata_dict.items():\n",
    "        if len(meta[feature]) > 0:\n",
    "            features[feature] += 1\n",
    "            if feature == 'mesh':\n",
    "                mesh_length.append(len(meta[feature]))\n",
    "            \n",
    "            elif feature == 'chemical':\n",
    "                chemical_length.append(len(meta[feature]))\n",
    "                \n",
    "            \n",
    "print(\"recorded features \", features)\n",
    "print(f\"avg mesh length: {np.mean(mesh_length)} std: {np.std(mesh_length)}\" )\n",
    "print(f\"avg chemical length: {np.mean(chemical_length)} std: {np.std(chemical_length)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0c402",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('first_cluster_metadata.json', 'w') as json_file:\n",
    "    json.dump(metadata_dict, json_file, indent=4)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b161bb",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the metadata file\n",
    "with open('first_cluster_metadata.json', 'r') as json_file:\n",
    "    metadata_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9512e5",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_dict_similarity(dict_1, dict_2, mode ): \n",
    "    similarity = 0\n",
    "    modes = ['number_of_common_terms', 'jaccard']\n",
    "    \n",
    "    assert mode in modes\n",
    "    \n",
    "    for key in dict_1:\n",
    "            if key in dict_2:\n",
    "                similarity += 1\n",
    "                \n",
    "    \n",
    "    if mode == 'number_of_common_terms':\n",
    "        pass\n",
    "       \n",
    "    elif mode == 'jaccard':\n",
    "        similarity = similarity / (len(dict_1) + len(dict_2))\n",
    "        \n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443af2b5",
   "metadata": {},
   "source": [
    "<h1> Defining MeSH similarity </h1>\n",
    "<p> First we need to find similarity for each MeSH pair. For now we just find the number of common terms by adding a . after the first letter. We will normalize by the total number.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef67e175",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "max_mesh_overlap = 0\n",
    "import json\n",
    "\n",
    "with open('all_mesh_terms.json', 'r') as json_file:\n",
    "    all_mesh_terms = json.load(json_file)\n",
    "    \n",
    "# print(all_mesh_terms)\n",
    "    \n",
    "def calculate_mesh_pair_similarity(mesh1, mesh2):\n",
    "    global max_mesh_overlap\n",
    "\n",
    "    mesh1 = mesh1[0] + '.' + mesh1[1:]\n",
    "    mesh2 = mesh2[0] + '.' + mesh2[1:]    \n",
    "    \n",
    "    mesh_1_decomp = mesh1.split('.')\n",
    "    mesh_2_decomp = mesh2.split('.')\n",
    "    \n",
    "    \n",
    "    common_terms = 0\n",
    "    limit = min(len(mesh_1_decomp), len(mesh_2_decomp))\n",
    "    for i in range(limit):\n",
    "        if mesh_1_decomp[i] == mesh_2_decomp[i]:\n",
    "            common_terms += 1\n",
    "        \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    if common_terms > max_mesh_overlap:\n",
    "        max_mesh_overlap = common_terms\n",
    "        \n",
    "    return common_terms\n",
    "\n",
    "print(calculate_mesh_pair_similarity('C23.300.820', 'C23.550.291.125'))\n",
    "\n",
    "def calculate_mesh_similarity_for_two_papers(pmid1, pmid2, mode):\n",
    "    assert mode in ['median', 'mean', 'max', 'min']\n",
    "    similarities = []\n",
    "    mesh_terms_1 = metadata_dict[pmid1]['mesh']\n",
    "    mesh_terms_2 = metadata_dict[pmid2]['mesh']\n",
    "    \n",
    "    for first in mesh_terms_1:\n",
    "        first_mesh_tree = all_mesh_terms[first]\n",
    "        for second in mesh_terms_2:\n",
    "            second_mesh_tree = all_mesh_terms[second]\n",
    "            similarities.append(calculate_mesh_pair_similarity(first_mesh_tree, second_mesh_tree))\n",
    "    \n",
    "    if len(similarities) == 0:\n",
    "        return -1\n",
    "    \n",
    "    else:\n",
    "        if mode == 'median':\n",
    "            return np.median(similarities)\n",
    "        \n",
    "        if mode == 'mean':\n",
    "            return np.mean(similarities)\n",
    "        \n",
    "        if mode == 'max':\n",
    "            return np.max(similarities)\n",
    "        \n",
    "        if mode == 'min':\n",
    "            return np.min(similarities)\n",
    "\n",
    "first_dummy_pmid = '3734909'\n",
    "second_dummy_pmid = '324738'\n",
    "\n",
    "print(calculate_mesh_similarity_for_two_papers(first_dummy_pmid, second_dummy_pmid, 'mean'))   \n",
    "print(metadata_dict[first_dummy_pmid]['mesh'], metadata_dict[second_dummy_pmid]['mesh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a7e782",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Calculate similarity between two pmid's\n",
    "#Lets call it metric for now. This is unnormalized\n",
    "def calculate_similarity(pmid1, pmid2, feature):\n",
    "    \n",
    "    metric = 0\n",
    "    pmid1 = str(pmid1)\n",
    "    pmid2 = str(pmid2)\n",
    "    \n",
    "    assert feature in ['keyword','year', 'mesh_jaccard', 'mesh_tree'\n",
    "                       , 'chemical', 'co-citation', 'bib-coupling', 'grants', 'journal', 'author']\n",
    "    if feature == 'year':             \n",
    "                year1 = metadata_dict[pmid1][feature]\n",
    "                year2 = metadata_dict[pmid2][feature]\n",
    "                \n",
    "                if len(year1) > 0 and len(year2)>0:\n",
    "                    metric = np.abs(int(year1)-int(year2))\n",
    "                \n",
    "                else:\n",
    "                    metric = -1\n",
    "                    \n",
    "    if feature == 'journal':\n",
    "        issn1 = metadata_dict[pmid1]['journal_ISSN']\n",
    "        issn2 = metadata_dict[pmid2]['journal_ISSN']\n",
    "        \n",
    "        title1 = metadata_dict[pmid1]['journal_title']\n",
    "        title2 = metadata_dict[pmid2]['journal_title']\n",
    "        \n",
    "        \n",
    "        if len(issn1)>0 and len(issn2)>0:\n",
    "            metric = int(issn1==issn2)\n",
    "        \n",
    "        \n",
    "  \n",
    "        elif len(title1)>0 and len(title2)>0:\n",
    "            metric = int(title1==title2)\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            metric = -1\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    #They are both treated the same way ...\n",
    "    elif feature == 'mesh_jaccard' or feature == 'chemical':\n",
    "        if feature == 'mesh_jaccard':\n",
    "            feature = 'mesh'\n",
    "            \n",
    "        terms_1 = {}\n",
    "        terms_2 = {}\n",
    "        \n",
    "        for term in metadata_dict[pmid1][feature]:\n",
    "            terms_1[term] = 1\n",
    "    \n",
    "        for term in metadata_dict[pmid2][feature]:\n",
    "            terms_2[term] = 1\n",
    "        \n",
    "        if len(terms_1) > 0 and len(terms_2)>0:\n",
    "            metric = calculate_dict_similarity(terms_1, terms_2, 'jaccard')\n",
    "                    \n",
    "        else:\n",
    "            metric = -1\n",
    "            \n",
    "    elif feature == 'mesh_tree':\n",
    "        metric = calculate_mesh_similarity_for_two_papers(pmid1, pmid2, 'mean')\n",
    "        \n",
    "            \n",
    "    elif feature == 'bib-coupling':\n",
    "        \n",
    "        node_1 = node_lookup_dict[pmid1]\n",
    "        node_2 = node_lookup_dict[pmid2]\n",
    "        \n",
    "        common = np.dot(adj_matrix[node_1,:], adj_matrix[node_2, :])\n",
    "        denom = np.sum(adj_matrix[node_1, :]) + np.sum(adj_matrix[node_2, :]) - common\n",
    "        \n",
    "        if denom > 0 :\n",
    "            metric = (common / denom)\n",
    "        \n",
    "    \n",
    "    elif feature == 'co-citation':\n",
    "        node_1 = node_lookup_dict[pmid1]\n",
    "        node_2 = node_lookup_dict[pmid2]\n",
    "        \n",
    "        common = np.dot(adj_matrix[: , node_1], adj_matrix[: , node_2])\n",
    "        denom = np.sum(adj_matrix[:, node_1]) + np.sum(adj_matrix[:, node_2]) - common\n",
    "        \n",
    "        if denom > 0 :\n",
    "            metric = (common / denom)\n",
    "            \n",
    "    \n",
    "    elif feature == 'grants':\n",
    "        grants_1 = metadata_dict[pmid1]['grants']\n",
    "        grants_2 = metadata_dict[pmid2]['grants']\n",
    "       \n",
    "        \n",
    "        for first in grants_1:\n",
    "            for second in grants_2:\n",
    "                if first == second:\n",
    "                    metric +=1\n",
    "                    \n",
    "    elif feature == 'author':\n",
    "        author_1 = {}\n",
    "        author_2 = {}\n",
    "        \n",
    "        for term in metadata_dict[pmid1][feature]:\n",
    "            author_1[term] = 1\n",
    "    \n",
    "        for term in metadata_dict[pmid2][feature]:\n",
    "            author_2[term] = 1\n",
    "        \n",
    "        if len(author_1) > 0 and len(author_2)>0:\n",
    "            metric = calculate_dict_similarity(author_1, author_2, 'jaccard')\n",
    "            \n",
    "        else:\n",
    "            metric = -1\n",
    "       \n",
    "        \n",
    "                    \n",
    "    elif feature == 'keyword':\n",
    "        keyword_1 = metadata_dict[pmid1]['keyword']\n",
    "        keyword_2 = metadata_dict[pmid2]['keyword']\n",
    "       \n",
    "        if len(keyword_1) == 0 or len(keyword_2)== 0:\n",
    "            metric = -1\n",
    "        \n",
    "        else:\n",
    "            common = 0\n",
    "            for first in keyword_1:\n",
    "                for second in keyword_2:\n",
    "                    if first == second:\n",
    "                        common +=1\n",
    "\n",
    "\n",
    "            metric = common/(len(keyword_1)+len(keyword_2)-common)\n",
    "\n",
    "                    \n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c7268",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_three_hop_similarity():\n",
    "    #Is currently inefficient as relies on matrix multiplication\n",
    "    # We use undirected edges\n",
    "    aggregated_three_hop_similarity = np.zeros_like(adj_matrix)\n",
    "    undirected_adj_matrix = adj_matrix + adj_matrix.transpose()\n",
    "    second_hop_distance = np.matmul(undirected_adj_matrix, undirected_adj_matrix)\n",
    "    \n",
    "    three_hop_distance = np.matmul(second_hop_distance, undirected_adj_matrix)\n",
    "    \n",
    "    for i in tqdm.tqdm(range(adj_matrix.shape[0])):\n",
    "        for j in range(i):\n",
    "            similarity = 0\n",
    "            if undirected_adj_matrix[i][j] == 1:\n",
    "                similarity = 0.7\n",
    "            \n",
    "            elif second_hop_distance[i][j] > 0:\n",
    "                similarity = 0.2\n",
    "            \n",
    "            elif three_hop_distance[i][j] > 0:\n",
    "                similarity = 0.1\n",
    "            \n",
    "            aggregated_three_hop_similarity[i][j] = similarity\n",
    "    \n",
    "    aggregated_three_hop_similarity = aggregated_three_hop_similarity + aggregated_three_hop_similarity.transpose()\n",
    "    return aggregated_three_hop_similarity\n",
    "\n",
    "aggregated_three_hop_similarity = calculate_three_hop_similarity()\n",
    "np.save('aggregated_three_hop_similarity.npy', aggregated_three_hop_similarity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95f055",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "def report_stats(vals, title, caption, y_axis):\n",
    "    filtered_val = []\n",
    "    for val in vals:\n",
    "        if val >= 0:\n",
    "            filtered_val.append(val)\n",
    "            \n",
    "    median = np.median(filtered_val)\n",
    "    mean = np.mean(filtered_val)\n",
    "    min = np.amin(filtered_val)\n",
    "    max = np.amax(filtered_val)\n",
    "    total = np.sum(filtered_val)\n",
    "    \n",
    "    font = {'family' : 'Times New Roman',\n",
    "#         'weight' : 'bold',\n",
    "        'size'   : 18}\n",
    "\n",
    "    matplotlib.rc('font', **font)\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"    \n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "#     fig.suptitle('bold figure suptitle', fontsize=14, fontweight='bold')\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.boxplot(vals)\n",
    "    \n",
    "    labels = [title]\n",
    "\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "    ax.set_title(f'{title}')\n",
    "    ax.set_xlabel(f'{caption}')\n",
    "    ax.set_ylabel(f'{y_axis}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print(f'median {median} mean {mean} min {min} max {max} total {total}')\n",
    "\n",
    "    \n",
    "#Assuming a square matrix, report statistics\n",
    "def report_matrix_stats(matrix, title, caption, y_axis):\n",
    "    n = matrix.shape[0]\n",
    "    all_values = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            #Remove negatives as they are flags\n",
    "            if matrix[i][j] > -1:\n",
    "                all_values.append(matrix[i][j])\n",
    "    \n",
    "    report_stats(all_values, title, caption, y_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae28d79",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix(feature):\n",
    "    similarity_matrix = np.zeros((len(nodes_array), len(nodes_array))) \n",
    "    \n",
    "    for i in tqdm.tqdm(range(similarity_matrix.shape[0])):\n",
    "        for j in range(i):\n",
    "            pmid1 = str(nodes_array[i])\n",
    "            pmid2 = str(nodes_array[j])            \n",
    "            similarity_matrix[i][j] = calculate_similarity(pmid1, pmid2, feature)\n",
    "        \n",
    "    similarity_matrix = similarity_matrix + similarity_matrix.transpose()\n",
    "    \n",
    "    #Year is the only feature that is initially distance and needs to be similarity\n",
    "    if feature == 'year':\n",
    "        similarity_matrix = np.ones_like(similarity_matrix) - similarity_matrix/np.amax(similarity_matrix)\n",
    "        similarity_matrix = np.where(similarity_matrix > 1, -1, similarity_matrix)\n",
    "        \n",
    "    return similarity_matrix\n",
    "\n",
    "# year_similarity_matrix = calculate_similarity_matrix('year')\n",
    "# np.save('year_similarity_matrix.npy', year_similarity_matrix)\n",
    "\n",
    "# mesh_jaccard_similarity_matrix = calculate_similarity_matrix('mesh_jaccard')\n",
    "# np.save('mesh_jaccard_similarity_matrix.npy', mesh_jaccard_similarity_matrix)\n",
    "\n",
    "\n",
    "# mesh_tree_similarity_matrix = calculate_similarity_matrix('mesh_tree')\n",
    "# mesh_tree_similarity_matrix /= max_mesh_overlap\n",
    "# np.save('mesh_tree_similarity_matrix.npy', mesh_tree_similarity_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# bib_coupling_similarity_matrix = calculate_similarity_matrix('bib-coupling')\n",
    "# np.save('bib_coupling_similarity_matrix.npy', bib_coupling_similarity_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# cocitation_similarity_matrix = calculate_similarity_matrix('co-citation')\n",
    "# np.save('cocitation_similarity_matrix.npy', cocitation_similarity_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# chemical_similarity_matrix = calculate_similarity_matrix('chemical')\n",
    "# np.save('chemical_similarity_matrix.npy', chemical_similarity_matrix)\n",
    "\n",
    "\n",
    "# grants_similarity_matrix = calculate_similarity_matrix('grants')\n",
    "# np.save('grants_similarity_matrix.npy', grants_similarity_matrix)\n",
    "\n",
    "\n",
    "journal_similarity_matrix = calculate_similarity_matrix('journal')\n",
    "np.save('journal_similarity_matrix.npy', journal_similarity_matrix)\n",
    "\n",
    "\n",
    "# keyword_similarity_matrix = calculate_similarity_matrix('keyword')\n",
    "# np.save('keyword_similarity_matrix.npy', keyword_similarity_matrix)\n",
    "\n",
    "\n",
    "# author_similarity_matrix = calculate_similarity_matrix('author')\n",
    "# np.save('author_similarity_matrix.npy', author_similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b67cc47",
   "metadata": {},
   "source": [
    "<h1>Load metrices </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9bb696",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "year_similarity_matrix = np.load('year_similarity_matrix.npy')\n",
    "mesh_tree_similarity_matrix = np.load('mesh_tree_similarity_matrix.npy')\n",
    "bib_coupling_similarity_matrix = np.load('bib_coupling_similarity_matrix.npy')\n",
    "cocitation_matrix = np.load('cocitation_matrix.npy')\n",
    "cocitation_matrix/= np.amax(cocitation_matrix)\n",
    "chemical_similarity_matrix = np.load('chemical_similarity_matrix.npy')\n",
    "journal_similarity_matrix = np.load('journal_similarity_matrix.npy')\n",
    "aggregated_three_hop_similarity = np.load('aggregated_three_hop_similarity.npy')\n",
    "\n",
    "author_similarity_matrix = np.load('author_similarity_matrix.npy')\n",
    "keyword_similarity_matrix = np.load('keyword_similarity_matrix.npy')\n",
    "\n",
    "\n",
    "# cocitation_matrix = np.load('cocitation_matrix.npy')\n",
    "# bib_coupling_matrix = np.load('bib_coupling_matrix.npy')\n",
    "\n",
    "# cocitation_matrix /= np.amax(cocitation_matrix)\n",
    "# bib_coupling_matrix /= np.amax(bib_coupling_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad3cec",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# title = 'Year similarity boxplot'\n",
    "# caption = 'Year similarity value is defined by year difference devided by maximum difference'\n",
    "# y_axis = 'Year similarity'\n",
    "# report_matrix_stats(year_similarity_matrix, title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "# title = 'Jaccard mesh similarity boxplot'\n",
    "# caption = 'Jaccard mesh similarity value is defined by \\n the size of union of two mesh terms devided by the size of their intersection'\n",
    "# y_axis = 'Jaccard mesh similarity'\n",
    "# report_matrix_stats(mesh_jaccard_similarity_matrix,  title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "title = 'Max-Normalized pairwise mean mesh-tree similarity boxplot'\n",
    "caption = 'Max-Normalized pairwise mesh-tree similarity value is defined by \\n the average of pairwise MeSH similarities of papers'\n",
    "y_axis = 'Max-Normalized pairwise mesh-tree similarity'\n",
    "report_matrix_stats(mesh_tree_similarity_matrix,  title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "\n",
    "\n",
    "# title = 'Jaccard chemical similarity boxplot'\n",
    "# caption = 'Jaccard chemical similarity value is defined by \\n the size of union of two chemical lists devided by the size of their intersection'\n",
    "# y_axis = 'Jaccard chemical similarity'\n",
    "# report_matrix_stats(chemical_similarity_matrix, title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "\n",
    "# title = 'Jaccard co-citation similarity boxplot'\n",
    "# caption = 'Jaccard co-citation similarity value is defined by \\n the size of union of inward citation list devided by the size of their intersection'\n",
    "# y_axis = 'Jaccard co-citation similarity'\n",
    "# report_matrix_stats(cocitation_similarity_matrix, title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "# title = 'Max-normalized co-citation similarity boxplot'\n",
    "# caption = 'Max-normalized co-citation similarity value is defined by \\n the frequency of co-citation devided by maximum co-citation value observed'\n",
    "# y_axis = 'Max-normalized co-citation similarity'\n",
    "# report_matrix_stats(cocitation_matrix,  title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "\n",
    "# title = 'Jaccard bib-coupling similarity boxplot'\n",
    "# caption = 'Jaccard bib-coupling similarity value is defined by \\n the size of union of outward citation list devided by the size of their intersection'\n",
    "# y_axis = 'Jaccard bib-coupling similarity'\n",
    "# report_matrix_stats(bib_coupling_similarity_matrix, title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "# title = 'Max-normalized bib-coupling similarity boxplot'\n",
    "# caption = 'Max-normalized bib-coupling similarity value is defined by \\n the frequency of bib-coupling devided by maximum bibcoupling value observed'\n",
    "# y_axis = 'Max-normalized bib-coupling similarity'\n",
    "# report_matrix_stats(bib_coupling_matrix, title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "# title = 'Three-hop range similarity boxplot'\n",
    "# caption = 'Three-hop range similarity value is defined in an undirected graph, \\n as 0.7 if two nodes are neighbours, 0.2 if their distance is 2, 0.1 if their distance is 3 \\n and 0 otherwise'\n",
    "# y_axis = 'Three-hop range similarity'\n",
    "# report_matrix_stats(aggregated_three_hop_similarity, title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "\n",
    "# title = 'Grant similarity boxplot'\n",
    "# caption = 'Grant similarity value is defined as 1 if two nodes have listed the same grant and 0 otherwise'\n",
    "# y_axis = 'Grant similarity'\n",
    "# report_matrix_stats(grants_similarity_matrix, title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "\n",
    "# title = 'Journal similarity boxplot'\n",
    "# caption = 'Journal similarity value is defined as 1 if two nodes are published in a same journal and 0 otherwise'\n",
    "# y_axis = 'Journal similarity'\n",
    "# report_matrix_stats(journal_similarity_matrix, title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "# title = 'Jaccard keyword similarity boxplot'\n",
    "# caption = 'Keyword similarity value is defined as jaccard similarity of two keywords if existed \\n else this similarity is not taken into account'\n",
    "# y_axis = 'Keyword similarity'\n",
    "# report_matrix_stats(keyword_similarity_matrix, title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "\n",
    "# title = 'Jaccard similarity of authors'\n",
    "# caption = 'Jaccard similarity value is defined by \\n the size of union of inward citation list devided by the size of their intersection'\n",
    "# y_axis = 'Jaccard author similarity'\n",
    "# report_matrix_stats(author_similarity_matrix, title =title, caption=caption, y_axis=y_axis)\n",
    "\n",
    "# title = 'Pairwise distance similarity'\n",
    "# caption = 'Pairwise distance similarity value is defined by \\n considering weighted similarities of different features'\n",
    "# y_axis = 'Pairwise distance similarity'\n",
    "# report_matrix_stats(cluster_pairwise_similarity, title =title, caption=caption, y_axis=y_axis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9a7ed",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(np.mean(grants_similarity_matrix))\n",
    "\n",
    "for key, value in metadata_dict.items():\n",
    "    if len(value['grants']) > 0:\n",
    "        print(value['grants'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea75bd3",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Verify that those entries without grant actually do not have grants\n",
    "sample_list_of_pmid_without_grant = []\n",
    "without_grants_doi = []\n",
    "i = 0\n",
    "with_grants = []\n",
    "\n",
    "for key, value in all_xmls.items():\n",
    "    if 'grant' in str(value).lower():\n",
    "        with_grants.append(key)\n",
    "    \n",
    "    else:\n",
    "        sample_list_of_pmid_without_grant.append(key)\n",
    "        without_grants_doi.append(doi_lookup_dict[key])\n",
    "        \n",
    "    i+= 1\n",
    "    \n",
    "    if i == 100:\n",
    "        break\n",
    "\n",
    "print('Statistics for first 10 papers:\\n')\n",
    "print(f'DOIs without grant: {without_grants_doi[0:10]}')\n",
    "print(f'PMIDs without grant: {sample_list_of_pmid_without_grant[0:10]}\\n')\n",
    "\n",
    "print(f'PMID of papers with grants {with_grants}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd746ba",
   "metadata": {},
   "source": [
    "<h1>Example cross-checking of bib-coupling and co-citation</h1>\n",
    "An example of bib-couple and co-citation calculation for two nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784fe88",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_node_id = 0\n",
    "first_node_pmid = nodes_array[first_node_id]\n",
    "\n",
    "second_node_id = 50\n",
    "second_node_pmid = nodes_array[second_node_id]\n",
    "\n",
    "first_reference = {}\n",
    "first_cited = {}\n",
    "\n",
    "second_reference = {}\n",
    "second_cited = {}\n",
    "\n",
    "for edge in edge_array:\n",
    "    start_node = edge[0]\n",
    "    end_node = edge[1]\n",
    "\n",
    "    if start_node == first_node_pmid:\n",
    "        first_reference[end_node] = 1\n",
    "    if end_node == first_node_pmid:\n",
    "        first_cited[start_node] = 1     \n",
    "        \n",
    "    \n",
    "    if start_node == second_node_pmid:\n",
    "        second_reference[end_node] = 1\n",
    "    if end_node == second_node_pmid:\n",
    "        second_cited[start_node] = 1       \n",
    "\n",
    "print(f'recorded bib-coupling: {bib_coupling_matrix[first_node_id][second_node_id]}')\n",
    "print(f'crossed checked bib-coupling: {calculate_dict_similarity(first_reference, second_reference, mode = \"number_of_common_terms\")}')\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'recorded co-citation: {cocitation_matrix[first_node_id][second_node_id]}')\n",
    "print(f'crossed checked co-citation: {calculate_dict_similarity(first_cited, second_cited, mode = \"number_of_common_terms\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d49b37",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "<h1>Missing ISSN</h1>\n",
    "Finding xml's without ISSN. Any journal info?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea48bb",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_issn = []\n",
    "for key, value in all_xmls.items():\n",
    "    if not 'issn' in str(value).lower():\n",
    "        missing_issn.append(key)\n",
    "        \n",
    "print(f'missing ISSN pmids {missing_issn}')\n",
    "print(len(missing_issn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab282043",
   "metadata": {},
   "source": [
    "<h1>Examples of co-citation similarity of 1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4b7d8",
   "metadata": {},
   "source": [
    "Interestingly, for all those of paris with jaccard_cocitation = 1, they have been only cited once! As we see below, citation counts of all of those pairs is 1. This could falsly inflate co_citation similarity. This will likely be the case with new publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff64255",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "year_similarity_matrix = np.load('year_similarity_matrix.npy')\n",
    "year_similarity_array = []\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "\n",
    "for i in range(cocitation_similarity_matrix.shape[0]):\n",
    "    for j in range(i):\n",
    "        if cocitation_similarity_matrix[i][j] > 0.99:\n",
    "            row_indices.append(i)\n",
    "            col_indices.append(j)\n",
    "\n",
    "for idx in range(len(row_indices)):\n",
    "    row = row_indices[idx]\n",
    "    col = col_indices[idx]\n",
    "    year_similarity_array.append(year_similarity_matrix[row][col])\n",
    "    print(f'citation count of both papers: {np.sum(adj_matrix[:,row])} cocitation Jaccard similarity: {cocitation_similarity_matrix[row][col]} Pmid1:{nodes_array[row]} Pmid1:{nodes_array[col]}')\n",
    "\n",
    "\n",
    "print(f'Average year similarity {np.average(year_similarity_array)} total cases {len(row_indices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b73db1",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bib_coupling_similarity_matrix = np.load('bib_coupling_similarity_matrix.npy')\n",
    "cocitation_similarity_matrix = np.load('cocitation_similarity_matrix.npy')\n",
    "\n",
    "#For co_citation of 1\n",
    "first_paper_id = np.unravel_index(cocitation_similarity_matrix.argmax(), cocitation_similarity_matrix.shape)[0]\n",
    "second_paper_id = np.unravel_index(cocitation_similarity_matrix.argmax(), cocitation_similarity_matrix.shape)[1]\n",
    "\n",
    "first_node_pmid =  nodes_array[first_paper_id]\n",
    "second_node_pmid =  nodes_array[second_paper_id]\n",
    "\n",
    "first_cited = []\n",
    "second_cited = []\n",
    "\n",
    "\n",
    "\n",
    "for edge in edge_array:\n",
    "    start_node = edge[0]\n",
    "    end_node = edge[1]\n",
    "\n",
    "    if end_node == first_node_pmid:\n",
    "        first_cited.append(start_node)   \n",
    "        \n",
    "    if end_node == second_node_pmid:\n",
    "        second_cited.append(start_node)\n",
    "        \n",
    "\n",
    "print(f'first paper pmid: {first_node_pmid} second paper pmid: {second_node_pmid}. Citing list:\\n')\n",
    "print(first_cited)\n",
    "\n",
    "#Assert two arrays are equal\n",
    "assert np.sum(np.sort(first_cited) - np.sort(second_cited)) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3f863b",
   "metadata": {},
   "source": [
    "<h1>Examples of bib-coupling similarity of 1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631c1dcd",
   "metadata": {},
   "source": [
    "Here the situation is differen. As we expect, reference list is typically larger than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc92ca",
   "metadata": {
    "is_executing": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row_indices, col_indices = np.where(bib_coupling_similarity_matrix == 1)\n",
    "year_similarity_array = []\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "\n",
    "\n",
    "for i in range(bib_coupling_similarity_matrix.shape[0]):\n",
    "    for j in range(i):\n",
    "        if bib_coupling_similarity_matrix[i][j] > 0.99:\n",
    "            row_indices.append(i)\n",
    "            col_indices.append(j)\n",
    "            \n",
    "            \n",
    "for idx in range(len(row_indices)):\n",
    "    row = row_indices[idx]\n",
    "    col = col_indices[idx]\n",
    "    year_similarity_array.append(year_similarity_matrix[row][col])\n",
    "    print(f' Reference count of both papers: {np.sum(adj_matrix[row, :])} Bib-coupling Jaccard similarity: {bib_coupling_similarity_matrix[row][col]} Pmid1:{nodes_array[row]} Pmid1:{nodes_array[col]}')\n",
    "#print(f'citation count of both papers: {np.sum(adj_matrix[:,row])} Pmid1:{nodes_array[row]} Pmid1:{nodes_array[col]}')\n",
    "\n",
    "print(f'Average year similarity {np.average(year_similarity_array)}, total cases: {len(row_indices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239f8b0",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bib_coupling_similarity_matrix = np.load('bib_coupling_similarity_matrix.npy')\n",
    "cocitation_similarity_matrix = np.load('cocitation_similarity_matrix.npy')\n",
    "\n",
    "#For co_citation of 1\n",
    "first_paper_id = row_indices[3]\n",
    "second_paper_id = col_indices[3]\n",
    "\n",
    "\n",
    "first_node_pmid =  3945365 #nodes_array[first_paper_id]\n",
    "second_node_pmid =  11916530 #nodes_array[second_paper_id]\n",
    "\n",
    "first_reference = []\n",
    "second_reference = []\n",
    "\n",
    "\n",
    "\n",
    "for edge in edge_array:\n",
    "    start_node = edge[0]\n",
    "    end_node = edge[1]\n",
    "\n",
    "    if start_node == first_node_pmid:\n",
    "        first_reference.append(end_node)   \n",
    "        \n",
    "    if start_node == second_node_pmid:\n",
    "        second_reference.append(end_node)\n",
    "        \n",
    "\n",
    "print(f'first paper pmid: {first_node_pmid} second paper pmid: {second_node_pmid}. total references: {len(first_reference)} Reference list:\\n')\n",
    "print(first_reference)\n",
    "\n",
    "#Assert two arrays are equal\n",
    "assert np.sum(np.sort(first_reference) - np.sort(second_reference)) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd51e3",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "<h1> Missing grants </h1>\n",
    "<p>Let's see how those samples with 'grant' string but no grant data look like </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483c43a",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_pmids = []\n",
    "\n",
    "for key, value in all_xmls.items():\n",
    "    if 'grantlist' in str(value).lower() and len(metadata_dict[key]['grants']) == 0:\n",
    "        target_pmids.append(key)\n",
    "        \n",
    "print(target_pmids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e1c17",
   "metadata": {},
   "source": [
    "Through better parsing, this number is now very low!\n",
    "Now the case of this 3:\n",
    "<html>\n",
    "<head>\n",
    "    <title>PMID and Reason for Missing</title>\n",
    "</head>\n",
    "<body>\n",
    "    <table border=\"1\">\n",
    "        <tr>\n",
    "            <th>PMID</th>\n",
    "            <th>Reason for Missing</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>1971008</td>\n",
    "            <td>No grant Id, only agency and country</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2bbbec",
   "metadata": {},
   "source": [
    "<h1>Checking for same grants</h1> <p> Let's simply record number of same grants. It turns out no two papers have same grant. As we can see on the cell bellow, no two papers are supported by the same grant as the mean of the grant similarity matrix is 0</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa89836",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "grants_similarity_matrix = np.load('grants_similarity_matrix.npy')\n",
    "print(np.mean(grants_similarity_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e105ed59",
   "metadata": {},
   "source": [
    "<h1>Missing Mesh</h1> \n",
    "As we verify manually, these 3 articles don't have any mesh term inside them. So, out of 1993 parsable responses, only 3 miss mesh information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97099845",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_pmids = []\n",
    "\n",
    "for key, value in all_xmls.items():\n",
    "    if not'meshheadinglist' in str(value).lower() and len(str(all_xmls[key])) > 250:\n",
    "        target_pmids.append(key)\n",
    "        \n",
    "print(target_pmids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad69df6c",
   "metadata": {},
   "source": [
    "<h1>Highly repeated Chemicals </h1>\n",
    "<p> As we can see, in the first cluster, 96.32% of chemical terms are already in MesH terms </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a033c",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "inside = 0\n",
    "outside = 0\n",
    "chemicals_not_in_MeSH = []\n",
    "\n",
    "for key, value in tqdm(metadata_dict.items()):\n",
    "    for chemical in value['chemical']:\n",
    "        if chemical in value['mesh']:\n",
    "            inside += 1\n",
    "        \n",
    "        else:\n",
    "            chemicals_not_in_MeSH.append(chemical)\n",
    "            outside += 1\n",
    "\n",
    "print(f'Number of whole chemicals in this cluster {inside + outside}')\n",
    "print(f'Percentage of Chemicals already in MeSH terms {(100*inside/(inside+outside)):.2f}')\n",
    "print(chemicals_not_in_MeSH, len(chemicals_not_in_MeSH))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d7f1c",
   "metadata": {},
   "source": [
    "<h1>Finding MeSH from UI </h1>\n",
    "<p> Currently we only have UI for MeSH terms or chemicals, but we want their tree structure to find their similarity. As it turns out, we can only get the MeSH tree for MeSH terms, not for chemicals </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b81f95",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import multiprocessing \n",
    "\n",
    "def retrieve_mesh_tree(UI, idx, shared_dict):\n",
    "    url = f\"https://meshb.nlm.nih.gov/record/ui?ui={UI}\"\n",
    "    with requests.Session() as session:\n",
    "        url = f\"https://meshb.nlm.nih.gov/record/ui?ui={UI}\"\n",
    "\n",
    "        response = session.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        text_of_interest = response.text\n",
    "        \n",
    "        try:\n",
    "            treeNumber_idx = text_of_interest.index('treeNumber_0')\n",
    "            uniqueID = text_of_interest.index('Unique ID')\n",
    "            limited_string = text_of_interest[treeNumber_idx:uniqueID]\n",
    "            end_index = limited_string.find('</a>')\n",
    "            counter = 1\n",
    "\n",
    "            while end_index-counter + 1 >= 0:\n",
    "                if limited_string[end_index-counter] == '>':\n",
    "                    shared_dict[UI] = limited_string[end_index-counter + 1:end_index]\n",
    "                    break\n",
    "                counter += 1\n",
    "            \n",
    "        except:\n",
    "            shared_dict[UI] = \"failed\"\n",
    "\n",
    "    else:\n",
    "        shared_dict[UI] = \"failed\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "temp_mesh = {}\n",
    "all_mesh_terms = Manager().dict()\n",
    "\n",
    "lst = []\n",
    "\n",
    "\n",
    "for key, value in metadata_dict.items():\n",
    "    for mesh in value['mesh']:\n",
    "        if not mesh in all_mesh_terms:\n",
    "            temp_mesh[mesh] = 1\n",
    "            \n",
    "\n",
    "for index, mesh in enumerate(temp_mesh.keys()):\n",
    "    lst.append((mesh, index, all_mesh_terms))\n",
    "\n",
    "    \n",
    "CHUNK_SIZE = 50\n",
    "SPLIT = len(lst) // CHUNK_SIZE + 1\n",
    "\n",
    "\n",
    "for i in tqdm(range(SPLIT)):\n",
    "    if i != SPLIT -1:\n",
    "        with multiprocessing.Pool(processes=10) as pool:\n",
    "                pool.starmap(retrieve_mesh_tree, lst[i*CHUNK_SIZE: (i+1) * CHUNK_SIZE])\n",
    "    \n",
    "    else:\n",
    "        with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "            pool.starmap(retrieve_mesh_tree, lst[i*CHUNK_SIZE: ])  \n",
    "\n",
    "        \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc791cd",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "64\n",
    "        try:\n",
    "65\n",
    "            if 'JournalIssue' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal'].keys():\n",
    "66\n",
    "                if 'PubDate' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['JournalIssue']:\n",
    "67\n",
    "                    if 'Year' in xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']:\n",
    "68\n",
    "                        pub_year = xml_dict['PubmedArticleSet']['PubmedArticle']['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate']['Yimport json\n",
    "with open('all_mesh_terms.json', 'r') as json_file:\n",
    "    all_mesh_terms = json.load(json_file)\n",
    "    \n",
    "    \n",
    "mesh_save_dict = {}\n",
    "failed = 0\n",
    "success = 0\n",
    "\n",
    "for key, val in all_mesh_terms.items():\n",
    "    mesh_save_dict[key] = val\n",
    "    \n",
    "    if val == 'failed':\n",
    "        failed += 1\n",
    "    \n",
    "    else:\n",
    "        success += 1\n",
    "    \n",
    "print(success, failed)\n",
    "# with open('all_meshhh_terms.json', 'w') as json_file:\n",
    "#     json.dump(mesh_save_dict, json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bcdf43",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "<h1> Finally we create our first aggregated similarity metric</h1>\n",
    "<p> The way we handle that is we create a set of weights for our metrics. In case of a missing value, the relative scales are adjusted. This is the initial proposed weights, ordered in ascending manner: </p>    \n",
    "<table border=\"1\">\n",
    "        <tr>\n",
    "            <th>Metric</th>\n",
    "            <th>Relative weight</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Year</td>\n",
    "            <td>1</td>\n",
    "        </tr>    \n",
    "        <tr>\n",
    "            <td>Journal similarity</td>\n",
    "            <td>2</td>\n",
    "        </tr>  \n",
    "        <tr>\n",
    "            <td>Max-normalized Cocitation</td>\n",
    "            <td>4</td>\n",
    "        </tr>    \n",
    "        <tr>\n",
    "            <td>Bib-coupling Jaccard</td>\n",
    "            <td>6</td>\n",
    "        </tr>       \n",
    "        <tr>\n",
    "            <td>Three-hop similarity</td>\n",
    "            <td>8</td>\n",
    "        </tr>        \n",
    "        <tr>\n",
    "            <td>Chemical Jaccard</td>\n",
    "            <td>10</td>\n",
    "        </tr>     \n",
    "        <tr>\n",
    "            <td>MeSH Jaccard</td>\n",
    "            <td>15</td>\n",
    "        </tr>       \n",
    "    </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17509e77",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "reference_weights = {'year': 1, 'journal': 2, 'cocitation': 4, 'bib-coupling': 6, \n",
    "                     'three-hop': 8, 'chemical': 10, 'mesh':15}\n",
    "\n",
    "initial_weight_sum = 0\n",
    "\n",
    "for _, value in reference_weights.items():\n",
    "    initial_weight_sum += value\n",
    "    \n",
    "    \n",
    "reference_matrices = {'year': year_similarity_matrix, 'journal': journal_similarity_matrix,\n",
    "                     'cocitation': cocitation_matrix, 'bib-coupling': bib_coupling_similarity_matrix, \n",
    "                     'three-hop': aggregated_three_hop_similarity , 'chemical': chemical_similarity_matrix,\n",
    "                     'mesh':mesh_tree_similarity_matrix}\n",
    "\n",
    "def calculate_two_paper_similarity(paper1_index, paper2_index):\n",
    "    #paper1_index and paper2_index are those mapped to interval [1,2,...,n]\n",
    "    \n",
    "    total_similarity = 0\n",
    "    sum_of_available_feature_weights = 0\n",
    "    \n",
    "    for key, matrix_of_interest in reference_matrices.items():\n",
    "        if matrix_of_interest[paper1_index][paper2_index] >= 0:\n",
    "            sum_of_available_feature_weights += reference_weights[key]\n",
    "            total_similarity += reference_weights[key]*matrix_of_interest[paper1_index][paper2_index]\n",
    "    \n",
    "    if sum_of_available_feature_weights == 0:\n",
    "        return 0\n",
    "    \n",
    "    return total_similarity * (initial_weight_sum/sum_of_available_feature_weights)\n",
    "\n",
    "\n",
    "def calculate_whole_cluster_similarity():\n",
    "    cluster_pairwise_similarity = np.zeros_like(adj_matrix)\n",
    "    \n",
    "    for i in tqdm.tqdm(range(cluster_pairwise_similarity.shape[0])):\n",
    "        for j in range(i):\n",
    "            cluster_pairwise_similarity[i][j] = calculate_two_paper_similarity(i,j)\n",
    "    \n",
    "    return cluster_pairwise_similarity + cluster_pairwise_similarity.transpose()\n",
    "\n",
    "cluster_pairwise_similarity = calculate_whole_cluster_similarity()/initial_weight_sum\n",
    "np.save('cluster_pairwise_similarity.npy', cluster_pairwise_similarity)\n",
    "\n",
    "\n",
    "title = 'Pairwise similarity'\n",
    "caption = 'Pairwise similarity value is defined by \\n considering weighted similarities of different features'\n",
    "y_axis = 'Pairwise similarity'\n",
    "report_matrix_stats(cluster_pairwise_similarity, title =title, caption=caption, y_axis=y_axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dfc0e4",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "for key, value in reference_matrices.items():\n",
    "    print(key, np.amax(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa61e4",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Load stuff\n",
    "\n",
    "import pickle\n",
    "print(len(nodes_array))\n",
    "file_name = \"nodes_array.pkl\"\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_name, 'rb') as file:\n",
    "    # Use pickle.load() to deserialize and load the object\n",
    "    nodes_array = pickle.load(file)\n",
    "    \n",
    "print(len(nodes_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d8420",
   "metadata": {},
   "source": [
    "<h3> Checking with cluster 18, which is the cluster of interest </h3>\n",
    "<p> Initially we started with cluster_1, but it turns out that cluster_18 is the coherent cluster with microRNA theme. Let's investigate if that's the case that these two clusters are different?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f1c591",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = 'fabios_test_data_doi.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "# print(df.head())\n",
    "cluster_18 = []\n",
    "\n",
    "cluster_18_doi_lookup = {}\n",
    "\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    cluster_id, node_id, doi = row['cluster_id'], row['node_id'], row['doi']\n",
    "    \n",
    "    if int(cluster_id) == 18:\n",
    "        cluster_18.append((node_id,doi))\n",
    "        cluster_18_doi_lookup[str(node_id)] = doi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b56eb",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "common = 0 \n",
    "\n",
    "for element in tqdm(cluster_18):\n",
    "    node_id , doi = element\n",
    "    \n",
    "    \n",
    "    #This one doesn't have pmid \n",
    "    if node_id == 14482471:\n",
    "        continue\n",
    "        \n",
    "    if int(node_id) in nodes_array and doi == doi_lookup_dict[str(node_id)]:\n",
    "        common += 1\n",
    "        \n",
    "        assert node_id == nodes_array[nodes_array.index(node_id)]\n",
    "        \n",
    "\n",
    "print(common)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52be43",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(cluster_18[0:10])\n",
    "while True:\n",
    "    pmid = input('Enter pmid')\n",
    "    print(f'cluster_18: {cluster_18_doi_lookup[pmid]} cluster_1: {doi_lookup_dict[pmid]} equal? {cluster_18_doi_lookup[pmid] == doi_lookup_dict[pmid]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae769475",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(doi_lookup_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2128c1b3",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
