{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a99bd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T18:55:04.230467977Z",
     "start_time": "2023-11-08T18:55:04.075809116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vi\n"
     ]
    }
   ],
   "source": [
    "print(\"vi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a490ae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T18:55:04.306896076Z",
     "start_time": "2023-11-08T18:55:04.082849524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted values successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Set the PGDATABASE environment variable\n",
    "os.environ[\"PGDATABASE\"] = \"ernieplus\"\n",
    "\n",
    "def insert_values_into_table(values_list):\n",
    "    try:\n",
    "        # Connect to the PostgreSQL database\n",
    "        conn = psycopg2.connect(\"\")\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        \n",
    "        args = ','.join(cur.mogrify(\"(%s,%s,%s, %s, %s, %s, %s, %s, %s, %s)\", i).decode('utf-8')\n",
    "                for i in values_list)\n",
    "        \n",
    "        cur.execute(\"INSERT INTO hm31.pubmed_all_xmls_abstracts VALUES \" + (args))\n",
    "\n",
    "        conn.commit()\n",
    "        print(\"Inserted values successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "# Example usage:\n",
    "values_to_insert = [\n",
    "    (123425, '', '', '', 0, 0, '', 'doi1','title1', 'abs1'),\n",
    "    (543251, '5678-1234', 'Grant3, Grant4', 'Chemical3, Chemical4', 2021, 2020, 'Term3, Term4','doi2','t1','a1')\n",
    "]\n",
    "\n",
    "insert_values_into_table(values_to_insert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba8ba960",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-08T18:55:04.185121712Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read\n",
      "parsed\n"
     ]
    }
   ],
   "source": [
    "import xmltodict\n",
    "import pandas as pd\n",
    "\n",
    "def parse(file_path):\n",
    "    try:\n",
    "        # Open and read the XML file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            xml_contents = file.read()\n",
    "        print(\"read\")\n",
    "        # Parse the XML content using xmltodict\n",
    "        xml_dict = xmltodict.parse(xml_contents)\n",
    "        print(\"parsed\")\n",
    "        # Print the parsed XML as a Python dictionary\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        \n",
    "    return xml_dict\n",
    "\n",
    "xml_dict = parse('/shared/hossein_hm31/xml_data/pubmed23n1439.xml')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cbb502",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import metapub\n",
    "\n",
    "!convert pmid2doi 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef3df4",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from dicttoxml import dicttoxml\n",
    "xml = dicttoxml(xml_dict['PubmedArticleSet']['PubmedArticle'][0])\n",
    "print(type(xml))\n",
    "# print(str(xml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0006f3d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(len(xml_dict['PubmedArticleSet']['PubmedArticle']))\n",
    "# print(xml_dict['PubmedArticleSet']['PubmedArticle'][0])\n",
    "print(type(xml_dict['PubmedArticleSet']['PubmedArticle'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f257ed",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "article_id_list = temp['PubmedData']['ArticleIdList']['ArticleId']\n",
    "print('doi' in str(article_id_list[1]))\n",
    "# print(article_id_list[1])\n",
    "print(article_id_list[1].keys())\n",
    "print(article_id_list[1]['#text'])\n",
    "\n",
    "\n",
    "# Iterate through the list of ArticleId entries\n",
    "# for article_id in article_id_list['ArticleId']:\n",
    "#     if article_id.get('@IdType') == 'doi':\n",
    "#         doi = article_id['#text']\n",
    "#         print(\"DOI:\", doi)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5a03d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "text = \"\"\"\n",
    "<Day>16</Day>\n",
    "</PubMedPubDate>\n",
    "<PubMedPubDate PubStatus=\"medline\">\n",
    "<Year>1976</Year>\n",
    "<Month>3</Month>\n",
    "<Day>16</Day>\n",
    "<Hour>0</Hour>\n",
    "<Minute>1</Minute>\n",
    "</PubMedPubDate>\n",
    "<PubMedPubDate PubStatus=\"entrez\">\n",
    "<Year>1976</Year>\n",
    "<Month>3</Month>\n",
    "<Day>16</Day>\n",
    "<Hour>0</Hour>\n",
    "<Minute>0</Minute>\n",
    "</PubMedPubDate>\n",
    "</History>\n",
    "<PublicationStatus>ppublish</PublicationStatus>\n",
    "<ArticleIdList>\n",
    "<ArticleId IdType=\"pubmed\">4311</ArticleId>\n",
    "<ArticleId IdType=\"doi\">10.1111/j.1432-1033.1976.tb10218.x</ArticleId>\n",
    "</ArticleIdList>\n",
    "</PubmedData>\n",
    "</PubmedArticle>\n",
    "</PubmedArticleSet>\n",
    "\"\"\"\n",
    "\n",
    "doi_pattern = r'\\b10\\.\\d{4,}/\\S+'\n",
    "doi_pattern = r'\\b10\\.\\d{4,}(?:\\.\\d+)*\\/[^\\s]+'\n",
    "\n",
    "\n",
    "# Find all DOIs in the text\n",
    "dois = re.findall(doi_pattern, text)\n",
    "\n",
    "# Print the found DOIs\n",
    "for doi in dois:\n",
    "    print(\"Found DOI:\", doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886dbc6",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def find_doi(string):\n",
    "    doi_pattern = r'\\b10\\.\\d{4,}(?:\\.\\d+)*\\/[^\\s]+'\n",
    "    dois = re.findall(doi_pattern, string)\n",
    "    return dois\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7afa0a21",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def clean_abstract(abstract):\n",
    "    overhauled = ''\n",
    "    \n",
    "    if type(abstract) != str:    \n",
    "      for a in abstract:\n",
    "        if type(a) != str:\n",
    "            if a != None and '#text' in a:\n",
    "                overhauled += a['#text']\n",
    " \n",
    "        else:\n",
    "            overhauled += a\n",
    "        \n",
    "      return overhauled\n",
    "\n",
    "    return abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3620b8e6",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17763/17763 [00:00<00:00, 30931.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def parse_single_record(xml_dict, originial_dict,i=0):\n",
    "    mesh_headings = []\n",
    "    grants = []\n",
    "    year = \"\"\n",
    "    journal_ISSN = \"\"\n",
    "    chemical_list = []\n",
    "    meta_data = {}\n",
    "    pub_year = \"\"\n",
    "    PMID = \"\"\n",
    "    doi = \"\"\n",
    "    title = \"\"\n",
    "    abstract = \"\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        xml_dict = dict(xml_dict)\n",
    "        \n",
    "        \n",
    "#         print(xml_dict)\n",
    "        \n",
    "        try:\n",
    "            if 'PMID' in xml_dict:\n",
    "                PMID = xml_dict['PMID']['#text']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            if 'DateCompleted' in xml_dict:\n",
    "                new_dic = dict(xml_dict['DateCompleted'])\n",
    "                if 'Year' in new_dic:\n",
    "                    year = new_dic['Year']\n",
    "\n",
    "            else:\n",
    "                  pass\n",
    "    \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        try:\n",
    "            if 'Article' in xml_dict:\n",
    "                new_dic = dict(xml_dict['Article'])\n",
    "                journal_ISSN = new_dic['Journal']['ISSN']['#text']\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        try:\n",
    "            if 'Article' in xml_dict:\n",
    "                new_dic = dict(xml_dict['Article'])\n",
    "                pub_year = new_dic['Journal']['JournalIssue']['PubDate']['Year']\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        try:\n",
    "\n",
    "                article_id_list = originial_dict['PubmedData']['ArticleIdList']['ArticleId']\n",
    "                \n",
    "                for element in article_id_list:\n",
    "                    if 'doi' in str(element).lower():\n",
    "                        doi = element['#text']\n",
    "                        break\n",
    "#                 print('doi' in str(article_id_list[1]))\n",
    "#                 # print(article_id_list[1])\n",
    "#                 print(article_id_list[1].keys())\n",
    "#                 print(article_id_list[1]['#text'])\n",
    "#                 #print('doi' in str(article_id_list[1]))\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "     \n",
    "        \n",
    "\n",
    "        try:\n",
    "            if 'Article' in xml_dict: \n",
    "                new_dic = dict(xml_dict['Article'])\n",
    "                \n",
    "            if 'Title' in  new_dic['Journal'].keys():\n",
    "                journal_title = new_dic['Journal']['Title']\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            if 'Article' in xml_dict: \n",
    "                new_dic = dict(xml_dict['Article'])\n",
    "            \n",
    "\n",
    "                title = new_dic['ArticleTitle']\n",
    "                \n",
    "                \n",
    "#                 if i == 10844:\n",
    "#                     print(title,'AAA \\n')\n",
    "                    \n",
    "                if '#text' in title:\n",
    "                    title = title['#text']\n",
    "                    \n",
    "#                     if i == 10844:\n",
    "#                         print(title,'BBB \\n')\n",
    "                        \n",
    "                elif 'b' in title:\n",
    "                    title = title['b']\n",
    "                    if '#text' in title:\n",
    "                        title = title['#text']\n",
    "                        \n",
    "                        \n",
    "                elif 'sup' in title:\n",
    "                    title = title ['sup']\n",
    "                    \n",
    "                    \n",
    "                        \n",
    "                if 'i' in title:\n",
    "                    title = title ['i']\n",
    "                    \n",
    "                if type(title) == list:\n",
    "                    title = ' '.join(title)\n",
    "                    \n",
    "   \n",
    "                    \n",
    "                  \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "                \n",
    "        try:\n",
    "\n",
    "            if 'Article' in xml_dict: \n",
    "                new_dic = dict(xml_dict['Article'])\n",
    "                abstract = new_dic['Abstract']['AbstractText']\n",
    "                \n",
    "                while '#text' in abstract:\n",
    "                    abstract = abstract['#text']\n",
    "                                        \n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "            if 'Article' in xml_dict: \n",
    "                new_dic = dict(xml_dict['Article'])\n",
    "\n",
    "            if 'GrantList' in new_dic:\n",
    "                if type(new_dic['GrantList']['Grant']) == list:\n",
    "                    for grant in new_dic['GrantList']['Grant']:\n",
    "                        if 'GrantID' in grant:\n",
    "                            grants.append((grant['GrantID']))\n",
    "                            \n",
    "                else:\n",
    "                     grants.append(new_dic['GrantList']['Grant']['GrantID'])\n",
    "                     pass   \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            if 'MeshHeadingList' in xml_dict:  \n",
    "                if type(xml_dict['MeshHeadingList']['MeshHeading']) == list:\n",
    "                    for mesh in xml_dict['MeshHeadingList']['MeshHeading']:\n",
    "                        if '@Type' in mesh['DescriptorName'].keys() and mesh['DescriptorName']['@Type'] == 'Geographic':\n",
    "                            continue\n",
    "                \n",
    "                \n",
    "                        mesh_headings.append((mesh['DescriptorName']['@UI']))\n",
    "            \n",
    "                else:\n",
    "                    \n",
    "                    mesh = xml_dict['MeshHeadingList']['MeshHeading']['DescriptorName']\n",
    "                    if  (not '@Type' in mesh.keys() or mesh['@Type'] != 'Geographic'):\n",
    "                        mesh_headings.append(xml_dict['MeshHeadingList']['MeshHeading']['DescriptorName']['@UI'])\n",
    "                    \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        try:\n",
    "        \n",
    "            if 'ChemicalList' in xml_dict:\n",
    "               if type(xml_dict['ChemicalList']['Chemical']) == list:\n",
    "                   for substance in xml_dict['ChemicalList']['Chemical']:\n",
    "                        if substance['NameOfSubstance']['@UI'][0].lower() == 'c':\n",
    "                           chemical_list.append(substance['NameOfSubstance']['@UI'])\n",
    "                        \n",
    "               else:\n",
    "                    \n",
    "                    if xml_dict['ChemicalList']['Chemical']['NameOfSubstance']['@UI'][0].lower() == 'c':\n",
    "                           chemical_list.append(xml_dict['ChemicalList']['Chemical']['NameOfSubstance']['@UI'])\n",
    "\n",
    "                            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"ERR\")\n",
    "            pass\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    if len(year) == 0:\n",
    "        year = pub_year\n",
    "        \n",
    "    if title == None:\n",
    "        title = ''\n",
    "        \n",
    "    if abstract == None:\n",
    "        abstract = ''\n",
    "        \n",
    "    abstract = clean_abstract(abstract)\n",
    "\n",
    "    \n",
    "    meta_data = {'PMID': PMID, 'mesh': mesh_headings, 'grants': grants, 'year': year, \n",
    "                 'journal_ISSN': journal_ISSN,'journal_title': journal_title,\n",
    "                 'chemical' : chemical_list, 'pub_year': pub_year, 'doi': doi, 'title': title, 'abstract': abstract} \n",
    "    \n",
    "    return meta_data\n",
    "\n",
    "meta_data_array = []\n",
    "\n",
    "counter = 0\n",
    "for i in tqdm(range(len(xml_dict['PubmedArticleSet']['PubmedArticle']))):\n",
    "    rec = xml_dict['PubmedArticleSet']['PubmedArticle'][i]['MedlineCitation']\n",
    "    total = xml_dict['PubmedArticleSet']['PubmedArticle'][i]\n",
    "    x=parse_single_record(rec, total,i)\n",
    "    meta_data_array.append(x)\n",
    "    \n",
    "    if type(x['title']) != str:\n",
    "        print(x['title'])\n",
    "        print(type(x['title']))\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd946cf",
   "metadata": {},
   "source": [
    "<h2>Saving into parquet </h2>\n",
    "<p> We will convert the metadata array to dataframe, write it to parquet and read it and inspect the saved file against the original array as a cross-check mechanism</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e657615",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                              mesh  \\\n",
      "PMID     doi                                                                         \n",
      "36343930 10.11477/mf.1416202225      [D006801, D051818, D002524, D012027, D002531]   \n",
      "36343931 10.11477/mf.1416202226  [D006801, D003371, D010523, D013577, D002524, ...   \n",
      "\n",
      "                                grants  year journal_ISSN  \\\n",
      "PMID     doi                                                \n",
      "36343930 10.11477/mf.1416202225     []  2022    1881-6096   \n",
      "36343931 10.11477/mf.1416202226     []  2022    1881-6096   \n",
      "\n",
      "                                                              journal_title  \\\n",
      "PMID     doi                                                                  \n",
      "36343930 10.11477/mf.1416202225  Brain and nerve = Shinkei kenkyu no shinpo   \n",
      "36343931 10.11477/mf.1416202226  Brain and nerve = Shinkei kenkyu no shinpo   \n",
      "\n",
      "                                chemical pub_year  \\\n",
      "PMID     doi                                        \n",
      "36343930 10.11477/mf.1416202225       []     2022   \n",
      "36343931 10.11477/mf.1416202226       []     2022   \n",
      "\n",
      "                                                                             title  \\\n",
      "PMID     doi                                                                         \n",
      "36343930 10.11477/mf.1416202225  [Vestibular Dysfunction in Replication Factor ...   \n",
      "36343931 10.11477/mf.1416202226                         [Chronic Cough in CANVAS].   \n",
      "\n",
      "                                                                          abstract  \n",
      "PMID     doi                                                                        \n",
      "36343930 10.11477/mf.1416202225  More than 90% of replication factor c subunit ...  \n",
      "36343931 10.11477/mf.1416202226  Among patients with RFC1 spectrum disorders re...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(meta_data_array)\n",
    "df.set_index(['PMID', 'doi'], inplace=True)\n",
    "df.head()\n",
    "df.to_parquet('myfile.parquet')\n",
    "print(df.head(2))\n",
    "!rm myfile.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476b193",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "read_df = pd.read_parquet('myfile.parquet')\n",
    "print(read_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a97cbbc",
   "metadata": {},
   "source": [
    "<h2>As we see here, very few dois is available in the XMLS. This is cross checked with looking for 'doi' occurence in the string</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675ae1d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def investigate_for_doi_manually(xml_dict):\n",
    "    xml = str(dicttoxml(xml_dict))\n",
    "    return 'doi' in xml\n",
    " \n",
    "total_doi = 0\n",
    "for idx, meta in tqdm(enumerate(meta_data_array),  total = len(meta_data_array)):\n",
    "    if meta['doi'] != '':\n",
    "        total_doi += 1\n",
    "\n",
    "print(f'totaly {total_doi} dois available from {len(meta_data_array)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d694450",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# total_doi = 0\n",
    "for idx, meta in tqdm(enumerate(meta_data_array),  total = len(meta_data_array)):\n",
    "    if meta['doi'] != '':\n",
    "        total_doi += 1\n",
    "    \n",
    "    else:\n",
    "        exist = investigate_for_doi_manually( xml_dict['PubmedArticleSet']['PubmedArticle'][i])\n",
    "        if exist:\n",
    "            print(meta['PMID'])\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782088a",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Convert dict to query\n",
    "def convert_dict_to_query(dic):\n",
    "    if dic['year'] == '':\n",
    "        year = 0\n",
    "    \n",
    "    else:\n",
    "        year = dic['year']\n",
    "        \n",
    "    \n",
    "    if dic['pub_year'] == '':\n",
    "        pub_year = 0\n",
    "    \n",
    "    else:\n",
    "        pub_year = dic['pub_year']\n",
    "        \n",
    "        \n",
    "    query = (int(dic['PMID']), dic['journal_ISSN'], ' '.join(dic['grants']), ' '.join(dic['chemical']), \n",
    "            pub_year, year, ' '.join(dic['mesh']), dic['doi'], dic['abstract'], dic['title'] )\n",
    "        \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c812e5b0",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3959329",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "query_array = []\n",
    "na = 0\n",
    "nt = 0\n",
    "for i in meta_data_array:\n",
    "    query_array.append(convert_dict_to_query(i))\n",
    "    \n",
    "#     print(i['title'])\n",
    "    if len (i['title']) > 0:\n",
    "        na +=1 \n",
    "    \n",
    "    if len (i['abstract']) > 0:\n",
    "        nt += 1\n",
    "\n",
    "print(na)\n",
    "print(nt)\n",
    "\n",
    "for query in query_array:\n",
    "    if type(query[-1]) != str:\n",
    "        print(query[-1])\n",
    "\n",
    "# insert_values_into_table(query_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6da10bae",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def parallelize(file_path, mode='parquet', dump_address = '/shared/hossein_hm31/pubmed_parquet/' ):\n",
    "    xml_dict = parse(file_path)\n",
    "    \n",
    "    meta_data_array = []\n",
    "\n",
    "    for i in range(len(xml_dict['PubmedArticleSet']['PubmedArticle'])):\n",
    "        rec = xml_dict['PubmedArticleSet']['PubmedArticle'][i]['MedlineCitation']\n",
    "        total = xml_dict['PubmedArticleSet']['PubmedArticle'][i]\n",
    "        x=parse_single_record(rec, total)\n",
    "        meta_data_array.append(x)\n",
    "        \n",
    "    if mode == 'postgres':\n",
    "        query_array = []\n",
    "\n",
    "        for i in meta_data_array:\n",
    "            query_array.append(convert_dict_to_query(i))\n",
    "\n",
    "\n",
    "        insert_values_into_table(query_array)\n",
    "        \n",
    "    elif mode == 'parquet':\n",
    "        try:\n",
    "            xml_name = file_path.split('/')[-1].split('.')[0] #Example '/shared/hossein_hm31/xml_data/pubmed23n0933.xml' -> pubmed23n0933.xml\n",
    "            df = pd.DataFrame(meta_data_array)\n",
    "            df.set_index(['PMID', 'doi'], inplace=True)\n",
    "            df.to_parquet(f'{dump_address+xml_name}.parquet')\n",
    "            print('saved')\n",
    "        except Exception as e: # work on python 3.x\n",
    "            print(str(e)+'\\n')\n",
    "\n",
    "\n",
    "#23 Mb vs 230 Mb single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc91576d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "nest_dir = '/shared/hossein_hm31/xml_data/'\n",
    "files = os.listdir(nest_dir)\n",
    "\n",
    "lst = []\n",
    "\n",
    "for file in files:\n",
    "    lst.append((nest_dir+file,))\n",
    "    \n",
    "with multiprocessing.Pool(processes=80) as pool:\n",
    "    results = pool.starmap(parallelize, lst)\n",
    "    \n",
    "end = time.time()\n",
    "print(f'elapsed {end - start}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa470018",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "<h2> Finishing the unfinished ones </h2>\n",
    "<p> Get the incomplete files </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "46bf7ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pubmed23n1439']\n",
      "1\n",
      "read\n",
      "parsed\n",
      "saved\n",
      "elapsed 54.92585349082947\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "obtained_files = os.listdir('/shared/hossein_hm31/pubmed_parquet/')\n",
    "all_files = os.listdir('/shared/hossein_hm31/xml_data//')\n",
    "\n",
    "all_xml_files = [file.split('.')[0] for file in all_files if '.xml' in file]\n",
    "all_parquet_files = [file.split('.')[0] for file in obtained_files]\n",
    "\n",
    "files_left = [file for file in all_xml_files if not file in all_parquet_files]\n",
    "print(files_left)\n",
    "print(len(files_left))\n",
    "\n",
    "lst = []\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for file in files_left:\n",
    "    lst.append((f'/shared/hossein_hm31/xml_data/{file}.xml',))\n",
    "\n",
    "\n",
    "with multiprocessing.Pool(processes=60) as pool:\n",
    "    results = pool.starmap(parallelize, lst)\n",
    "    \n",
    "end = time.time()\n",
    "print(f'elapsed {end - start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0f809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
