{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d16a44a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T13:08:08.215277147Z",
     "start_time": "2023-09-28T13:08:08.204401966Z"
    },
    "collapsed": true
   },
   "source": [
    "<h1>Get all mesh_terms from the Pubmed </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f7d894",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-11T03:39:06.292773525Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm \n",
    "import pickle\n",
    "\n",
    "# Set the PGDATABASE environment variable\n",
    "os.environ[\"PGDATABASE\"] = \"ernieplus\"\n",
    "import psycopg2\n",
    "\n",
    "def get_all_mesh_terms():\n",
    "    all_mesh_set = set()\n",
    "    \n",
    "    conn = psycopg2.connect(\"\")\n",
    "    print(\"Connected to Postgres successfully\")\n",
    "    cur = conn.cursor()\n",
    "    sql_query = \"select mesh_terms from hm31.pubmed_all_xmls_new am\"\n",
    "\n",
    "    cur.execute(sql_query)\n",
    "\n",
    "    result = cur.fetchall()\n",
    "    for idx, row in tqdm(enumerate(result), total = 34780700):\n",
    "        if len(row) == 0 or len(row[0]) == 0:\n",
    "            continue\n",
    "\n",
    "   \n",
    "        mesh_terms = row[0].split()[0].split(',')\n",
    "        #print(mesh_terms)\n",
    "        \n",
    "        for mesh in mesh_terms:\n",
    "            all_mesh_set.add(mesh)\n",
    "            \n",
    "    return all_mesh_set\n",
    "\n",
    "# all_mesh_set = get_all_mesh_terms()\n",
    "\n",
    "# with open('all_mesh.pkl', 'wb') as file:\n",
    "#     pickle.dump(all_mesh_set, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e9f6c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-11T03:39:06.292922054Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('all_mesh.pkl', 'rb') as file:\n",
    "    all_mesh_set = pickle.load(file)\n",
    "    \n",
    "print(len(all_mesh_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dd6498",
   "metadata": {},
   "source": [
    "<h1>Obtaining MeSH tree structure </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f6965",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-11T03:39:06.293002716Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import multiprocessing \n",
    "import json\n",
    "\n",
    "def retrieve_mesh_tree(UI, idx, shared_dict):\n",
    "    url = f\"https://meshb.nlm.nih.gov/record/ui?ui={UI}\"\n",
    "    with requests.Session() as session:\n",
    "        url = f\"https://meshb.nlm.nih.gov/record/ui?ui={UI}\"\n",
    "\n",
    "        response = session.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        text_of_interest = response.text\n",
    "        \n",
    "        try:\n",
    "            treeNumber_idx = text_of_interest.index('treeNumber_0')\n",
    "            uniqueID = text_of_interest.index('Unique ID')\n",
    "            limited_string = text_of_interest[treeNumber_idx:uniqueID]\n",
    "            end_index = limited_string.find('</a>')\n",
    "            counter = 1\n",
    "\n",
    "            while end_index-counter + 1 >= 0:\n",
    "                if limited_string[end_index-counter] == '>':\n",
    "                    shared_dict[UI] = limited_string[end_index-counter + 1:end_index]\n",
    "                    break\n",
    "                counter += 1\n",
    "            \n",
    "        except:\n",
    "            shared_dict[UI] = \"failed\"\n",
    "\n",
    "    else:\n",
    "        shared_dict[UI] = \"failed\"\n",
    "    \n",
    "\n",
    "temp_mesh = {}\n",
    "all_mesh_terms = multiprocessing.Manager().dict()\n",
    "\n",
    "lst = []\n",
    "\n",
    "\n",
    "for idx, mesh in enumerate(all_mesh_set):  \n",
    "        if not mesh in all_mesh_terms:\n",
    "            temp_mesh[mesh] = 1\n",
    "            \n",
    "\n",
    "for index, mesh in enumerate(temp_mesh.keys()):\n",
    "    lst.append((mesh, index, all_mesh_terms))\n",
    "\n",
    "    \n",
    "CHUNK_SIZE = 100\n",
    "SPLIT = len(lst) // CHUNK_SIZE + 1\n",
    "\n",
    "\n",
    "for i in tqdm(range(SPLIT)):\n",
    "    if i != SPLIT -1:\n",
    "        with multiprocessing.Pool(processes=10) as pool:\n",
    "                pool.starmap(retrieve_mesh_tree, lst[i*CHUNK_SIZE: (i+1) * CHUNK_SIZE])\n",
    "    \n",
    "    else:\n",
    "        with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "            pool.starmap(retrieve_mesh_tree, lst[i*CHUNK_SIZE: ])  \n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "\n",
    "        \n",
    "    time.sleep(10)\n",
    "    \n",
    "\n",
    "with open('all_mesh_retrieved', \"w\") as json_file:\n",
    "    json_file.write(all_mesh_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9993c550",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-11T03:39:06.293064682Z"
    }
   },
   "outputs": [],
   "source": [
    "mesh_saved = {}\n",
    "\n",
    "for key,value in all_mesh_terms.items():\n",
    "    mesh_saved[key] = value\n",
    "    \n",
    "    \n",
    "json_data = json.dumps(mesh_saved, indent=4)  # You can use indent for pretty formatting\n",
    "\n",
    "# Write the JSON data to the file\n",
    "with open('all_mesh_retrieved.json', 'w') as json_file:\n",
    "    json_file.write(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb3f08",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-11T03:39:06.293149893Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the file path\n",
    "file_path = 'all_mesh_retrieved.json'\n",
    "\n",
    "# Open the JSON file for reading\n",
    "with open(file_path, 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "    all_mesh_terms = json.load(json_file)\n",
    "\n",
    "print(len(all_mesh_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501751e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-11T03:39:06.293307680Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
