WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/hm31/step_1/venv/lib/python3.6/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
23/12/20 13:47:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
23/12/20 13:47:27 INFO SparkContext: Running Spark version 3.2.4
23/12/20 13:47:27 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
23/12/20 13:47:27 INFO ResourceUtils: ==============================================================
23/12/20 13:47:27 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/20 13:47:27 INFO ResourceUtils: ==============================================================
23/12/20 13:47:27 INFO SparkContext: Submitted application: Python Spark SQL basic example
23/12/20 13:47:27 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/20 13:47:27 INFO ResourceProfile: Limiting resource is cpu
23/12/20 13:47:27 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/20 13:47:27 INFO SecurityManager: Changing view acls to: hm31
23/12/20 13:47:27 INFO SecurityManager: Changing modify acls to: hm31
23/12/20 13:47:27 INFO SecurityManager: Changing view acls groups to: 
23/12/20 13:47:27 INFO SecurityManager: Changing modify acls groups to: 
23/12/20 13:47:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hm31); groups with view permissions: Set(); users  with modify permissions: Set(hm31); groups with modify permissions: Set()
23/12/20 13:47:27 INFO Utils: Successfully started service 'sparkDriver' on port 40055.
23/12/20 13:47:27 INFO SparkEnv: Registering MapOutputTracker
23/12/20 13:47:27 INFO SparkEnv: Registering BlockManagerMaster
23/12/20 13:47:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/20 13:47:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/20 13:47:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/20 13:47:28 INFO DiskBlockManager: Created local directory at /shared/hm31/blockmgr-5214cf7f-9cfc-4e89-84f9-5c391392da38
23/12/20 13:47:28 INFO MemoryStore: MemoryStore started with capacity 131.8 GiB
23/12/20 13:47:28 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/20 13:47:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/12/20 13:47:28 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://chackoge-serv01.cs.illinois.edu:4040
23/12/20 13:47:28 INFO SparkContext: Added JAR file:///home/hm31/step_1/step_7_calculate_similarities/postgresql-42.5.2.jar at spark://chackoge-serv01.cs.illinois.edu:40055/jars/postgresql-42.5.2.jar with timestamp 1703101647467
23/12/20 13:47:28 INFO Executor: Starting executor ID driver on host chackoge-serv01.cs.illinois.edu
23/12/20 13:47:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37537.
23/12/20 13:47:28 INFO NettyBlockTransferService: Server created on chackoge-serv01.cs.illinois.edu:37537
23/12/20 13:47:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/20 13:47:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, chackoge-serv01.cs.illinois.edu, 37537, None)
23/12/20 13:47:28 INFO BlockManagerMasterEndpoint: Registering block manager chackoge-serv01.cs.illinois.edu:37537 with 131.8 GiB RAM, BlockManagerId(driver, chackoge-serv01.cs.illinois.edu, 37537, None)
23/12/20 13:47:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, chackoge-serv01.cs.illinois.edu, 37537, None)
23/12/20 13:47:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, chackoge-serv01.cs.illinois.edu, 37537, None)
/home/hm31/step_1/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.
  FutureWarning
23/12/20 13:47:28 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/20 13:47:28 INFO SharedState: Warehouse path is 'file:/home/hm31/step_1/step_7_calculate_similarities/spark-warehouse'.
year completed
mesh completed
pre persist
post persist
23/12/20 14:22:35 ERROR Executor: Exception in task 87.0 in stage 6.0 (TID 288)
org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:35 ERROR Executor: Exception in task 29.0 in stage 6.0 (TID 230)
org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:35 ERROR Executor: Exception in task 94.0 in stage 6.0 (TID 295)
org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:35 ERROR Executor: Exception in task 65.0 in stage 6.0 (TID 266)
org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:35 ERROR Executor: Exception in task 96.0 in stage 6.0 (TID 297)
org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:35 ERROR Executor: Exception in task 45.0 in stage 6.0 (TID 246)
org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:35 ERROR Executor: Exception in task 4.0 in stage 6.0 (TID 205)
org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:35 ERROR Executor: Exception in task 34.0 in stage 6.0 (TID 235)
org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:35 ERROR Executor: Exception in task 20.0 in stage 6.0 (TID 221)
org.postgresql.util.PSQLException: FATAL: sorry, too many clients already
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:693)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:203)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:35 ERROR Executor: Exception in task 28.0 in stage 6.0 (TID 229)
org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:35 ERROR Executor: Exception in task 75.0 in stage 6.0 (TID 276)
org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 96.0 in stage 6.0 (TID 297) (chackoge-serv01.cs.illinois.edu executor driver): org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

23/12/20 14:22:35 ERROR TaskSetManager: Task 96 in stage 6.0 failed 1 times; aborting job
23/12/20 14:22:35 WARN TaskSetManager: Lost task 20.0 in stage 6.0 (TID 221) (chackoge-serv01.cs.illinois.edu executor driver): org.postgresql.util.PSQLException: FATAL: sorry, too many clients already
	at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:693)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:203)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:258)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

23/12/20 14:22:35 WARN TaskSetManager: Lost task 5.0 in stage 6.0 (TID 206) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 13.0 in stage 6.0 (TID 214) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 19.0 in stage 6.0 (TID 220) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 98.0 in stage 6.0 (TID 299) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 93.0 in stage 6.0 (TID 294) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 8.0 in stage 6.0 (TID 209) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 82.0 in stage 6.0 (TID 283) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 56.0 in stage 6.0 (TID 257) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 57.0 in stage 6.0 (TID 258) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 71.0 in stage 6.0 (TID 272) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 95.0 in stage 6.0 (TID 296) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 80.0 in stage 6.0 (TID 281) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 62.0 in stage 6.0 (TID 263) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 59.0 in stage 6.0 (TID 260) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 1.0 in stage 6.0 (TID 202) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 58.0 in stage 6.0 (TID 259) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 76.0 in stage 6.0 (TID 277) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 41.0 in stage 6.0 (TID 242) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 67.0 in stage 6.0 (TID 268) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 46.0 in stage 6.0 (TID 247) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 36.0 in stage 6.0 (TID 237) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 18.0 in stage 6.0 (TID 219) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 44.0 in stage 6.0 (TID 245) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 11.0 in stage 6.0 (TID 212) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 16.0 in stage 6.0 (TID 217) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 66.0 in stage 6.0 (TID 267) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 91.0 in stage 6.0 (TID 292) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 7.0 in stage 6.0 (TID 208) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 30.0 in stage 6.0 (TID 231) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 24.0 in stage 6.0 (TID 225) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 21.0 in stage 6.0 (TID 222) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 43.0 in stage 6.0 (TID 244) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 53.0 in stage 6.0 (TID 254) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 22.0 in stage 6.0 (TID 223) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 42.0 in stage 6.0 (TID 243) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 69.0 in stage 6.0 (TID 270) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 74.0 in stage 6.0 (TID 275) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 92.0 in stage 6.0 (TID 293) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 49.0 in stage 6.0 (TID 250) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 79.0 in stage 6.0 (TID 280) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 6.0 in stage 6.0 (TID 207) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 14.0 in stage 6.0 (TID 215) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 32.0 in stage 6.0 (TID 233) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 72.0 in stage 6.0 (TID 273) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 48.0 in stage 6.0 (TID 249) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 38.0 in stage 6.0 (TID 239) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 33.0 in stage 6.0 (TID 234) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 0.0 in stage 6.0 (TID 201) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 2.0 in stage 6.0 (TID 203) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 37.0 in stage 6.0 (TID 238) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 12.0 in stage 6.0 (TID 213) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 31.0 in stage 6.0 (TID 232) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 60.0 in stage 6.0 (TID 261) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 77.0 in stage 6.0 (TID 278) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 85.0 in stage 6.0 (TID 286) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 10.0 in stage 6.0 (TID 211) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 15.0 in stage 6.0 (TID 216) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 81.0 in stage 6.0 (TID 282) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 23.0 in stage 6.0 (TID 224) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 35.0 in stage 6.0 (TID 236) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 99.0 in stage 6.0 (TID 300) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 40.0 in stage 6.0 (TID 241) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 86.0 in stage 6.0 (TID 287) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 47.0 in stage 6.0 (TID 248) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 54.0 in stage 6.0 (TID 255) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 78.0 in stage 6.0 (TID 279) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 9.0 in stage 6.0 (TID 210) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 83.0 in stage 6.0 (TID 284) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 97.0 in stage 6.0 (TID 298) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 39.0 in stage 6.0 (TID 240) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 89.0 in stage 6.0 (TID 290) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 90.0 in stage 6.0 (TID 291) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 64.0 in stage 6.0 (TID 265) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 55.0 in stage 6.0 (TID 256) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 52.0 in stage 6.0 (TID 253) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 25.0 in stage 6.0 (TID 226) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 63.0 in stage 6.0 (TID 264) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 88.0 in stage 6.0 (TID 289) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 51.0 in stage 6.0 (TID 252) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 84.0 in stage 6.0 (TID 285) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 27.0 in stage 6.0 (TID 228) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 26.0 in stage 6.0 (TID 227) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 61.0 in stage 6.0 (TID 262) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 68.0 in stage 6.0 (TID 269) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 17.0 in stage 6.0 (TID 218) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 73.0 in stage 6.0 (TID 274) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 50.0 in stage 6.0 (TID 251) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 70.0 in stage 6.0 (TID 271) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
23/12/20 14:22:35 WARN TaskSetManager: Lost task 3.0 in stage 6.0 (TID 204) (chackoge-serv01.cs.illinois.edu executor driver): TaskKilled (Stage cancelled)
Traceback (most recent call last):
  File "/home/hm31/step_1/step_7_calculate_similarities/calculate_similarities.py", line 261, in <module>
    calculate_raw_similarities(spark)
  File "/home/hm31/step_1/step_7_calculate_similarities/calculate_similarities.py", line 225, in calculate_raw_similarities
    write_df(edges_annotated_with_year_and_mesh_features, jdbc_url, 'hm31.year_mesh_edge_weights_cert')
  File "/home/hm31/step_1/step_7_calculate_similarities/calculate_similarities.py", line 25, in write_df
    result.repartition(100).write.format('jdbc').mode('overwrite').option("truncate", False).option("url", jdbc_url).option('driver', "org.postgresql.Driver").option("user", 'hm31') .option("password", 'graphs').option("dbtable", table_name) .option("isolationLevel", "NONE").option("batchsize", 1000000) .save();
  File "/home/hm31/step_1/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 738, in save
  File "/home/hm31/step_1/venv/lib/python3.6/site-packages/pyspark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/home/hm31/step_1/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in deco
  File "/home/hm31/step_1/venv/lib/python3.6/site-packages/pyspark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o145.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 96 in stage 6.0 failed 1 times, most recent failure: Lost task 96.0 in stage 6.0 (TID 297) (chackoge-serv01.cs.illinois.edu executor driver): org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2450)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2399)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2398)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2398)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1156)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1156)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1156)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2638)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2580)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2569)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2224)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2245)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2264)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2289)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1020)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1018)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:893)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:64)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:97)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:93)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:93)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:80)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:78)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:115)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.postgresql.util.PSQLException: FATAL: remaining connection slots are reserved for non-replication superuser connections
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.readStartupMessages(QueryExecutorImpl.java:2788)
	at org.postgresql.core.v3.QueryExecutorImpl.<init>(QueryExecutorImpl.java:174)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:313)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:54)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:253)
	at org.postgresql.Driver.makeConnection(Driver.java:434)
	at org.postgresql.Driver.connect(Driver.java:291)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:670)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)
	at org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	... 1 more

23/12/20 14:22:36 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /shared/hm31/blockmgr-5214cf7f-9cfc-4e89-84f9-5c391392da38. Falling back to Java IO way
java.io.IOException: Failed to delete: /shared/hm31/blockmgr-5214cf7f-9cfc-4e89-84f9-5c391392da38
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1193)
	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:318)
	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:314)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:314)
	at org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:309)
	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2013)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:92)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2136)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1471)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2136)
	at org.apache.spark.SparkContext.$anonfun$new$38(SparkContext.scala:677)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:36 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /shared/hm31/blockmgr-5214cf7f-9cfc-4e89-84f9-5c391392da38/08. Falling back to Java IO way
java.io.IOException: Failed to delete: /shared/hm31/blockmgr-5214cf7f-9cfc-4e89-84f9-5c391392da38/08
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1193)
	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:318)
	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:314)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:314)
	at org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:309)
	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2013)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:92)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2136)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1471)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2136)
	at org.apache.spark.SparkContext.$anonfun$new$38(SparkContext.scala:677)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:36 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /shared/hm31/blockmgr-5214cf7f-9cfc-4e89-84f9-5c391392da38/08/.nfs000000000d9a604b00003757. Falling back to Java IO way
java.io.IOException: Failed to delete: /shared/hm31/blockmgr-5214cf7f-9cfc-4e89-84f9-5c391392da38/08/.nfs000000000d9a604b00003757
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1193)
	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:318)
	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:314)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:314)
	at org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:309)
	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2013)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:92)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2136)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1471)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2136)
	at org.apache.spark.SparkContext.$anonfun$new$38(SparkContext.scala:677)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/12/20 14:22:36 ERROR DiskBlockManager: Exception while deleting local spark dir: /shared/hm31/blockmgr-5214cf7f-9cfc-4e89-84f9-5c391392da38
java.io.IOException: Failed to delete: /shared/hm31/blockmgr-5214cf7f-9cfc-4e89-84f9-5c391392da38/08/.nfs000000000d9a604b00003757
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1193)
	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:318)
	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:314)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:314)
	at org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:309)
	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2013)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:92)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2136)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1471)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2136)
	at org.apache.spark.SparkContext.$anonfun$new$38(SparkContext.scala:677)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/hm31/step_1/venv/lib/python3.6/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.4.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
23/12/20 14:25:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
23/12/20 14:25:53 INFO SparkContext: Running Spark version 3.2.4
23/12/20 14:25:53 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
23/12/20 14:25:53 INFO ResourceUtils: ==============================================================
23/12/20 14:25:53 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/20 14:25:53 INFO ResourceUtils: ==============================================================
23/12/20 14:25:53 INFO SparkContext: Submitted application: Python Spark SQL basic example
23/12/20 14:25:53 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/20 14:25:53 INFO ResourceProfile: Limiting resource is cpu
23/12/20 14:25:53 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/20 14:25:53 INFO SecurityManager: Changing view acls to: hm31
23/12/20 14:25:53 INFO SecurityManager: Changing modify acls to: hm31
23/12/20 14:25:53 INFO SecurityManager: Changing view acls groups to: 
23/12/20 14:25:53 INFO SecurityManager: Changing modify acls groups to: 
23/12/20 14:25:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hm31); groups with view permissions: Set(); users  with modify permissions: Set(hm31); groups with modify permissions: Set()
23/12/20 14:25:53 INFO Utils: Successfully started service 'sparkDriver' on port 34225.
23/12/20 14:25:53 INFO SparkEnv: Registering MapOutputTracker
23/12/20 14:25:53 INFO SparkEnv: Registering BlockManagerMaster
23/12/20 14:25:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/20 14:25:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/20 14:25:53 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/20 14:25:53 INFO DiskBlockManager: Created local directory at /shared/hm31/blockmgr-1c409d6b-5ed6-4bcb-a88e-d9751817513b
23/12/20 14:25:53 INFO MemoryStore: MemoryStore started with capacity 131.8 GiB
23/12/20 14:25:53 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/20 14:25:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/12/20 14:25:54 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://chackoge-serv01.cs.illinois.edu:4040
23/12/20 14:25:54 INFO SparkContext: Added JAR file:///home/hm31/step_1/step_7_calculate_similarities/postgresql-42.5.2.jar at spark://chackoge-serv01.cs.illinois.edu:34225/jars/postgresql-42.5.2.jar with timestamp 1703103953392
23/12/20 14:25:54 INFO Executor: Starting executor ID driver on host chackoge-serv01.cs.illinois.edu
23/12/20 14:25:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46794.
23/12/20 14:25:54 INFO NettyBlockTransferService: Server created on chackoge-serv01.cs.illinois.edu:46794
23/12/20 14:25:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/20 14:25:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, chackoge-serv01.cs.illinois.edu, 46794, None)
23/12/20 14:25:54 INFO BlockManagerMasterEndpoint: Registering block manager chackoge-serv01.cs.illinois.edu:46794 with 131.8 GiB RAM, BlockManagerId(driver, chackoge-serv01.cs.illinois.edu, 46794, None)
23/12/20 14:25:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, chackoge-serv01.cs.illinois.edu, 46794, None)
23/12/20 14:25:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, chackoge-serv01.cs.illinois.edu, 46794, None)
/home/hm31/step_1/venv/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.
  FutureWarning
23/12/20 14:25:54 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/20 14:25:54 INFO SharedState: Warehouse path is 'file:/home/hm31/step_1/step_7_calculate_similarities/spark-warehouse'.
year completed
